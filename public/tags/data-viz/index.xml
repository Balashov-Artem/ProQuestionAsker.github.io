<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amber Thomas</title>
    <link>/tags/data-viz/index.xml</link>
    <description>Recent content on Amber Thomas</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2016 Amber Thomas</copyright>
    <atom:link href="/tags/data-viz/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Mapping Student Course Activity</title>
      <link>/projects/fcc_courses3/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/fcc_courses3/</guid>
      <description>&lt;p&gt;Cleaning, exploration, interactive visualizations, and machine learning with Free Code Camp&amp;rsquo;s student course completion dataset.
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#importing-necessary-packages&#34;&gt;Importing Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-exploration&#34;&gt;Data Exploration&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#importing-dataset&#34;&gt;Importing Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-structure-and-variables&#34;&gt;Data Structure and Variables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#using-original-dataset&#34;&gt;Using Original Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#web-scraping-new-data&#34;&gt;Web Scraping New Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#engineered-variables&#34;&gt;Engineered Variables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-visualizations&#34;&gt;Data Visualizations&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-class-do-fcc-students-start-with&#34;&gt;What class do FCC students start with?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#which-classes-are-the-most-popular&#34;&gt;Which classes are the most popular?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-do-students-flow-through-the-courses&#34;&gt;How do students flow through the courses?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-many-courses-do-students-take&#34;&gt;How many courses do students take?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#can-you-group-students-based-on-the-number-of-classes-they-take-vs.-the-amount-of-time-they-spend-per-class&#34;&gt;Can you group students based on the number of classes they take vs. the amount of time they spend per class?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#does-taking-a-2-week-break-help-or-hurt-course-completion&#34;&gt;Does taking a 2 week break help or hurt course completion?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#which-courses-tend-to-be-repeated-by-students&#34;&gt;Which courses tend to be repeated by students?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#can-we-predict-the-number-of-courses-a-student-will-complete-using-machine-learning&#34;&gt;Can we predict the number of courses a student will complete using machine learning?&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-baseline-model&#34;&gt;Fitting a baseline model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-traincontrol&#34;&gt;Creating trainControl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-random-forest-model&#34;&gt;Fitting a random forest model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-glmnet-model&#34;&gt;Fitting a glmnet model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparing-model-fit&#34;&gt;Comparing Model Fit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#my-suggestions&#34;&gt;My Suggestions:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.freecodecamp.com/&#34;&gt;Free Code Camp&lt;/a&gt; (FCC) is an online, self-paced, collection of massive open online courses (MOOCs) aimed at teaching users to code. Campers can log onto the service, complete coding challenges and projects, and earn certificates commemorating their completion. The topics covered include HTML5, CSS3, JavaScript, Databases, Git &amp;amp; Github, Node.js, React.js, and D3.js.&lt;/p&gt;

&lt;p&gt;In December of 2015, FCC released &lt;a href=&#34;https://medium.freecodecamp.com/free-code-camp-christmas-special-giving-the-gift-of-data-6ecbf0313d62#.ibujuvlhc&#34;&gt;lots of data&lt;/a&gt; regarding the progress and solutions of their users throughout the courses. When I say lots, I mean there are data for over 100,000 students here!&lt;/p&gt;

&lt;p&gt;Without having first looked at the dataset, the first questions I may consider are those posed by FCC itself:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Can our campers be broken down into cohort groups based on challenge completion behavior?&lt;/li&gt;
&lt;li&gt;Is there a challenge completion tempo that typifies high-achieving campers? One that typifies slow-and-steady campers?&lt;/li&gt;
&lt;li&gt;Many campers will leave Free Code Camp for several months due to burnout, or life getting in the way, then return a few months later. Are there any meaningful patterns here?&lt;/li&gt;
&lt;li&gt;What proportion of campers complete challenges mostly in order, as opposed to skipping around?&lt;/li&gt;
&lt;li&gt;What proportion of campers dive directly into harder challenges, then work backward until they are able to start successfully completing challenges?&lt;/li&gt;
&lt;li&gt;Are there any challenges that seem excessively hard, and require significantly more time investment than adjacent challenges?&lt;/li&gt;
&lt;li&gt;Are there any challenges that are disproportionately popular, considering their later position within our curriculum?&lt;/li&gt;
&lt;li&gt;Which challenges support the most diverse solutions?&lt;/li&gt;
&lt;li&gt;Are campers more likely to use Object Oriented Programming solutions or Functional Programming solutions?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That&amp;rsquo;s certainly a good place to start. I don&amp;rsquo;t think I&amp;rsquo;ll get to answer all of those in this project, but I&amp;rsquo;ll answer some.&lt;/p&gt;

&lt;p&gt;Time to look at the data!&lt;/p&gt;

&lt;h3 id=&#34;importing-necessary-packages&#34;&gt;Importing Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For importing JSON data
library(tidyjson)
library(jsonlite)
library(data.table)

# For data manipulation and tidying
library(dplyr)
library(tidyr)
library(Hmisc)

# For data visualizations
library(ggplot2)
library(highcharter)
library(igraph)
library(networkD3)
library(htmlwidgets)

# For web scraping
library(rvest)
library(curl)

# For machine learning
library(caret)
library(ranger)
library(e1071)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h2&gt;

&lt;h3 id=&#34;importing-dataset&#34;&gt;Importing Dataset&lt;/h3&gt;

&lt;p&gt;The data are freely available from FCC and can be downloaded &lt;a href=&#34;http://academictorrents.com/details/030b10dad0846b5aecc3905692890fb02404adbf&#34;&gt;here&lt;/a&gt;. I&amp;rsquo;m going to import the data using the&lt;code&gt;jsonlite&lt;/code&gt;, &lt;code&gt;tidyjson&lt;/code&gt; and &lt;code&gt;data.table&lt;/code&gt; packages.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: my poor little laptop couldn&amp;rsquo;t handle importing/binding these files. I am lucky enough that &lt;a href=&#34;http://www.animoplex.com&#34;&gt;Parker&lt;/a&gt; let me use his animation rendering machine (i.e. work-horse in computer form) to complete this project.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Import JSON using the jsonlite package
fcc &amp;lt;- fromJSON(&amp;quot;output.json&amp;quot;, flatten = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a list of data frames. Time to bind them into a giant data frame using the &lt;code&gt;data.table&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_df &amp;lt;- rbindlist(fcc, fill = TRUE, idcol = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Last thing is to convert the data.table to a data.frame (this one is in base R).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_df2 &amp;lt;- as.data.frame(fcc_df)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;data-structure-and-variables&#34;&gt;Data Structure and Variables&lt;/h3&gt;

&lt;p&gt;Great! Now that our data is imported, we can get a look at it. I&amp;rsquo;ll start by looking at it&amp;rsquo;s structure.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(fcc_df2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    7236580 obs. of  4 variables:
##  $ .id          : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ name         : chr  &amp;quot;Waypoint: Learn how Free Code Camp Works&amp;quot; &amp;quot;Waypoint: Learn how Free Code Camp Works&amp;quot; &amp;quot;Waypoint: Preview our Challenge Map&amp;quot; &amp;quot;Waypoint: Browse our Field Guide&amp;quot; ...
##  $ completedDate: chr  &amp;quot;1434650566196&amp;quot; &amp;quot;1434650582665&amp;quot; &amp;quot;1434651100007&amp;quot; &amp;quot;1434651311734&amp;quot; ...
##  $ solution     : chr  NA NA NA NA ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so as expected, we are working with a data frame with 4 variables and &lt;strong&gt;7,236,580&lt;/strong&gt; observations! No wonder my laptop couldn&amp;rsquo;t handle it.&lt;/p&gt;

&lt;p&gt;Our 4 variables are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.id&lt;/strong&gt; : The ID number created when binding our list of data frames into a single data frame. In this case, it corresponds to FCC user number.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt; : The FCC course completed&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;completedDate&lt;/strong&gt; : The date the course was completed (as a Unix timestamp in milliseconds)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;solution&lt;/strong&gt; :The user&amp;rsquo;s solution to the course challenge.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While a character string is fine for the &amp;ldquo;solution&amp;rdquo; column, I&amp;rsquo;m going to change the data type of the name, id, and completedDate columns. Name and id should both be factors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_df2$name &amp;lt;- as.factor(fcc_df2$name)
fcc_df2$.id &amp;lt;- as.factor(fcc_df2$.id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How many users are we dealing with?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_df2 %&amp;gt;% summarise(n_distinct(.id))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   n_distinct(.id)
## 1          103091
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;103,091 different users!&lt;/p&gt;

&lt;p&gt;How many challenges are there? And do we have any duplicates?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(fcc_df2$name)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;&amp;quot;                                                                          
##   [2] &amp;quot;: Use the Javascript Console&amp;quot;                                              
##   [3] &amp;quot;: Using typeof&amp;quot;                                                            
##   [4] &amp;quot;Apply Angular.js Directives&amp;quot;                                               
##   [5] &amp;quot;Arguments Optional&amp;quot;                                                        
##   [6] &amp;quot;Basejump: Build a Nightlife Coordination App&amp;quot;                              
##   [7] &amp;quot;Basejump: Build a Pinterest Clone&amp;quot;                                         
##   [8] &amp;quot;Basejump: Build a Pintrest Clone&amp;quot;                                          
##   [9] &amp;quot;Basejump: Build a Voting App&amp;quot;                                              
##  [10] &amp;quot;Basejump: Chart the Stock Market&amp;quot;                                          
##  [11] &amp;quot;Basejump: Manage a Book Trading Club&amp;quot;                                      
##  [12] &amp;quot;Basejumps: Build a Nightlife Coordination App&amp;quot;                             
##  [13] &amp;quot;Basejumps: Build a Pinterest Clone&amp;quot;                                        
##  [14] &amp;quot;Basejumps: Build a Voting App&amp;quot;                                             
##  [15] &amp;quot;Basejumps: Chart the Stock Market&amp;quot;                                         
##  [16] &amp;quot;Basejumps: Manage a Book Trading Club&amp;quot;                                     
##  [17] &amp;quot;Binary Agents&amp;quot;                                                             
##  [18] &amp;quot;Bonfire: Arguments Optional&amp;quot;                                               
##  [19] &amp;quot;Bonfire: Binary Agents&amp;quot;                                                    
##  [20] &amp;quot;Bonfire: Boo who&amp;quot;                                                          
##  [21] &amp;quot;Bonfire: Check for Palindromes&amp;quot;                                            
##  [22] &amp;quot;Bonfire: Chunky Monkey&amp;quot;                                                    
##  [23] &amp;quot;Bonfire: Confirm the Ending&amp;quot;                                               
##  [24] &amp;quot;Bonfire: Convert HTML Entities&amp;quot;                                            
##  [25] &amp;quot;Bonfire: Diff Two Arrays&amp;quot;                                                  
##  [26] &amp;quot;Bonfire: DNA Pairing&amp;quot;                                                      
##  [27] &amp;quot;Bonfire: Drop it&amp;quot;                                                          
##  [28] &amp;quot;Bonfire: Everything Be True&amp;quot;                                               
##  [29] &amp;quot;Bonfire: Exact Change&amp;quot;                                                     
##  [30] &amp;quot;Bonfire: Factorialize a Number&amp;quot;                                            
##  [31] &amp;quot;Bonfire: Falsey Bouncer&amp;quot;                                                   
##  [32] &amp;quot;Bonfire: Falsy Bouncer&amp;quot;                                                    
##  [33] &amp;quot;Bonfire: Find the Longest Word in a String&amp;quot;                                
##  [34] &amp;quot;Bonfire: Finders Keepers&amp;quot;                                                  
##  [35] &amp;quot;Bonfire: Friendly Date Ranges&amp;quot;                                             
##  [36] &amp;quot;Bonfire: Inventory Update&amp;quot;                                                 
##  [37] &amp;quot;Bonfire: Make a Person&amp;quot;                                                    
##  [38] &amp;quot;Bonfire: Map the Debris&amp;quot;                                                   
##  [39] &amp;quot;Bonfire: Meet Bonfire&amp;quot;                                                     
##  [40] &amp;quot;Bonfire: Missing letters&amp;quot;                                                  
##  [41] &amp;quot;Bonfire: Mutations&amp;quot;                                                        
##  [42] &amp;quot;Bonfire: No repeats please&amp;quot;                                                
##  [43] &amp;quot;Bonfire: Pairwise&amp;quot;                                                         
##  [44] &amp;quot;Bonfire: Pig Latin&amp;quot;                                                        
##  [45] &amp;quot;Bonfire: Repeat a string repeat a string&amp;quot;                                  
##  [46] &amp;quot;Bonfire: Return Largest Numbers in Arrays&amp;quot;                                 
##  [47] &amp;quot;Bonfire: Reverse a String&amp;quot;                                                 
##  [48] &amp;quot;Bonfire: Roman Numeral Converter&amp;quot;                                          
##  [49] &amp;quot;Bonfire: Search and Replace&amp;quot;                                               
##  [50] &amp;quot;Bonfire: Seek and Destroy&amp;quot;                                                 
##  [51] &amp;quot;Bonfire: Slasher Flick&amp;quot;                                                    
##  [52] &amp;quot;Bonfire: Smallest Common Multiple&amp;quot;                                         
##  [53] &amp;quot;Bonfire: Sorted Union&amp;quot;                                                     
##  [54] &amp;quot;Bonfire: Spinal Tap Case&amp;quot;                                                  
##  [55] &amp;quot;Bonfire: Steamroller&amp;quot;                                                      
##  [56] &amp;quot;Bonfire: Sum All Numbers in a Range&amp;quot;                                       
##  [57] &amp;quot;Bonfire: Sum All Odd Fibonacci Numbers&amp;quot;                                    
##  [58] &amp;quot;Bonfire: Sum All Primes&amp;quot;                                                   
##  [59] &amp;quot;Bonfire: Symmetric Difference&amp;quot;                                             
##  [60] &amp;quot;Bonfire: Title Case a Sentence&amp;quot;                                            
##  [61] &amp;quot;Bonfire: Truncate a string&amp;quot;                                                
##  [62] &amp;quot;Bonfire: Validate US Telephone Numbers&amp;quot;                                    
##  [63] &amp;quot;Bonfire: Where art thou&amp;quot;                                                   
##  [64] &amp;quot;Bonfire: Where do I belong&amp;quot;                                                
##  [65] &amp;quot;Boo who&amp;quot;                                                                   
##  [66] &amp;quot;Browse our Field Guide&amp;quot;                                                    
##  [67] &amp;quot;Build a Cash Register&amp;quot;                                                     
##  [68] &amp;quot;Build a Contact List&amp;quot;                                                      
##  [69] &amp;quot;Build a Geolocation Angular App&amp;quot;                                           
##  [70] &amp;quot;Build a Landing Page with HTML&amp;quot;                                            
##  [71] &amp;quot;Build an Address Book&amp;quot;                                                     
##  [72] &amp;quot;Build an Adventure Game&amp;quot;                                                   
##  [73] &amp;quot;Build Rock Paper Scissors&amp;quot;                                                 
##  [74] &amp;quot;Build Web Apps with Express.js&amp;quot;                                            
##  [75] &amp;quot;Cash Register&amp;quot;                                                             
##  [76] &amp;quot;Check for Palindromes&amp;quot;                                                     
##  [77] &amp;quot;Chunky Monkey&amp;quot;                                                             
##  [78] &amp;quot;Confirm the Ending&amp;quot;                                                        
##  [79] &amp;quot;Convert HTML Entities&amp;quot;                                                     
##  [80] &amp;quot;Create Angular.js Services&amp;quot;                                                
##  [81] &amp;quot;Customize Angular.js Directives&amp;quot;                                           
##  [82] &amp;quot;Customize your Porfolio Page&amp;quot;                                              
##  [83] &amp;quot;Customize your Portfolio Page&amp;quot;                                             
##  [84] &amp;quot;Design a Layout with HTML&amp;quot;                                                 
##  [85] &amp;quot;Design Responsively with Bootstrap&amp;quot;                                        
##  [86] &amp;quot;Diff Two Arrays&amp;quot;                                                           
##  [87] &amp;quot;Discover Chrome&#39;s DevTools&amp;quot;                                                
##  [88] &amp;quot;DNA Pairing&amp;quot;                                                               
##  [89] &amp;quot;Drop it like it&#39;s hot&amp;quot;                                                     
##  [90] &amp;quot;Everything Be True&amp;quot;                                                        
##  [91] &amp;quot;Factorialize a Number&amp;quot;                                                     
##  [92] &amp;quot;Falsey Bouncer&amp;quot;                                                            
##  [93] &amp;quot;Find the Longest Word in a String&amp;quot;                                         
##  [94] &amp;quot;Finders Keepers&amp;quot;                                                           
##  [95] &amp;quot;Friendly Date Ranges&amp;quot;                                                      
##  [96] &amp;quot;Get Help the Hacker Way with RSAP&amp;quot;                                         
##  [97] &amp;quot;Get Set for Basejumps&amp;quot;                                                     
##  [98] &amp;quot;Get Set for Ziplines&amp;quot;                                                      
##  [99] &amp;quot;Get Started with Angular.js&amp;quot;                                               
## [100] &amp;quot;Get Started with jQuery&amp;quot;                                                   
## [101] &amp;quot;Harness Dynamic HTML&amp;quot;                                                      
## [102] &amp;quot;Inventory Update&amp;quot;                                                          
## [103] &amp;quot;Join Our Chat Room&amp;quot;                                                        
## [104] &amp;quot;Learn Basic Computer Science&amp;quot;                                              
## [105] &amp;quot;Learn Boolean Logic&amp;quot;                                                       
## [106] &amp;quot;Learn Computer Hardware&amp;quot;                                                   
## [107] &amp;quot;Learn Computer Networking&amp;quot;                                                 
## [108] &amp;quot;Learn Computer Security&amp;quot;                                                   
## [109] &amp;quot;Learn Control Flow&amp;quot;                                                        
## [110] &amp;quot;Learn how Free Code Camp Works&amp;quot;                                            
## [111] &amp;quot;Learn JavaScript For Loops&amp;quot;                                                
## [112] &amp;quot;Learn JavaScript While Loops&amp;quot;                                              
## [113] &amp;quot;Learn Loops&amp;quot;                                                               
## [114] &amp;quot;Learn Regular Expressions&amp;quot;                                                 
## [115] &amp;quot;Listen for jQuery Events&amp;quot;                                                  
## [116] &amp;quot;Make a Person&amp;quot;                                                             
## [117] &amp;quot;Manage Packages with NPM&amp;quot;                                                  
## [118] &amp;quot;Manage Source Code with Git&amp;quot;                                               
## [119] &amp;quot;Map the Debris&amp;quot;                                                            
## [120] &amp;quot;Meet Bonfire&amp;quot;                                                              
## [121] &amp;quot;Meet Other Campers in your City&amp;quot;                                           
## [122] &amp;quot;Missing letters&amp;quot;                                                           
## [123] &amp;quot;Mutations&amp;quot;                                                                 
## [124] &amp;quot;No repeats please&amp;quot;                                                         
## [125] &amp;quot;Pair Program on Bonfires&amp;quot;                                                  
## [126] &amp;quot;Pairwise&amp;quot;                                                                  
## [127] &amp;quot;Pig Latin&amp;quot;                                                                 
## [128] &amp;quot;Power Forms with Angular.js&amp;quot;                                               
## [129] &amp;quot;Preview our Challenge Map&amp;quot;                                                 
## [130] &amp;quot;Repeat a string repeat a string&amp;quot;                                           
## [131] &amp;quot;Return Largest Numbers in Arrays&amp;quot;                                          
## [132] &amp;quot;Reverse a String&amp;quot;                                                          
## [133] &amp;quot;Roman Numeral Converter&amp;quot;                                                   
## [134] &amp;quot;Search and Replace&amp;quot;                                                        
## [135] &amp;quot;Seek and Destroy&amp;quot;                                                          
## [136] &amp;quot;Slasher Flick&amp;quot;                                                             
## [137] &amp;quot;Smallest Common Multiple&amp;quot;                                                  
## [138] &amp;quot;Sorted Union&amp;quot;                                                              
## [139] &amp;quot;Space Out with CSS&amp;quot;                                                        
## [140] &amp;quot;Spinal Tap Case&amp;quot;                                                           
## [141] &amp;quot;Start a Node.js Server&amp;quot;                                                    
## [142] &amp;quot;Steamroller&amp;quot;                                                               
## [143] &amp;quot;Structure Angular.js Routes&amp;quot;                                               
## [144] &amp;quot;Style Text with CSS&amp;quot;                                                       
## [145] &amp;quot;Sum All Numbers in a Range&amp;quot;                                                
## [146] &amp;quot;Sum All Odd Fibonacci Numbers&amp;quot;                                             
## [147] &amp;quot;Sum All Primes&amp;quot;                                                            
## [148] &amp;quot;Symmetric Difference&amp;quot;                                                      
## [149] &amp;quot;Title Case a Sentence&amp;quot;                                                     
## [150] &amp;quot;Trigger jQuery Effects&amp;quot;                                                    
## [151] &amp;quot;Truncate a string&amp;quot;                                                         
## [152] &amp;quot;Try Camper News&amp;quot;                                                           
## [153] &amp;quot;Validate US Telephone Numbers&amp;quot;                                             
## [154] &amp;quot;Waypoint: Access Array Data with Indexes&amp;quot;                                  
## [155] &amp;quot;Waypoint: Add a Negative Margin to an Element&amp;quot;                             
## [156] &amp;quot;Waypoint: Add a Submit Button to a Form&amp;quot;                                   
## [157] &amp;quot;Waypoint: Add Alt Text to an Image for Accessibility&amp;quot;                      
## [158] &amp;quot;Waypoint: Add Borders Around your Elements&amp;quot;                                
## [159] &amp;quot;Waypoint: Add Different a Margin to Each Side of an Element&amp;quot;               
## [160] &amp;quot;Waypoint: Add Different Margins to Each Side of an Element&amp;quot;                
## [161] &amp;quot;Waypoint: Add Different Padding to Each Side of an Element&amp;quot;                
## [162] &amp;quot;Waypoint: Add Elements within your Bootstrap Wells&amp;quot;                        
## [163] &amp;quot;Waypoint: Add Font Awesome Icons all of our Buttons&amp;quot;                       
## [164] &amp;quot;Waypoint: Add Font Awesome Icons to all of our Buttons&amp;quot;                    
## [165] &amp;quot;Waypoint: Add Font Awesome Icons to our Buttons&amp;quot;                           
## [166] &amp;quot;Waypoint: Add Free Code Camp to your LinkedIn Profile&amp;quot;                     
## [167] &amp;quot;Waypoint: Add ID Attributes to Bootstrap Elements&amp;quot;                         
## [168] &amp;quot;Waypoint: Add Images to your Website&amp;quot;                                      
## [169] &amp;quot;Waypoint: Add New Properties to a JavaScript Object&amp;quot;                       
## [170] &amp;quot;Waypoint: Add Placeholder Text to a Text Field&amp;quot;                            
## [171] &amp;quot;Waypoint: Add Rounded Corners with a Border Radius&amp;quot;                        
## [172] &amp;quot;Waypoint: Add Two Numbers with JavaScript&amp;quot;                                 
## [173] &amp;quot;Waypoint: Add your JavaScript Slot Machine Slots&amp;quot;                          
## [174] &amp;quot;Waypoint: Adjust the Margin of an Element&amp;quot;                                 
## [175] &amp;quot;Waypoint: Adjusting the Padding of an Element&amp;quot;                             
## [176] &amp;quot;Waypoint: Apply Angular.js Directives&amp;quot;                                     
## [177] &amp;quot;Waypoint: Apply Angularjs Directives&amp;quot;                                      
## [178] &amp;quot;Waypoint: Apply the Default Bootstrap Button Style&amp;quot;                        
## [179] &amp;quot;Waypoint: Bring your JavaScript Slot Machine to Life&amp;quot;                      
## [180] &amp;quot;Waypoint: Browse Camper News&amp;quot;                                              
## [181] &amp;quot;Waypoint: Browse our Field Guide&amp;quot;                                          
## [182] &amp;quot;Waypoint: Build a Cash Register&amp;quot;                                           
## [183] &amp;quot;Waypoint: Build a Contact List&amp;quot;                                            
## [184] &amp;quot;Waypoint: Build an Address Book&amp;quot;                                           
## [185] &amp;quot;Waypoint: Build an Adventure Game&amp;quot;                                         
## [186] &amp;quot;Waypoint: Build JavaScript Objects&amp;quot;                                        
## [187] &amp;quot;Waypoint: Build Objects with Functional Classes&amp;quot;                           
## [188] &amp;quot;Waypoint: Build Objects with Prototypal Classes&amp;quot;                           
## [189] &amp;quot;Waypoint: Build Rock Paper Scissors&amp;quot;                                       
## [190] &amp;quot;Waypoint: Build Web Apps with Express.js&amp;quot;                                  
## [191] &amp;quot;Waypoint: Build Web Apps with Expressjs&amp;quot;                                   
## [192] &amp;quot;Waypoint: Call out Optional Actions with Button Info&amp;quot;                      
## [193] &amp;quot;Waypoint: Center Text with Bootstrap&amp;quot;                                      
## [194] &amp;quot;Waypoint: Change Text Inside an Element Using jQuery&amp;quot;                      
## [195] &amp;quot;Waypoint: Change Text with Click Events&amp;quot;                                   
## [196] &amp;quot;Waypoint: Change the Color of Text&amp;quot;                                        
## [197] &amp;quot;Waypoint: Change the CSS of an Element Using jQuery&amp;quot;                       
## [198] &amp;quot;Waypoint: Change the Font Size of an Element&amp;quot;                              
## [199] &amp;quot;Waypoint: Check Radio Buttons and Checkboxes by Default&amp;quot;                   
## [200] &amp;quot;Waypoint: Check the Length Property of a String Variable&amp;quot;                  
## [201] &amp;quot;Waypoint: Claim Your Back End Development Certificate&amp;quot;                     
## [202] &amp;quot;Waypoint: Claim Your Front End Development Certificate&amp;quot;                    
## [203] &amp;quot;Waypoint: Claim Your Full Stack Development Certificate&amp;quot;                   
## [204] &amp;quot;Waypoint: Clean up your form using Linebreaks&amp;quot;                             
## [205] &amp;quot;Waypoint: Clone an Element Using jQuery&amp;quot;                                   
## [206] &amp;quot;Waypoint: Comment out HTML&amp;quot;                                                
## [207] &amp;quot;Waypoint: Comment your JavaScript Code&amp;quot;                                    
## [208] &amp;quot;Waypoint: Commit to a Goal and a Nonprofit&amp;quot;                                
## [209] &amp;quot;Waypoint: Concatenate Arrays with concat&amp;quot;                                  
## [210] &amp;quot;Waypoint: Concatenate Strings with concat&amp;quot;                                 
## [211] &amp;quot;Waypoint: Condense arrays with reduce&amp;quot;                                     
## [212] &amp;quot;Waypoint: Configure your Code Portfolio&amp;quot;                                   
## [213] &amp;quot;Waypoint: Configure your Public Profile&amp;quot;                                   
## [214] &amp;quot;Waypoint: Construct JavaScript Objects with Functions&amp;quot;                     
## [215] &amp;quot;Waypoint: Constructing JavaScript Objects with Functions&amp;quot;                  
## [216] &amp;quot;Waypoint: Continue working with Node.js Servers&amp;quot;                           
## [217] &amp;quot;Waypoint: Continue working with Nodejs Servers&amp;quot;                            
## [218] &amp;quot;Waypoint: Convert JSON Data to HTML&amp;quot;                                       
## [219] &amp;quot;Waypoint: Count Backwards With a For Loop&amp;quot;                                 
## [220] &amp;quot;Waypoint: Create a Block Element Bootstrap Button&amp;quot;                         
## [221] &amp;quot;Waypoint: Create a Bootstrap Button&amp;quot;                                       
## [222] &amp;quot;Waypoint: Create a Bootstrap Headline&amp;quot;                                     
## [223] &amp;quot;Waypoint: Create a Bootstrap Row&amp;quot;                                          
## [224] &amp;quot;Waypoint: Create a Bulleted Unordered List&amp;quot;                                
## [225] &amp;quot;Waypoint: Create a Class to Target with jQuery Selectors&amp;quot;                  
## [226] &amp;quot;Waypoint: Create a Custom Heading&amp;quot;                                         
## [227] &amp;quot;Waypoint: Create a Form Element&amp;quot;                                           
## [228] &amp;quot;Waypoint: Create a GitHub Account and Join our Chat Rooms&amp;quot;                 
## [229] &amp;quot;Waypoint: Create a JavaScript Slot Machine&amp;quot;                                
## [230] &amp;quot;Waypoint: Create a Set of Checkboxes&amp;quot;                                      
## [231] &amp;quot;Waypoint: Create a Set of Radio Buttons&amp;quot;                                   
## [232] &amp;quot;Waypoint: Create a Text Field&amp;quot;                                             
## [233] &amp;quot;Waypoint: Create an Ordered List&amp;quot;                                          
## [234] &amp;quot;Waypoint: Create Angular.js Services&amp;quot;                                      
## [235] &amp;quot;Waypoint: Create Angularjs Services&amp;quot;                                       
## [236] &amp;quot;Waypoint: Create Bootstrap Wells&amp;quot;                                          
## [237] &amp;quot;Waypoint: Create Decimal Numbers with JavaScript&amp;quot;                          
## [238] &amp;quot;Waypoint: Customize Angular.js Directives&amp;quot;                                 
## [239] &amp;quot;Waypoint: Customize Angularjs Directives&amp;quot;                                  
## [240] &amp;quot;Waypoint: Customize your Portfolio Page&amp;quot;                                   
## [241] &amp;quot;Waypoint: Declare JavaScript Objects as Variables&amp;quot;                         
## [242] &amp;quot;Waypoint: Declare JavaScript Variables&amp;quot;                                    
## [243] &amp;quot;Waypoint: Declare String Variables&amp;quot;                                        
## [244] &amp;quot;Waypoint: Declaring JavaScript Objects as Variables&amp;quot;                       
## [245] &amp;quot;Waypoint: Delete HTML Elements&amp;quot;                                            
## [246] &amp;quot;Waypoint: Delete Properties from a JavaScript Object&amp;quot;                      
## [247] &amp;quot;Waypoint: Delete your jQuery Functions&amp;quot;                                    
## [248] &amp;quot;Waypoint: Disable an Element Using jQuery&amp;quot;                                 
## [249] &amp;quot;Waypoint: Discover Chrome DevTools&amp;quot;                                        
## [250] &amp;quot;Waypoint: Ditch Custom CSS for Bootstrap&amp;quot;                                  
## [251] &amp;quot;Waypoint: Divide one Decimal by Another with JavaScript&amp;quot;                   
## [252] &amp;quot;Waypoint: Divide One Number by Another with JavaScript&amp;quot;                    
## [253] &amp;quot;Waypoint: Duplicate Instances of Objects from a Constructor Function&amp;quot;      
## [254] &amp;quot;Waypoint: Fill in the Blank with Placeholder Text&amp;quot;                         
## [255] &amp;quot;Waypoint: Filter Arrays with filter&amp;quot;                                       
## [256] &amp;quot;Waypoint: Find Numbers with Regular Expressions&amp;quot;                           
## [257] &amp;quot;Waypoint: Find White Space with Regular Expressions&amp;quot;                       
## [258] &amp;quot;Waypoint: Find Whitespace with Regular Expressions&amp;quot;                        
## [259] &amp;quot;Waypoint: Finish working with Node.js Servers&amp;quot;                             
## [260] &amp;quot;Waypoint: Finish working with Nodejs Servers&amp;quot;                              
## [261] &amp;quot;Waypoint: Generate Random Fractions with JavaScript&amp;quot;                       
## [262] &amp;quot;Waypoint: Generate Random Whole Numbers with JavaScript&amp;quot;                   
## [263] &amp;quot;Waypoint: Generate Random Whole Numbers within a Range&amp;quot;                    
## [264] &amp;quot;Waypoint: Get Geolocation Data&amp;quot;                                            
## [265] &amp;quot;Waypoint: Get Help the Hacker Way with RSAP&amp;quot;                               
## [266] &amp;quot;Waypoint: Get JSON with the jQuery getJSON Method&amp;quot;                         
## [267] &amp;quot;Waypoint: Get Set for Basejumps&amp;quot;                                           
## [268] &amp;quot;Waypoint: Get Set for Bonfires&amp;quot;                                            
## [269] &amp;quot;Waypoint: Get Set for Ziplines&amp;quot;                                            
## [270] &amp;quot;Waypoint: Get Started with Angular.js&amp;quot;                                     
## [271] &amp;quot;Waypoint: Get Started with Angularjs&amp;quot;                                      
## [272] &amp;quot;Waypoint: Get Started with jQuery&amp;quot;                                         
## [273] &amp;quot;Waypoint: Give a Background Color to a Div Element&amp;quot;                        
## [274] &amp;quot;Waypoint: Give Each Element a Unique ID&amp;quot;                                   
## [275] &amp;quot;Waypoint: Give your JavaScript Slot Machine some stylish images&amp;quot;           
## [276] &amp;quot;Waypoint: Give your JavaScript Slot Machine some Stylish Images&amp;quot;           
## [277] &amp;quot;Waypoint: Harness Dynamic HTML&amp;quot;                                            
## [278] &amp;quot;Waypoint: Headline with the h2 Element&amp;quot;                                    
## [279] &amp;quot;Waypoint: House our page within a Bootstrap Container Fluid Div&amp;quot;           
## [280] &amp;quot;Waypoint: Import a Google Font&amp;quot;                                            
## [281] &amp;quot;Waypoint: Inform with the Paragraph Element&amp;quot;                               
## [282] &amp;quot;Waypoint: Inherit Styles from the Body Element&amp;quot;                            
## [283] &amp;quot;Waypoint: Invert Regular Expression Matches with JavaScript&amp;quot;               
## [284] &amp;quot;Waypoint: Iterate Odd Numbers With a For Loop&amp;quot;                             
## [285] &amp;quot;Waypoint: Iterate over Arrays with map&amp;quot;                                    
## [286] &amp;quot;Waypoint: Iterate with JavaScript For Loops&amp;quot;                               
## [287] &amp;quot;Waypoint: Iterate with JavaScript While Loops&amp;quot;                             
## [288] &amp;quot;Waypoint: Join a Campsite in Your City&amp;quot;                                    
## [289] &amp;quot;Waypoint: Join our Alumni Network and Commit to Your Goal&amp;quot;                 
## [290] &amp;quot;Waypoint: Join Our Chat Room&amp;quot;                                              
## [291] &amp;quot;Waypoint: Join our LinkedIn Alumni Network&amp;quot;                                
## [292] &amp;quot;Waypoint: Join Strings with join&amp;quot;                                          
## [293] &amp;quot;Waypoint: Label Bootstrap Buttons&amp;quot;                                         
## [294] &amp;quot;Waypoint: Label Bootstrap Wells&amp;quot;                                           
## [295] &amp;quot;Waypoint: Learn Basic Computer Science&amp;quot;                                    
## [296] &amp;quot;Waypoint: Learn Boolean Logic&amp;quot;                                             
## [297] &amp;quot;Waypoint: Learn Computer Hardware&amp;quot;                                         
## [298] &amp;quot;Waypoint: Learn Computer Networking&amp;quot;                                       
## [299] &amp;quot;Waypoint: Learn Computer Security&amp;quot;                                         
## [300] &amp;quot;Waypoint: Learn Control Flow&amp;quot;                                              
## [301] &amp;quot;Waypoint: Learn how Free Code Camp Works&amp;quot;                                  
## [302] &amp;quot;Waypoint: Learn how Script Tags and Document Ready Work&amp;quot;                   
## [303] &amp;quot;Waypoint: Learn JavaScript For Loops&amp;quot;                                      
## [304] &amp;quot;Waypoint: Learn JavaScript While Loops&amp;quot;                                    
## [305] &amp;quot;Waypoint: Learn Loops&amp;quot;                                                     
## [306] &amp;quot;Waypoint: Learn Regular Expressions&amp;quot;                                       
## [307] &amp;quot;Waypoint: Learn What to Do If You Get Stuck&amp;quot;                               
## [308] &amp;quot;Waypoint: Line up Form Elements Responsively with Bootstrap&amp;quot;               
## [309] &amp;quot;Waypoint: Link to External Pages with Anchor Elements&amp;quot;                     
## [310] &amp;quot;Waypoint: Listen for jQuery Events&amp;quot;                                        
## [311] &amp;quot;Waypoint: Make Circular Images with a Border Radius&amp;quot;                       
## [312] &amp;quot;Waypoint: Make Dead Links using the Hash Symbol&amp;quot;                           
## [313] &amp;quot;Waypoint: Make Images Mobile Responsive&amp;quot;                                   
## [314] &amp;quot;Waypoint: Make Instances of Objects with a Constructor Function&amp;quot;           
## [315] &amp;quot;Waypoint: Make Object Properties Private&amp;quot;                                  
## [316] &amp;quot;Waypoint: Make Unique Objects by Passing Parameters to our Constructor&amp;quot;    
## [317] &amp;quot;Waypoint: Manage Packages with NPM&amp;quot;                                        
## [318] &amp;quot;Waypoint: Manage Source Code with Git&amp;quot;                                     
## [319] &amp;quot;Waypoint: Manipulate Arrays With pop&amp;quot;                                      
## [320] &amp;quot;Waypoint: Manipulate Arrays With push&amp;quot;                                     
## [321] &amp;quot;Waypoint: Manipulate Arrays With shift&amp;quot;                                    
## [322] &amp;quot;Waypoint: Manipulate Arrays With unshift&amp;quot;                                  
## [323] &amp;quot;Waypoint: Manipulate JavaScript Objects&amp;quot;                                   
## [324] &amp;quot;Waypoint: Meet Other Campers in your City&amp;quot;                                 
## [325] &amp;quot;Waypoint: Mobile Responsive Images&amp;quot;                                        
## [326] &amp;quot;Waypoint: Modify Array Data With Indexes&amp;quot;                                  
## [327] &amp;quot;Waypoint: Multiply Two Decimals with JavaScript&amp;quot;                           
## [328] &amp;quot;Waypoint: Multiply Two Numbers with JavaScript&amp;quot;                            
## [329] &amp;quot;Waypoint: Nest an Anchor Element within a Paragraph&amp;quot;                       
## [330] &amp;quot;Waypoint: Nest Many Elements within a Single Div Element&amp;quot;                  
## [331] &amp;quot;Waypoint: Nest one Array within Another Array&amp;quot;                             
## [332] &amp;quot;Waypoint: Override All Other Styles by using Important&amp;quot;                    
## [333] &amp;quot;Waypoint: Override Class Declarations by Styling ID Attributes&amp;quot;            
## [334] &amp;quot;Waypoint: Override Class Declarations with Inline Styles&amp;quot;                  
## [335] &amp;quot;Waypoint: Override Styles in Subsequent CSS&amp;quot;                               
## [336] &amp;quot;Waypoint: Override Styles with Important&amp;quot;                                  
## [337] &amp;quot;Waypoint: Pair Program on Bonfires&amp;quot;                                        
## [338] &amp;quot;Waypoint: Perform Arithmetic Operations on Decimals with JavaScript&amp;quot;       
## [339] &amp;quot;Waypoint: Power Forms with Angular.js&amp;quot;                                     
## [340] &amp;quot;Waypoint: Power Forms with Angularjs&amp;quot;                                      
## [341] &amp;quot;Waypoint: Practice Functional Programming&amp;quot;                                 
## [342] &amp;quot;Waypoint: Prefilter JSON&amp;quot;                                                  
## [343] &amp;quot;Waypoint: Preview our Challenge Map&amp;quot;                                       
## [344] &amp;quot;Waypoint: Prioritize One Style Over Another&amp;quot;                               
## [345] &amp;quot;Waypoint: Reference our Wiki&amp;quot;                                              
## [346] &amp;quot;Waypoint: Reference your Current Object with This&amp;quot;                         
## [347] &amp;quot;Waypoint: Remove an Element Using jQuery&amp;quot;                                  
## [348] &amp;quot;Waypoint: Remove Classes from an element with jQuery&amp;quot;                      
## [349] &amp;quot;Waypoint: Render Images from Data Sources&amp;quot;                                 
## [350] &amp;quot;Waypoint: Responsively Style a Radio Buttons&amp;quot;                              
## [351] &amp;quot;Waypoint: Responsively Style Checkboxes&amp;quot;                                   
## [352] &amp;quot;Waypoint: Responsively Style Radio Buttons&amp;quot;                                
## [353] &amp;quot;Waypoint: Reuse Code with Decorators&amp;quot;                                      
## [354] &amp;quot;Waypoint: Reverse Arrays with reverse&amp;quot;                                     
## [355] &amp;quot;Waypoint: Save your Code Revisions Forever with Git&amp;quot;                       
## [356] &amp;quot;Waypoint: Say Hello to HTML Elements&amp;quot;                                      
## [357] &amp;quot;Waypoint: Scope Your Variables&amp;quot;                                            
## [358] &amp;quot;Waypoint: Set the Font Family of an Element&amp;quot;                               
## [359] &amp;quot;Waypoint: Set the ID of an Element&amp;quot;                                        
## [360] &amp;quot;Waypoint: Sift through Text with Regular Expressions&amp;quot;                      
## [361] &amp;quot;Waypoint: Size your Images&amp;quot;                                                
## [362] &amp;quot;Waypoint: Sort Arrays with sort&amp;quot;                                           
## [363] &amp;quot;Waypoint: Specify How Fonts Should Degrade&amp;quot;                                
## [364] &amp;quot;Waypoint: Split Strings with split&amp;quot;                                        
## [365] &amp;quot;Waypoint: Split your Bootstrap Row&amp;quot;                                        
## [366] &amp;quot;Waypoint: Start a Node.js Server&amp;quot;                                          
## [367] &amp;quot;Waypoint: Start a Nodejs Server&amp;quot;                                           
## [368] &amp;quot;Waypoint: Store Data in MongoDB&amp;quot;                                           
## [369] &amp;quot;Waypoint: Store Multiple Values in one Variable using JavaScript Arrays&amp;quot;   
## [370] &amp;quot;Waypoint: Style Multiple Elements with a CSS Class&amp;quot;                        
## [371] &amp;quot;Waypoint: Style Multiple Elements with a CSS Classes&amp;quot;                      
## [372] &amp;quot;Waypoint: Style Text Inputs as Form Controls&amp;quot;                              
## [373] &amp;quot;Waypoint: Style the HTML Body Element&amp;quot;                                     
## [374] &amp;quot;Waypoint: Subclass one Object to Another&amp;quot;                                  
## [375] &amp;quot;Waypoint: Subtract One Number from Another with JavaScript&amp;quot;                
## [376] &amp;quot;Waypoint: Target a Specific Child of an Element Using jQuery&amp;quot;              
## [377] &amp;quot;Waypoint: Target Elements by Class Using jQuery&amp;quot;                           
## [378] &amp;quot;Waypoint: Target Elements by ID Using jQuery&amp;quot;                              
## [379] &amp;quot;Waypoint: Target Even Numbered Elements Using jQuery&amp;quot;                      
## [380] &amp;quot;Waypoint: Target HTML Elements with Selectors Using jQuery&amp;quot;                
## [381] &amp;quot;Waypoint: Target the Children of an Element Using jQuery&amp;quot;                  
## [382] &amp;quot;Waypoint: Target the Parent of an Element Using jQuery&amp;quot;                    
## [383] &amp;quot;Waypoint: Target the same element with multiple jQuery Selectors&amp;quot;          
## [384] &amp;quot;Waypoint: Taste the Bootstrap Button Color Rainbow&amp;quot;                        
## [385] &amp;quot;Waypoint: Traverse the Prototype Chain&amp;quot;                                    
## [386] &amp;quot;Waypoint: Trigger Click Events with jQuery&amp;quot;                                
## [387] &amp;quot;Waypoint: Trigger jQuery Effects&amp;quot;                                          
## [388] &amp;quot;Waypoint: Trigger on click Events with jQuery&amp;quot;                             
## [389] &amp;quot;Waypoint: Try Camper News&amp;quot;                                                 
## [390] &amp;quot;Waypoint: Turn an Image into a Link&amp;quot;                                       
## [391] &amp;quot;Waypoint: Uncomment HTML&amp;quot;                                                  
## [392] &amp;quot;Waypoint: Understand Boolean Values&amp;quot;                                       
## [393] &amp;quot;Waypoint: Understand Pseudoclassical Patterns&amp;quot;                             
## [394] &amp;quot;Waypoint: Understanding Public and Private Properties&amp;quot;                     
## [395] &amp;quot;Waypoint: Update the Properties of a JavaScript Object&amp;quot;                    
## [396] &amp;quot;Waypoint: Use a CSS Class to Style an Element&amp;quot;                             
## [397] &amp;quot;Waypoint: Use Abbreviated Hex Code&amp;quot;                                        
## [398] &amp;quot;Waypoint: Use an ID Attribute to Style an Element&amp;quot;                         
## [399] &amp;quot;Waypoint: Use appendTo to Move Elements with jQuery&amp;quot;                       
## [400] &amp;quot;Waypoint: Use Bracket Notation to Find the First Character in a String&amp;quot;    
## [401] &amp;quot;Waypoint: Use Bracket Notation to Find the Last Character in a String&amp;quot;     
## [402] &amp;quot;Waypoint: Use Bracket Notation to Find the Nth Character in a String&amp;quot;      
## [403] &amp;quot;Waypoint: Use Bracket Notation to Find the NthtoLast Character in a String&amp;quot;
## [404] &amp;quot;Waypoint: Use Clockwise Notation to Specify the Margin of an Element&amp;quot;      
## [405] &amp;quot;Waypoint: Use Clockwise Notation to Specify the Padding of an Element&amp;quot;     
## [406] &amp;quot;Waypoint: Use Comments to Clarify Code&amp;quot;                                    
## [407] &amp;quot;Waypoint: Use Conditional Logic with If and Else Statements&amp;quot;               
## [408] &amp;quot;Waypoint: Use Conditional Logic with IfElse Statements&amp;quot;                    
## [409] &amp;quot;Waypoint: Use CSS Selectors to Style Elements&amp;quot;                             
## [410] &amp;quot;Waypoint: Use Hex Code for Specific Colors&amp;quot;                                
## [411] &amp;quot;Waypoint: Use Hex Code for Specific Shades of Gray&amp;quot;                        
## [412] &amp;quot;Waypoint: Use Hex Code to Color Elements Blue&amp;quot;                             
## [413] &amp;quot;Waypoint: Use Hex Code to Color Elements Gray&amp;quot;                             
## [414] &amp;quot;Waypoint: Use Hex Code to Color Elements Green&amp;quot;                            
## [415] &amp;quot;Waypoint: Use Hex Code to Color Elements Red&amp;quot;                              
## [416] &amp;quot;Waypoint: Use Hex Code to Color Elements White&amp;quot;                            
## [417] &amp;quot;Waypoint: Use Hex Code to Mix Colors&amp;quot;                                      
## [418] &amp;quot;Waypoint: Use HTML5 to Require a Field&amp;quot;                                    
## [419] &amp;quot;Waypoint: Use jQuery to Modify the Entire Page&amp;quot;                            
## [420] &amp;quot;Waypoint: Use Pseudoclassical Subclasses&amp;quot;                                  
## [421] &amp;quot;Waypoint: Use Responsive Design with Bootstrap Fluid Containers&amp;quot;           
## [422] &amp;quot;Waypoint: Use RGB to Color Elements Blue&amp;quot;                                  
## [423] &amp;quot;Waypoint: Use RGB to Color Elements Gray&amp;quot;                                  
## [424] &amp;quot;Waypoint: Use RGB to Color Elements Green&amp;quot;                                 
## [425] &amp;quot;Waypoint: Use RGB to Color Elements Red&amp;quot;                                   
## [426] &amp;quot;Waypoint: Use RGB to Color Elements White&amp;quot;                                 
## [427] &amp;quot;Waypoint: Use RGB to Mix Colors&amp;quot;                                           
## [428] &amp;quot;Waypoint: Use RGB values to Color Elements&amp;quot;                                
## [429] &amp;quot;Waypoint: Use Spans for Inline Elements&amp;quot;                                   
## [430] &amp;quot;Waypoint: Use the Bootstrap Grid to Put Elements Side By Side&amp;quot;             
## [431] &amp;quot;Waypoint: Use the Javascript Console&amp;quot;                                      
## [432] &amp;quot;Waypoint: Using concat&amp;quot;                                                    
## [433] &amp;quot;Waypoint: Using filter&amp;quot;                                                    
## [434] &amp;quot;Waypoint: Using join&amp;quot;                                                      
## [435] &amp;quot;Waypoint: Using map&amp;quot;                                                       
## [436] &amp;quot;Waypoint: Using reduce&amp;quot;                                                    
## [437] &amp;quot;Waypoint: Using reverse&amp;quot;                                                   
## [438] &amp;quot;Waypoint: Using sort&amp;quot;                                                      
## [439] &amp;quot;Waypoint: Using split&amp;quot;                                                     
## [440] &amp;quot;Waypoint: Using typeof&amp;quot;                                                    
## [441] &amp;quot;Waypoint: Visually Separate Elements with Line Breaks&amp;quot;                     
## [442] &amp;quot;Waypoint: Warn your Users of a Dangerous Action&amp;quot;                           
## [443] &amp;quot;Waypoint: Wrap an Anchor Element within a Paragraph&amp;quot;                       
## [444] &amp;quot;Waypoint: Wrap Many Elements within a Div Element&amp;quot;                         
## [445] &amp;quot;Waypoint: Wrap Many Elements within a Single Div Element&amp;quot;                  
## [446] &amp;quot;Waypoint: Write Functions with jQuery&amp;quot;                                     
## [447] &amp;quot;Waypoint: Write Reusable JavaScript with Functions&amp;quot;                        
## [448] &amp;quot;Where art thou&amp;quot;                                                            
## [449] &amp;quot;Where do I belong&amp;quot;                                                         
## [450] &amp;quot;Write Functions with jQuery&amp;quot;                                               
## [451] &amp;quot;Zipline: Build a JavaScript Calculator&amp;quot;                                    
## [452] &amp;quot;Zipline: Build a Personal Portfolio Webpage&amp;quot;                               
## [453] &amp;quot;Zipline: Build a Pomodoro Clock&amp;quot;                                           
## [454] &amp;quot;Zipline: Build a Random Quote Machine&amp;quot;                                     
## [455] &amp;quot;Zipline: Build a Simon Game&amp;quot;                                               
## [456] &amp;quot;Zipline: Build a Tic Tac Toe Game&amp;quot;                                         
## [457] &amp;quot;Zipline: Build a Wikipedia Viewer&amp;quot;                                         
## [458] &amp;quot;Zipline: Show the Local Weather&amp;quot;                                           
## [459] &amp;quot;Zipline: Stylize Stories on Camper News&amp;quot;                                   
## [460] &amp;quot;Zipline: Use the Twitch.tv JSON API&amp;quot;                                       
## [461] &amp;quot;Zipline: Use the Twitchtv JSON API&amp;quot;                                        
## [462] &amp;quot;Zipline: Wikipedia Viewer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! So 462 challenges. A quick skim of the levels indicate that these data are pretty clean but it&amp;rsquo;s hard to tell if there are duplicates. There are definitely some NA values, and some labelled as &amp;ldquo;&amp;rdquo;. I&amp;rsquo;m going to remove those from this dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_df3 &amp;lt;- fcc_df2 %&amp;gt;% filter(!is.na(name)) %&amp;gt;% filter(!name == 
    &amp;quot;&amp;quot;) %&amp;gt;% droplevels()

# Validate that there are no more NA course names
sum(is.na(fcc_df3$name))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;ll deal more with the course names a bit later. One more thing before moving on; I&amp;rsquo;d like to separate the &amp;ldquo;name&amp;rdquo; column into &amp;ldquo;type&amp;rdquo; and course, splitting the course name at the &amp;ldquo;:&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Subset data frame to only include student entries where the
# course name has a &#39;:&#39; and separate course name into 2
# columns: type and course
fcc_sub1 &amp;lt;- fcc_df3 %&amp;gt;% filter(grepl(&amp;quot;\\:\\s&amp;quot;, name)) %&amp;gt;% separate(col = name, 
    into = c(&amp;quot;type&amp;quot;, &amp;quot;course&amp;quot;), sep = &amp;quot;: &amp;quot;)

# Subset data frame to only include student entries where
# course name does not have a &#39;:&#39;. Add a new &#39;type&#39; column
# filled with NA
fcc_sub2 &amp;lt;- fcc_df3 %&amp;gt;% filter(!grepl(&amp;quot;\\:\\s&amp;quot;, name)) %&amp;gt;% mutate(type = NA)

# Rename the &#39;name&#39; variable in the second subset to &#39;course&#39;
# (to match first subset)
fcc_sub2 &amp;lt;- rename(fcc_sub2, course = name)

# Bind subsets together
fcc_all &amp;lt;- rbind(fcc_sub1, fcc_sub2)

# Make both &#39;course&#39; and &#39;type&#39; factors
fcc_all$course &amp;lt;- as.factor(fcc_all$course)
fcc_all$type &amp;lt;- as.factor(fcc_all$type)

# Check structure of &#39;course&#39;
str(fcc_all$course)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  Factor w/ 370 levels &amp;quot;Access Array Data with Indexes&amp;quot;,..: 187 187 238 31 110 306 214 150 255 163 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect! That will make dealing with course names easier in the future, and it looks like it trimmed us down to 370 courses (some of them must have had duplicate names).&lt;/p&gt;

&lt;p&gt;While we&amp;rsquo;re at it, let&amp;rsquo;s clean up our completedDate variable; it should be a POSIXct object.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Convert characters to numeric
fcc_all$completedDate &amp;lt;- as.numeric(fcc_all$completedDate)

# Divide by 1000 to account for the numbers being in
# milliseconds
fcc_all$completedDate &amp;lt;- fcc_all[, &amp;quot;completedDate&amp;quot;]/1000

# Convert to POSIXct object
fcc_all$completedDate &amp;lt;- as.POSIXct((fcc_all$completedDate), 
    origin = &amp;quot;1970-01-01&amp;quot;, tz = &amp;quot;GMT&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Were all the dates coded correctly?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if any entries are recorded as being completed before FCC launched in October 2014.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;wrong_dates &amp;lt;- fcc_all %&amp;gt;% 
			filter(completedDate &amp;lt; &amp;quot;2014-10-01&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops! 19 of our entries have incorrectly coded dates. We&amp;rsquo;ll remove those from the dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_all &amp;lt;- fcc_all %&amp;gt;% 
	       filter(completedDate &amp;gt; &amp;quot;2014-10-01&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Do we have any NA values in our completedDate column? If so, we&amp;rsquo;ll remove those as well.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Count NA
sum(is.na(fcc_all$completedDate))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Remove NA
fcc_all &amp;lt;- fcc_all %&amp;gt;% 
	       filter(!is.na(completedDate))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so far so good. Let&amp;rsquo;s take another quick look at our structure.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(fcc_all)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    7216723 obs. of  5 variables:
##  $ .id          : Factor w/ 102882 levels &amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ type         : Factor w/ 6 levels &amp;quot;&amp;quot;,&amp;quot;Basejump&amp;quot;,..: 5 5 5 5 5 5 5 5 5 5 ...
##  $ course       : Factor w/ 370 levels &amp;quot;Access Array Data with Indexes&amp;quot;,..: 187 187 238 31 110 306 214 150 255 163 ...
##  $ completedDate: POSIXct, format: &amp;quot;2015-06-18 18:02:46&amp;quot; &amp;quot;2015-06-18 18:03:02&amp;quot; ...
##  $ solution     : chr  NA NA NA NA ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That looks much better!&lt;/p&gt;

&lt;h2 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h2&gt;

&lt;h3 id=&#34;using-original-dataset&#34;&gt;Using Original Dataset&lt;/h3&gt;

&lt;p&gt;There are a few things that I&amp;rsquo;m interested in that aren&amp;rsquo;t readily available from this dataset.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What order did each student complete the courses in?&lt;/li&gt;
&lt;li&gt;How long did it take for each student to finish one course and then complete another?&lt;/li&gt;
&lt;li&gt;Which class did each student take &lt;em&gt;before&lt;/em&gt; the current course and which did they take &lt;em&gt;after&lt;/em&gt;?&lt;/li&gt;
&lt;li&gt;Did students generally take FCC classes in the order that they are offered?&lt;/li&gt;
&lt;li&gt;Are the most frequently completed courses the ones offered at the beginning?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ll look at one student first:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I chose the second student because that student only completed 25 courses, a much more reasonable starting-point than the 226 completed by student #1&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;second_student &amp;lt;- fcc_all %&amp;gt;% 
			     filter(.id == &amp;quot;2&amp;quot;)

second_student
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    .id type                             course       completedDate
## 1    2 &amp;lt;NA&amp;gt;     Learn how Free Code Camp Works 2015-05-21 17:44:57
## 2    2 &amp;lt;NA&amp;gt;                 Join Our Chat Room 2015-05-21 17:58:10
## 3    2 &amp;lt;NA&amp;gt;          Preview our Challenge Map 2015-05-21 18:45:44
## 4    2 &amp;lt;NA&amp;gt;             Browse our Field Guide 2015-05-21 18:49:15
## 5    2 &amp;lt;NA&amp;gt;      Customize your Portfolio Page 2015-05-21 19:06:19
## 6    2 &amp;lt;NA&amp;gt;                    Try Camper News 2015-05-21 19:22:35
## 7    2 &amp;lt;NA&amp;gt;    Meet Other Campers in your City 2015-05-21 19:45:10
## 8    2 &amp;lt;NA&amp;gt;  Get Help the Hacker Way with RSAP 2015-05-21 19:46:43
## 9    2 &amp;lt;NA&amp;gt;     Build a Landing Page with HTML 2015-05-22 14:40:57
## 10   2 &amp;lt;NA&amp;gt;                Style Text with CSS 2015-05-22 14:41:30
## 11   2 &amp;lt;NA&amp;gt;                 Space Out with CSS 2015-05-22 14:47:10
## 12   2 &amp;lt;NA&amp;gt;          Design a Layout with HTML 2015-05-22 14:49:57
## 13   2 &amp;lt;NA&amp;gt; Design Responsively with Bootstrap 2015-05-22 14:56:51
## 14   2 &amp;lt;NA&amp;gt;            Get Started with jQuery 2015-05-22 14:57:21
## 15   2 &amp;lt;NA&amp;gt;        Write Functions with jQuery 2015-05-22 15:10:05
## 16   2 &amp;lt;NA&amp;gt;               Harness Dynamic HTML 2015-05-22 15:31:01
## 17   2 &amp;lt;NA&amp;gt;           Listen for jQuery Events 2015-05-22 15:31:32
## 18   2 &amp;lt;NA&amp;gt;             Trigger jQuery Effects 2015-05-22 16:02:40
## 19   2 &amp;lt;NA&amp;gt;       Learn Basic Computer Science 2015-05-22 17:37:14
## 20   2 &amp;lt;NA&amp;gt;                        Learn Loops 2015-05-22 17:37:28
## 21   2 &amp;lt;NA&amp;gt;            Learn Computer Hardware 2015-05-24 22:20:35
## 22   2 &amp;lt;NA&amp;gt;          Learn Computer Networking 2015-05-25 22:03:14
## 23   2 &amp;lt;NA&amp;gt;                Learn Boolean Logic 2015-05-26 01:48:40
## 24   2 &amp;lt;NA&amp;gt;            Learn Computer Security 2015-05-26 02:07:25
## 25   2 &amp;lt;NA&amp;gt;                       Meet Bonfire 2015-05-22 00:15:04
##                                                                                                                                                                                                    solution
## 1                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 2                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 3                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 4                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 5                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 6                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 7                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 8                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 9                                                                                                                                                                                                      &amp;lt;NA&amp;gt;
## 10                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 11                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 12                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 13                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 14                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 15                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 16                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 17                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 18                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 19                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 20                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 21                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 22                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 23                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 24                                                                                                                                                                                                     &amp;lt;NA&amp;gt;
## 25 function meetBonfire(argument) {\n  // Good luck!\n  console.log(&amp;quot;you can read this function&#39;s argument in the developer tools&amp;quot;, argument);\n\n  return true;\n}\n\n\n\nmeetBonfire(&amp;quot;You can do this!&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So the second student in our list completed 25 courses. I&amp;rsquo;m going to try extracting the information I want on this sub-sample first to ensure that it&amp;rsquo;s behaving the way I&amp;rsquo;d expect before using it to generate information for 102,000 students.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;second_student_2 &amp;lt;- second_student %&amp;gt;% 
		group_by(.id) %&amp;gt;% 
		arrange(completedDate) %&amp;gt;% 
    		mutate(st_cour_num = rank(completedDate), 
			    time_since_last = completedDate - lag(completedDate), 
			    from_type = lag(type), 
			    from_course = lag(course), 
        			    to_type = lead(type), 
			    to_course = lead(course))

head(second_student_2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [6 x 11]
## Groups: .id [1]
## 
##      .id   type                         course       completedDate
##   &amp;lt;fctr&amp;gt; &amp;lt;fctr&amp;gt;                         &amp;lt;fctr&amp;gt;              &amp;lt;dttm&amp;gt;
## 1      2     NA Learn how Free Code Camp Works 2015-05-21 17:44:57
## 2      2     NA             Join Our Chat Room 2015-05-21 17:58:10
## 3      2     NA      Preview our Challenge Map 2015-05-21 18:45:44
## 4      2     NA         Browse our Field Guide 2015-05-21 18:49:15
## 5      2     NA  Customize your Portfolio Page 2015-05-21 19:06:19
## 6      2     NA                Try Camper News 2015-05-21 19:22:35
## # ... with 7 more variables: solution &amp;lt;chr&amp;gt;, st_cour_num &amp;lt;dbl&amp;gt;,
## #   time_since_last &amp;lt;time&amp;gt;, from_type &amp;lt;fctr&amp;gt;, from_course &amp;lt;fctr&amp;gt;,
## #   to_type &amp;lt;fctr&amp;gt;, to_course &amp;lt;fctr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! That works just as we&amp;rsquo;d expect. Let&amp;rsquo;s make sure it doesn&amp;rsquo;t do anything strange when there are more than one student.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;second_third &amp;lt;- fcc_all %&amp;gt;% 
			 filter(.id %in% c(&amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;)) %&amp;gt;% 
    			 group_by(.id) %&amp;gt;% 
			 arrange(completedDate) %&amp;gt;% 
			 mutate(st_cour_num = rank(completedDate, ties.method = &amp;quot;first&amp;quot;), 
			 	     time_since_last = completedDate - lag(completedDate), 
				     from_type = lag(type), 
				     from_course = lag(course), 
				     to_type = lead(type), 
				     to_course = lead(course))

second_third &amp;lt;- second_third %&amp;gt;% 
			 arrange(.id, st_cour_num)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So far so good. Let&amp;rsquo;s check rows 25 - 27 to make sure our counts started over again with a new student.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;second_third[25:27, c(&amp;quot;.id&amp;quot;, &amp;quot;st_cour_num&amp;quot;)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [3 x 2]
## Groups: .id [2]
## 
##      .id st_cour_num
##   &amp;lt;fctr&amp;gt;       &amp;lt;int&amp;gt;
## 1      2          25
## 2      3           1
## 3      3           2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect! We will apply this to the entire data structure, but I want to modify a few more things first.&lt;/p&gt;

&lt;h3 id=&#34;web-scraping-new-data&#34;&gt;Web Scraping New Data&lt;/h3&gt;

&lt;p&gt;I wonder if the most commonly taken courses are the ones offered at the beginning of the Free Code Camp program. To find out, I&amp;rsquo;m going to scrape the information from an archived version of the FCC course map from January 2016 (approximately 2 weeks after this dataset was released). I&amp;rsquo;ll use the &lt;code&gt;rvest&lt;/code&gt; package for this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;url &amp;lt;- &amp;quot;https://web.archive.org/web/20160101182240/http://www.freecodecamp.com/map#getting-started&amp;quot;
webpage &amp;lt;- read_html(curl(url, handle = curl::new_handle(useragent = &amp;quot;Chrome&amp;quot;)))

course_table &amp;lt;- html_nodes(webpage, &amp;quot;.col-md-offset-2 &amp;gt; .row .col-md-9&amp;quot;)
course_table2 &amp;lt;- html_text(course_table)
course_table2 &amp;lt;- as.data.frame(course_table2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a list of the courses in the order that FCC has them on their map. I&amp;rsquo;m going to add a few columns to this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What section of the FCC course map did this course come from?&lt;/li&gt;
&lt;li&gt;What number course is this inside each section and inside the entire map?&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;course_table3 &amp;lt;- course_table2 %&amp;gt;% 
	mutate(section = ifelse(row_number() %in% 1:5, &amp;quot;Getting Started&amp;quot;, 
ifelse(row_number() %in% 6:73, &amp;quot;HTML5 and CSS&amp;quot;, 
    ifelse(row_number() %in% 74:104, &amp;quot;Responsive Design with Bootstrap&amp;quot;, 
        ifelse(row_number() %in% 105:108, &amp;quot;Gear up for Success&amp;quot;, 
            ifelse(row_number() %in% 109:126, &amp;quot;jQuery&amp;quot;, ifelse(row_number() %in% 127:230, &amp;quot;Basic JavaScript&amp;quot;, 
            ifelse(row_number() %in% 231:243, &amp;quot;Object Oriented and Functional Programming&amp;quot;, 
                ifelse(row_number() %in% 244:260, &amp;quot;Basic Algorithm Scripting&amp;quot;, 
                  ifelse(row_number() %in% 261:265, &amp;quot;Basic Front End Development Projects&amp;quot;, 
                    ifelse(row_number() %in% 266:286, &amp;quot;Intermediate Algorithm Scripting&amp;quot;, 
                      ifelse(row_number() %in% 287:293, &amp;quot;JSON APIs and Ajax&amp;quot;, 
                        ifelse(row_number() %in% 294:299, &amp;quot;Intermediate Front End Development Projects&amp;quot;, 
                          ifelse(row_number() == 300, &amp;quot;Claim Your Front End Development Certificate&amp;quot;, 
                            ifelse(row_number() == 301, &amp;quot;Sass&amp;quot;, 
                              ifelse(row_number() == 302, &amp;quot;React&amp;quot;, 
                                ifelse(row_number() %in% 303:307, &amp;quot;React Projects&amp;quot;, 
                                ifelse(row_number() == 308, &amp;quot;D3&amp;quot;, 
                                 ifelse(row_number() %in% 309:313, &amp;quot;Data Visualization Projects&amp;quot;, 
                                    ifelse(row_number() == 314, &amp;quot;Claim Your Data Visualization Certificate&amp;quot;, 
                                      ifelse(row_number() %in% 315:317, &amp;quot;Upper Intermediate Algorithm Scripting&amp;quot;, 
                                        ifelse(row_number() %in% 318:319, &amp;quot;Automated Testing and Debugging&amp;quot;, 
                                          ifelse(row_number() %in%  320:325, &amp;quot;Advanced Algorithm Scripting&amp;quot;, 
                                            ifelse(row_number() %in% 326:330, &amp;quot;Node.js and Express.js&amp;quot;, 
                                              ifelse(row_number() ==  331, &amp;quot;Git&amp;quot;, 
                                              ifelse(row_number() == 332, &amp;quot;MongoDB&amp;quot;,  
                                              ifelse(row_number() %in% 333:338, &amp;quot;API Projects&amp;quot;, 
                                                  ifelse(row_number() %in%  339:343,  &amp;quot;Dynamic Web Applications&amp;quot;, 
                                                    ifelse(row_number() ==  344, &amp;quot;Claim Your Back End Development Certificate&amp;quot;, 
                                                      NA))))))))))))))))))))))))))))) %&amp;gt;% 
    group_by(section) %&amp;gt;% mutate(coursenum = row_number()) %&amp;gt;% 
    ungroup %&amp;gt;% mutate(overallnum = row_number())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I do plan to join this data table with the student data that we already have, but currently, the names won&amp;rsquo;t match. Let&amp;rsquo;s clean it up a bit.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Rename column
course_table3 &amp;lt;- rename(course_table3, course = course_table2)

# Remove everything after (and including) the phrase &amp;quot;incomplete&amp;quot; from course column
course_table3$course &amp;lt;- gsub(&amp;quot;(.*?)Incomplete.*&amp;quot;, &amp;quot;\\1&amp;quot;, course_table3$course)

# Separate the course column into Type and Course columns. 
course_table3 &amp;lt;- separate(course_table3, col = course, into = c(&amp;quot;type&amp;quot;, &amp;quot;course&amp;quot;), sep = &amp;quot;: &amp;quot;)

# Capitalize the first letter of type column
course_table3$type &amp;lt;- capitalize(course_table3$type) 

# Remove trailing space from course column
course_table3$course &amp;lt;- gsub(&amp;quot;\\s$&amp;quot;, &amp;quot;&amp;quot;, course_table3$course)

# Recode words that are entered differently in the original dataset
course_table4 &amp;lt;- course_table3 %&amp;gt;% 
                  mutate(course = gsub(&amp;quot;(.*?)\\.(.*?)&amp;quot;, &amp;quot;\\1\\2&amp;quot;, course),       # Removing the &amp;quot;.&amp;quot; at beginning of words
                         course = gsub(&amp;quot;(.*?)\\(\\).*&amp;quot;, &amp;quot;\\1&amp;quot;, course),          # Removing () at the end of pop(), shift() etc.
                         course = gsub(&amp;quot;Nth\\-to\\-Last&amp;quot;, &amp;quot;NthtoLast&amp;quot;, course),  # Removing hyphens     
                         course = gsub(&amp;quot;Geo-location&amp;quot;, &amp;quot;Geolocation&amp;quot;, course),   # Remove hyphen from Geo-location
                         course = gsub(&amp;quot;Node(\\s)js|Nodejs&amp;quot;, &amp;quot;Node\\.js&amp;quot;, course),
                         course = gsub(&amp;quot;Expressjs|Express js&amp;quot;, &amp;quot;Express\\.js&amp;quot;, course))       

# Remove trailing space from course column
course_table4$course &amp;lt;- gsub(&amp;quot;\\s$&amp;quot;, &amp;quot;&amp;quot;, course_table4$course)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, any other non-matches come from errors in our original dataset or courses whose name was different (or that no longer existed) when this dataset was published.&lt;/p&gt;

&lt;p&gt;Here are a few quick fixes to the original dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fcc_all2 &amp;lt;- fcc_all %&amp;gt;% 
		mutate(course = recode(course, `Add Font Awesome Icons all of our Buttons` = &amp;quot;Add Font Awesome Icons to all of our Buttons&amp;quot;), 
    course = gsub(&amp;quot;Pintrest&amp;quot;, &amp;quot;Pinterest&amp;quot;, course), course = gsub(&amp;quot;Node(\\s)js|Nodejs&amp;quot;, 
        &amp;quot;Node\\.js&amp;quot;, course), course = gsub(&amp;quot;Build Web Apps with Expressjs|Build Web Apps with Express\\.js|Build Web Apps with Express js&amp;quot;, 
        &amp;quot;Build Web Apps with Express\\.js&amp;quot;, course), course = recode(course, 
        `Add Free Code Camp to your LinkedIn Profile` = &amp;quot;Join our LinkedIn Alumni Network&amp;quot;), 
    course = recode(course, `Add Different a Margin to Each Side of an Element` = &amp;quot;Add Different Margins to Each Side of an Element&amp;quot;), 
    course = recode(course, `Check the Length Property of a String Variable` = &amp;quot;Find the Length of a String&amp;quot;), 
    course = gsub(&amp;quot;\\.concat&amp;quot;, &amp;quot;concat&amp;quot;, course), course = gsub(&amp;quot;White Space&amp;quot;, 
        &amp;quot;Whitespace&amp;quot;, course), course = recode(course, `Learn JavaScript For Loops` = &amp;quot;Iterate with JavaScript For Loops&amp;quot;), 
    course = recode(course, `Learn JavaScript While Loops` = &amp;quot;Iterate with JavaScript While Loops&amp;quot;), 
    course = recode(course, `Mobile Responsive Images` = &amp;quot;Make Images Mobile Responsive&amp;quot;), 
    course = recode(course, `Override Styles with Important` = &amp;quot;Override All Other Styles by using Important&amp;quot;), 
    course = recode(course, `Style Multiple Elements with a CSS Classes` = &amp;quot;Style Multiple Elements with a CSS Class&amp;quot;), 
    course = recode(course, `Trigger jQuery Effects` = &amp;quot;Trigger Click Events with jQuery&amp;quot;), 
    course = recode(course, `Trigger on click Events with jQuery` = &amp;quot;Trigger Click Events with jQuery&amp;quot;), 
    course = recode(course, `Try Camper News` = &amp;quot;Browse Camper News&amp;quot;), 
    course = recode(course, `Update the Properties of a JavaScript Object` = &amp;quot;Updating Object Properties&amp;quot;), 
    course = recode(course, `Use Conditional Logic with If and Else Statements` = &amp;quot;Use Conditional Logic with If Statements&amp;quot;), 
    course = recode(course, `Use Conditional Logic with IfElse Statements` = &amp;quot;Use Conditional Logic with If Statements&amp;quot;), 
    course = gsub(&amp;quot;twitch\\.tv&amp;quot;, &amp;quot;twitchtv&amp;quot;, course), course = recode(course, 
        `Wikipedia Viewer` = &amp;quot;Build a Wikipedia Viewer&amp;quot;), course = recode(course, 
        `Wrap an Anchor Element within a Paragraph` = &amp;quot;Nest an Anchor Element within a Paragraph&amp;quot;), 
    course = recode(course, `Wrap Many Elements within a Div Element` = &amp;quot;Nest Many Elements within a Single Div Element&amp;quot;), 
    course = recode(course, `Wrap Many Elements within a Single Div Element` = &amp;quot;Nest Many Elements within a Single Div Element&amp;quot;))

# Remove trailing space from course column
fcc_all2$course &amp;lt;- gsub(&amp;quot;\\s$&amp;quot;, &amp;quot;&amp;quot;, fcc_all2$course)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to join the two dataframes based on the &amp;ldquo;course&amp;rdquo; column.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sc_full &amp;lt;- left_join(fcc_all2, course_table4, by = &amp;quot;course&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How many of our entries are still missing a &amp;ldquo;section&amp;rdquo; label?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sum(is.na(sc_full$section))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 539128
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s 539,128 entries (or about 7.5% of our entire dataset). I checked the following subset of data (only focused on entries with an &amp;ldquo;NA&amp;rdquo; in &lt;code&gt;section&lt;/code&gt;), and then returned to code above to adjust the names of courses as necessary. Any remaining unmatched courses at this point were not on the FCC course map at the end of 2015, and thus will be removed from this dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Filter only entries with NA sections
sub_na &amp;lt;- sc_full %&amp;gt;% filter(is.na(section)) %&amp;gt;% group_by(course) %&amp;gt;% 
    summarise(count = n())

# Remove anything that still has missing section values
sc_full2 &amp;lt;- sc_full %&amp;gt;% filter(!is.na(section))

# Remove the original dataset&#39;s &#39;Type&#39; column in exchange for
# the amended &#39;Type column&#39;
sc_full3 &amp;lt;- sc_full2 %&amp;gt;% select(-2)

sc_full3 &amp;lt;- rename(sc_full3, type = type.y)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;engineered-variables&#34;&gt;Engineered Variables&lt;/h3&gt;

&lt;p&gt;Perfect! Now our data frame is all set to add other variables.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sc_full4 &amp;lt;- sc_full3 %&amp;gt;% group_by(.id) %&amp;gt;% arrange(completedDate) %&amp;gt;% 
    mutate(st_cour_num = rank(completedDate, ties.method = &amp;quot;first&amp;quot;), 
        time_since_last = completedDate - lag(completedDate), 
        from_type = lag(type), from_course = lag(course), from_section = lag(section), 
        to_type = lead(type), to_course = lead(course), to_section = lead(section)) %&amp;gt;% 
    ungroup()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at the top few data entries.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(sc_full4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 17
##      .id       course       completedDate
##   &amp;lt;fctr&amp;gt;        &amp;lt;chr&amp;gt;              &amp;lt;dttm&amp;gt;
## 1    954 Meet Bonfire 2015-01-28 06:41:03
## 2    954 Meet Bonfire 2015-01-28 06:41:03
## 3    954 Meet Bonfire 2015-01-28 06:41:03
## 4    954 Meet Bonfire 2015-01-28 06:41:03
## 5    954 Meet Bonfire 2015-01-28 06:41:03
## 6    954 Meet Bonfire 2015-01-28 06:41:03
## # ... with 14 more variables: solution &amp;lt;chr&amp;gt;, X &amp;lt;int&amp;gt;, type &amp;lt;chr&amp;gt;,
## #   section &amp;lt;chr&amp;gt;, coursenum &amp;lt;int&amp;gt;, overallnum &amp;lt;int&amp;gt;, st_cour_num &amp;lt;int&amp;gt;,
## #   time_since_last &amp;lt;time&amp;gt;, from_type &amp;lt;chr&amp;gt;, from_course &amp;lt;chr&amp;gt;,
## #   from_section &amp;lt;chr&amp;gt;, to_type &amp;lt;chr&amp;gt;, to_course &amp;lt;chr&amp;gt;, to_section &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Now that I have the following variables to work with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.id&lt;/strong&gt; : Individual student ID number (generated from JSON)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;course&lt;/strong&gt; : Course name (cleaned to match course map from Jan 2016)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;completedDate&lt;/strong&gt; : The POSIXct date and time that a course was completed by a student&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;solution&lt;/strong&gt; : The student&amp;rsquo;s solution to a given problem&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;type&lt;/strong&gt; : The type of course (Basejump, Bonfire, Waypoint, Zipline)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;section&lt;/strong&gt; :The specific section that each course falls into on the course map (&amp;ldquo;Getting Started&amp;rdquo;, &amp;ldquo;HTML5 and CSS&amp;rdquo;, etc.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;coursenum&lt;/strong&gt; : The number of the course within each section&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;overallnum&lt;/strong&gt; :The number of the course within the entire curriculum&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;st_cour_num&lt;/strong&gt; : The number of the course within each student&amp;rsquo;s specific journey (i.e., a student&amp;rsquo;s first completed class would be 1, 2nd completed class would be 2, etc.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;time_since_last&lt;/strong&gt; : The time between the completion of the current course and the completion of the last course (in seconds)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;from_type&lt;/strong&gt; : The type of class that was taken immediately before the present class (Basejump, Bonfire, Waypoint, Zipline)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;from_course&lt;/strong&gt; : The name of the class that was taken immediately before the present class&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;from_section&lt;/strong&gt; : The section of the course curriculum that the last class taken was in&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to_type&lt;/strong&gt; : The type of class that was taken immediately after the present class (Basejump, Bonfire, Waypoint, Zipline)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to_course&lt;/strong&gt; : The name of the class that was taken immediately after the present class&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;to_section&lt;/strong&gt; : The section of the course curriculum that the next class is in&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;data-visualizations&#34;&gt;Data Visualizations&lt;/h2&gt;

&lt;p&gt;Now that I have my variables sorted and my data cleaned, let&amp;rsquo;s try to answer a few simple questions.&lt;/p&gt;

&lt;h3 id=&#34;what-class-do-fcc-students-start-with&#34;&gt;What class do FCC students start with?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Does every student start with the same class?&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Separate out first courses
first &amp;lt;- sc_full4 %&amp;gt;% 
	   filter(st_cour_num == 1) %&amp;gt;% 
	   droplevels()

# How many different courses were the first ones taken?
length(unique(sc_full4))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 17
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like most users start in the same place. Let&amp;rsquo;s see how the popularity of first courses breaks down.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Count number of students for each course first
first_2 &amp;lt;- first %&amp;gt;% group_by(course) %&amp;gt;% summarise(n = n()) %&amp;gt;% 
    ungroup() %&amp;gt;% mutate(rank = dense_rank(desc(n))) %&amp;gt;% filter(rank &amp;lt;= 
    10) %&amp;gt;% arrange(rank)

fig1 &amp;lt;- hchart(first_2, &amp;quot;column&amp;quot;, x = course, y = n, zoomType = &amp;quot;x&amp;quot;) %&amp;gt;% 
    hc_xAxis(title = list(text = &amp;quot;First Completed Course on FCC&amp;quot;)) %&amp;gt;% 
    hc_yAxis(title = list(text = &amp;quot;Number of Students&amp;quot;), max = 50000) %&amp;gt;% 
    hc_chart(zoomType = &amp;quot;x&amp;quot;)

fig1
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig1/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;So about 48% of users start with the very first course in the curriculum &amp;ldquo;Learn How Free Code Camp Works&amp;rdquo;, another 10% skip straight to the first course in the &amp;ldquo;HTML5 and CSS&amp;rdquo; section to start their FCC journey. The remaining 42% of users started their first class on random courses throughout the curriculum.&lt;/p&gt;

&lt;h3 id=&#34;which-classes-are-the-most-popular&#34;&gt;Which classes are the most popular?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;How many students completed each course at some point?

&lt;ul&gt;
&lt;li&gt;Note: This figure is zoom-able!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pop_fig &amp;lt;- sc_full4 %&amp;gt;% 
		group_by(overallnum, section, course) %&amp;gt;% 
    		summarise(count = n()) %&amp;gt;% 
		arrange(overallnum) %&amp;gt;% ungroup()


# Plot
fig2 &amp;lt;- hchart(pop_fig, &amp;quot;column&amp;quot;, x = course, y = count, color = section) %&amp;gt;% 
    hc_title(text = &amp;quot;Course Completion in Curriculum Order&amp;quot;) %&amp;gt;% 
    hc_xAxis(title = list(text = &amp;quot;Completed Course on FCC (in order of FCC course curriculum)&amp;quot;)) %&amp;gt;% 
    hc_yAxis(title = list(text = &amp;quot;Number of Students&amp;quot;), max = 1e+05) %&amp;gt;% 
    hc_chart(zoomType = &amp;quot;xy&amp;quot;) %&amp;gt;% 
    hc_tooltip(headerFormat = &amp;quot;&amp;quot;, 
    	pointFormat = &amp;quot;&amp;lt;b&amp;gt;Class: {point.course}&amp;lt;/b&amp;gt; &amp;lt;br&amp;gt;
    	Section: {point.section}&amp;lt;br&amp;gt;
    	Number of Students: {point.y}&amp;quot;)

fig2
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig2/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;It definitely seems like the courses offered earlier in the curriculum are completed more frequently than courses offered later in the curriculum. There is also a spike in course completion at the beginning of the &amp;ldquo;HTML5 and CSS&amp;rdquo; and &amp;ldquo;Responsive Design with Boostrap&amp;rdquo; sections that declines throughout the course section. In the latter, that drop-off seems to happen sharply after the course &amp;ldquo;Line up Form Elements Responsively with Bootstrap&amp;rdquo; where almost 11,000 did not complete the next course.&lt;/p&gt;

&lt;p&gt;I wonder how the amount of time spent on courses changes throughout the curriculum, as courses (theoretically) get more difficult.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For this figure, I eliminated all course completion times that were over 1,210,000 seconds (14 days).&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;time_spent &amp;lt;- sc_full4 %&amp;gt;% 
			group_by(overallnum, section, course) %&amp;gt;% 
    			filter(!is.na(time_since_last)) %&amp;gt;% 
			filter(time_since_last &amp;lt; 1210000) %&amp;gt;% 
			mutate(time_since_last_m = time_since_last/60) %&amp;gt;% 
    			summarise(median = median(time_since_last_m), 
					  mean = mean(time_since_last_m), 
        					  sd = sd(time_since_last_m))

fig3 &amp;lt;- hchart(time_spent, &amp;quot;column&amp;quot;, x = course, y = mean, color = section) %&amp;gt;% 
    hc_title(text = &amp;quot;Average Time for Course Completion&amp;quot;) %&amp;gt;% 
    hc_subtitle(text = &amp;quot;&amp;lt;i&amp;gt;Does not contain course completion for students&#39; first class&amp;lt;/i&amp;gt;&amp;quot;) %&amp;gt;% 
    hc_xAxis(title = list(text = &amp;quot;Completed Course on FCC (in order of FCC course curriculum)&amp;quot;)) %&amp;gt;% 
    hc_yAxis(title = list(text = &amp;quot;Mean Time to Course Completion (minutes)&amp;quot;), 
        max = 6800) %&amp;gt;% hc_chart(zoomType = &amp;quot;xy&amp;quot;) %&amp;gt;% hc_tooltip(headerFormat = &amp;quot;&amp;quot;, 
    pointFormat = &amp;quot;&amp;lt;b&amp;gt;Class: {point.course}&amp;lt;/b&amp;gt; &amp;lt;br&amp;gt;Section: {point.section}&amp;lt;br&amp;gt;Mean time to completion: {point.y} minutes&amp;quot;, 
    valueDecimals = 2)

fig3
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig3/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;The class that took the longest to complete (&amp;ldquo;Claim Your Backend Development Certificate&amp;rdquo; with average 6845 minutes or 4.75 days) is the last and one of the least popular courses in the curriculum. It is possible that students completed all of the other courses and returned to FCC days later to claim their certificate.&lt;/p&gt;

&lt;p&gt;The next courses that took the longest to complete were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Build a Voting App (6675 minutes or 4.6 days)&lt;/li&gt;
&lt;li&gt;Build a Nightlife Coordination App (4861 minutes or 3.4 days)&lt;/li&gt;
&lt;li&gt;Use the Twitchtv JSON API (4289 minutes or 3 days)&lt;/li&gt;
&lt;li&gt;Build a Simon Game (4280 minutes or 3 days)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These courses either came immediately after a break (that was less than two weeks in duration) for many students or took students longer on these courses than others in the curriculum.  It may be worth investigating how long each of these projects is projected to take.&lt;/p&gt;

&lt;h3 id=&#34;how-do-students-flow-through-the-courses&#34;&gt;How do students flow through the courses?&lt;/h3&gt;

&lt;p&gt;Originally, I planned to depict student flow through the various FCC courses using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Sankey_diagram&#34;&gt;Sankey plot&lt;/a&gt;, but with so many courses in the curriculum this did not seem like a good option. I decided to visualize student course map as a network using the &lt;code&gt;igraph&lt;/code&gt; and &lt;code&gt;highcharter&lt;/code&gt; packages. Below, color indicates the section of each course, connections indicate flow of students from one course to another and the thickness of each connection indicates how many students followed that path. The size of each circle indicates how many students have taken each course.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hover over any point for more information and zoom in on sections for clearer detail&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nodes &amp;lt;- sc_full4 %&amp;gt;% 
		group_by(course, section, overallnum) %&amp;gt;% 
    		summarise(count = n()) %&amp;gt;% 
		ungroup()

edges &amp;lt;- sc_full4 %&amp;gt;% 
		group_by(from_course, to_course) %&amp;gt;% 
		summarise(weight = n()) %&amp;gt;% 
    		filter(!is.na(to_course), !is.na(from_course)) %&amp;gt;% 
		ungroup() %&amp;gt;% 
    		filter(weight &amp;gt; 200)
        

# Make graph object
net &amp;lt;- graph.data.frame(edges, nodes, directed = FALSE)

V(net)$color &amp;lt;- colorize(V(net)$section)
V(net)$size &amp;lt;- V(net)$count
E(net)$width &amp;lt;- E(net)$weight/4000
V(net)$Course_Number &amp;lt;- nodes$overallnum

# Plot graph using highcharter
set.seed(10)
fig4 &amp;lt;- hchart(net, minSize = 3, maxSize = 20, layout = layout_nicely)

fig4
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig4/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;There are several notable things about this figure:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &amp;ldquo;Getting Started&amp;rdquo; section is the &amp;ldquo;jumping off point&amp;rdquo; for many different tracks&lt;/li&gt;
&lt;li&gt;One of the most frequently used tracks runs through the HTML5 and CSS section&lt;/li&gt;
&lt;li&gt;Certain parts of the HTML5 and CSS section (i.e., the parts all about changing colors) are taken in order, while others skip entire chunks of the section (See the heavily followed path from class #8 (Inform with the Paragraph Element) and class #40 (Check radio buttons and checkboxes by default)).&lt;/li&gt;
&lt;li&gt;Users tend to flow straight from the jQuery section into Basic JavaScript following classes mostly in the recommended order&lt;/li&gt;
&lt;li&gt;Fewer users flow through the Intermediate and Advanced algorithm scripting sections than the Basic algorithm scripting section&lt;/li&gt;
&lt;li&gt;Several courses don&amp;rsquo;t follow any typical flow with the rest of the course curriculum. These courses seem to be treated as &amp;ldquo;stand-alone&amp;rdquo; courses instead of integrated parts of the map, but are also infrequently taken in general. These courses are:

&lt;ul&gt;
&lt;li&gt;Courses in the Node.js and Express.js section&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Get Set for Basejumps&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Save your code revisions forever with Git&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Courses in the Dynamic Web application section&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-many-courses-do-students-take&#34;&gt;How many courses do students take?&lt;/h3&gt;

&lt;p&gt;Given that there are 344 courses in the curriculum map that match the courses that these students have taken, how many does each student generally take?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;student_courses &amp;lt;- sc_full4 %&amp;gt;% 
		group_by(.id) %&amp;gt;% 
		mutate(time = as.numeric(time_since_last, units = &amp;quot;mins&amp;quot;)) %&amp;gt;% 
		summarise(count = n(), 
			total_time = sum(time, na.rm = TRUE), 
			median_time = median(time, na.rm = TRUE), 
    			average_time = mean(time, na.rm = TRUE)) %&amp;gt;% 
			mutate(time_per_class = (total_time/count)) %&amp;gt;% 
    			filter(count &amp;gt; 0)

fig5 &amp;lt;- hchart(student_courses$count) %&amp;gt;% 
	hc_title(text = &amp;quot;Number of Courses Completed&amp;quot;) %&amp;gt;% 
	hc_chart(zoomType = &amp;quot;xy&amp;quot;) %&amp;gt;% 
	hc_xAxis(title = list(text = &amp;quot;Number of Completed Courses&amp;quot;)) %&amp;gt;% 
   	hc_yAxis(title = list(text = &amp;quot;Number of Students&amp;quot;), max = 35000) %&amp;gt;% 
   	hc_legend(enabled = FALSE)

fig5
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig5/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;Wow! There&amp;rsquo;s a few things to point out here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The highest number of students (33,563 or 33% of students) completed only between 1 and 5 courses.&lt;/li&gt;
&lt;li&gt;The highest number of courses completed is 775! Since we&amp;rsquo;re only looking at 344 courses here, that&amp;rsquo;s a bit surprising. That student would have needed to complete almost every course twice! Is that the only student who has taken courses more than once?&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;multi_class &amp;lt;- student_courses %&amp;gt;% 
			filter(count &amp;gt; 344)

nrow(multi_class)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 219
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;219 students have taken more than the offered 344 courses and thus must have repeated some! It&amp;rsquo;s possible that the other students have repeated some courses too. I&amp;rsquo;ll come back to &lt;a href=&#34;#which-courses-tend-to-be-repeated-by-students&#34;&gt;that&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;can-you-group-students-based-on-the-number-of-classes-they-take-vs-the-amount-of-time-they-spend-per-class&#34;&gt;Can you group students based on the number of classes they take vs. the amount of time they spend per class?&lt;/h3&gt;

&lt;p&gt;The FCC folks who released this dataset seem interested in ways to group their students. I&amp;rsquo;m curious if this can be done by looking at the number of courses students have completed in comparison to the amount of time spent per course. Do students who complete classes more quickly tend to burn out quickly and ultimately take fewer courses?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;student_courses2 &amp;lt;- student_courses %&amp;gt;% 
		filter(count &amp;gt; 1)


ggplot(student_courses2, aes(x = count, y = median_time)) + geom_point(alpha = 1/4) + 
    labs(x = &amp;quot;Number of Completed Courses&amp;quot;, y = &amp;quot;Average time per Course (minutes)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../FCC_Courses_files/figure-markdown_github/unnamed-chunk-44-1.png&#34; class = &#34;img-responsive&#34; style = &#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This figure is a little overwhelmed with outliers who spent a very long time completing few courses.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d like to see what this looks like if students don&amp;rsquo;t take breaks between classes, so I&amp;rsquo;m going to remove any entries where the time to complete the course was greater than 14 days.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;student_no_break &amp;lt;- sc_full4 %&amp;gt;% 
		filter(overallnum &amp;gt; 5) %&amp;gt;% group_by(.id) %&amp;gt;% 
    		mutate(time = as.numeric(time_since_last, units = &amp;quot;mins&amp;quot;)) %&amp;gt;% 
    		summarise(count = n(), total_time = sum(time, na.rm = TRUE), 
        			median_time = median(time, na.rm = TRUE), 
			average_time = mean(time, na.rm = TRUE), 
			max_time = max(time, na.rm = TRUE)) %&amp;gt;% 
    		filter(count &amp;gt; 1, max_time &amp;lt; 20160) %&amp;gt;% 
		mutate(time_per_class = (total_time/count))

ggplot(student_no_break, aes(x = count, y = average_time)) + 
    geom_point(alpha = 1/4) + labs(x = &amp;quot;Number of Completed Courses&amp;quot;, 
    y = &amp;quot;Average time per Course (minutes)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../FCC_Courses_files/figure-markdown_github/unnamed-chunk-45-1.png&#34; class = &#34;img-responsive&#34; style = &#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Generally speaking, it looks like students who complete courses quickly (not including any breaks) complete the most courses overall. But what if we take breaks into account?&lt;/p&gt;

&lt;h3 id=&#34;does-taking-a-2-week-break-help-or-hurt-course-completion&#34;&gt;Does taking a 2 week break help or hurt course completion?&lt;/h3&gt;

&lt;p&gt;I wanted to look at a box plot of course completion depending on the number of breaks students completed.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;total_breaks &amp;lt;- sc_full4 %&amp;gt;% 
		group_by(.id) %&amp;gt;% 
		mutate(time = as.numeric(time_since_last, units = &amp;quot;mins&amp;quot;)) %&amp;gt;% 
		summarise(breaks = length(.id[time &amp;gt; 20160])) %&amp;gt;% 
		mutate(breaks = breaks - 1) %&amp;gt;% 
		ungroup()

breaks &amp;lt;- left_join(total_breaks, student_courses, by = &amp;quot;.id&amp;quot;)

multi_class_breaks &amp;lt;- breaks %&amp;gt;% 
		filter(count &amp;gt; 1)


fig6 &amp;lt;- highchart() %&amp;gt;% 
		hc_add_series_boxplot(multi_class_breaks$count, multi_class_breaks$breaks) %&amp;gt;% 	
		hc_xAxis(title = list(text = &amp;quot;Number of &amp;gt; 14 Day Breaks&amp;quot;)) %&amp;gt;% 
    		hc_yAxis(title = list(text = &amp;quot;Number of Completed Courses&amp;quot;), 
        			max = 500)

fig6
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig6/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;It seems possible that taking one or more 2 week breaks from the FCC program may actually have a positive impact on the number of courses completed. However, it is unclear at this time if any of those courses are repeats. Let&amp;rsquo;s try to take out repeat courses.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;no_repeats &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id) %&amp;gt;% 
	distinct(course) %&amp;gt;% 
    	summarise(nr_count = n()) %&amp;gt;% 
	ungroup()



no_repeat_join &amp;lt;- left_join(no_repeats, breaks, by = &amp;quot;.id&amp;quot;)

nr_multi &amp;lt;- no_repeat_join %&amp;gt;% filter(nr_count &amp;gt; 1)


fig7 &amp;lt;- highchart() %&amp;gt;% 
	hc_add_series_boxplot(nr_multi$nr_count, nr_multi$breaks) %&amp;gt;% 
	hc_xAxis(title = list(text = &amp;quot;Number of &amp;gt; 14 Day Breaks&amp;quot;)) %&amp;gt;% 
    	hc_yAxis(title = list(text = &amp;quot;Number of Completed Courses (Without Repeats)&amp;quot;), 
        			max = 300, 
			min = 0)

fig7
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig7/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;Even taking repeated courses out of the dataset seems to indicate that of students who completed more than one course, the presence of one or more 2 week breaks actually increases the median number of courses that will be completed. It may be worth encouraging students to take short breaks between classes if they feel they need to.&lt;/p&gt;

&lt;h3 id=&#34;which-courses-tend-to-be-repeated-by-students&#34;&gt;Which courses tend to be repeated by students?&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;repeats &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id, section, overallnum, course) %&amp;gt;% 
    	summarise(course_count = n()) %&amp;gt;% 
	ungroup() %&amp;gt;% 
	group_by(overallnum, section, course) %&amp;gt;% 
	summarise(student_repeats = n(), 
		avg_repeats = mean(course_count)) %&amp;gt;% 
    	arrange(overallnum)


fig8 &amp;lt;- hchart(repeats, &amp;quot;column&amp;quot;, x = course, y = avg_repeats, color = section) %&amp;gt;% 
	hc_title(text = &amp;quot;Average Number of Times a Single Student Completed Each Course&amp;quot;) %&amp;gt;% 
    	hc_subtitle(text = &amp;quot;&amp;lt;i&amp;gt;In course curriculum order&amp;lt;/i&amp;gt;&amp;quot;) %&amp;gt;% 
    	hc_xAxis(title = list(text = &amp;quot;FCC Course (in order of FCC course curriculum)&amp;quot;)) %&amp;gt;% 
    	hc_yAxis(title = list(text = &amp;quot;Mean # Times Single Student Completed Each Course&amp;quot;), 
       		max = 1.5, min = 1) %&amp;gt;% 
	hc_chart(zoomType = &amp;quot;xy&amp;quot;) %&amp;gt;% 
    	hc_tooltip(headerFormat = &amp;quot;&amp;quot;, pointFormat = &amp;quot;&amp;lt;b&amp;gt;Class: {point.course}&amp;lt;/b&amp;gt; &amp;lt;br&amp;gt;
		Section: {point.section}&amp;lt;br&amp;gt;
		Mean times course taken by single student: {point.y} times&amp;quot;, 
        		valueDecimals = 2)

fig8
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe seamless src=&#34;../FCC_Courses_files/figure-markdown_github/fig8/index.html&#34; width = &#34;100%&#34; height=&#34;500&#34; id=&#34;iframe_container&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;The courses closest to 1 in this figure were repeated the fewest number of times by students. The most commonly repeated course in the entire curriculum was &amp;ldquo;Where art thou&amp;rdquo;, a course near the beginning of the &amp;ldquo;Intermediate Algorithm Scripting&amp;rdquo; Section.&lt;/p&gt;

&lt;p&gt;Generally speaking, sections with the most repeated courses were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Basic JavaScript&lt;/li&gt;
&lt;li&gt;Basic Algorithm Scripting&lt;/li&gt;
&lt;li&gt;Intermediate Algorithm Scripting&lt;/li&gt;
&lt;li&gt;Automated Testing and Debugging&lt;/li&gt;
&lt;li&gt;Advanced Algorithm Scripting&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This could indicate that the courses in these sections are simply more difficult than other sections or that the material in these courses needs to be viewed more than once to completely comprehend the material. Either way, the content in these course sections should be assessed.&lt;/p&gt;

&lt;h3 id=&#34;can-we-predict-the-number-of-courses-a-student-will-complete-using-machine-learning&#34;&gt;Can we predict the number of courses a student will complete using machine learning?&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;m going to use some simple machine learning to see if I can predict the number of courses a student will complete (not counting repeated courses). I&amp;rsquo;m going to include 4 variables in this model:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First completed course&lt;/li&gt;
&lt;li&gt;Number of repeated courses&lt;/li&gt;
&lt;li&gt;Number of 14 day breaks&lt;/li&gt;
&lt;li&gt;Median course completion time (not including &amp;gt; 14 day breaks)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First, I need to transform my dataset to fit into a frame with the needed variables. To remain consistent, I&amp;rsquo;ll once again use &lt;code&gt;dplyr&lt;/code&gt; functions for this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;repeat_students &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id) %&amp;gt;% 
	summarise(total_count = n()) %&amp;gt;% 
    	ungroup() %&amp;gt;% 
	filter(total_count &amp;gt; 1)

first_course &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id) %&amp;gt;% 
	filter(st_cour_num == 1) %&amp;gt;% 
	select(1:2) %&amp;gt;% 
	ungroup()

repeated_courses &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id, course) %&amp;gt;% 
	summarise(course_count = n()) %&amp;gt;% 
    	filter(course_count &amp;gt; 1) %&amp;gt;% 
	summarise(repeat_count = n()) %&amp;gt;% 
   	ungroup()

breaks_courses &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id) %&amp;gt;% 
	mutate(time = as.numeric(time_since_last, units = &amp;quot;mins&amp;quot;)) %&amp;gt;% 
	summarise(breaks = length(.id[time &amp;gt; 20160])) %&amp;gt;% 
	mutate(breaks = breaks - 1) %&amp;gt;% 
	ungroup()

median_courses &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id) %&amp;gt;% 
	mutate(time = as.numeric(time_since_last, units = &amp;quot;mins&amp;quot;)) %&amp;gt;% 
	filter(time &amp;lt; 20160) %&amp;gt;% 
	summarise(median_time = median(time, na.rm = TRUE)) %&amp;gt;% 
	ungroup()

completed_courses &amp;lt;- sc_full4 %&amp;gt;% 
	group_by(.id) %&amp;gt;% 
	distinct(course) %&amp;gt;% 
   	summarise(nr_count = n()) %&amp;gt;% 
	ungroup()

mlset &amp;lt;- left_join(repeat_students, first_course, by = &amp;quot;.id&amp;quot;)
mlset &amp;lt;- left_join(mlset, repeated_courses, by = &amp;quot;.id&amp;quot;)
mlset &amp;lt;- left_join(mlset, breaks_courses, by = &amp;quot;.id&amp;quot;)
mlset &amp;lt;- left_join(mlset, median_courses, by = &amp;quot;.id&amp;quot;)
mlset &amp;lt;- left_join(mlset, completed_courses, by = &amp;quot;.id&amp;quot;)

# Replacing NA in repeat_count column with 0
mlset$repeat_count[is.na(mlset$repeat_count)] &amp;lt;- 0

# Making course into a factor
mlset$course &amp;lt;- as.factor(mlset$course)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the dataframe is set up the way I want (a single row per student and only the variables I&amp;rsquo;m interested in), I&amp;rsquo;m going to randomize the dataset and extract a test set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Set random seed
set.seed(1)

# Shuffle rows of data set
n &amp;lt;- nrow(mlset)
shuffled &amp;lt;- mlset[sample(n), ]

# Perform 70/30 split (70% to training set, 30% to test set)
train_indices &amp;lt;- 1:round(0.7 * n)
train &amp;lt;- shuffled[train_indices, ]

test_indices &amp;lt;- (round(0.7 * n) + 1):n
test &amp;lt;- shuffled[test_indices, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;fitting-a-baseline-model&#34;&gt;Fitting a baseline model&lt;/h4&gt;

&lt;p&gt;Without adding any extra variables, how well can we predict the number of courses that a student will complete? Without any additional variables, my best guess is that the mean number of courses taken (without replication) would help us predict the number of courses completed. This will give us a baseline to compare our more complex models with. Wow a RMSE of 73.17!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Creating baseline model
baseline &amp;lt;- mean(train$nr_count)

# Evaluate RMSE on the test set
base_test &amp;lt;- sqrt(mean((baseline - test$nr_count)^2))
base_test
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 73.17323
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;creating-traincontrol&#34;&gt;Creating trainControl&lt;/h4&gt;

&lt;p&gt;Since I plan to use the &lt;code&gt;caret&lt;/code&gt; package to test two different models for these data, I will create a system that will perform a 10-fold cross-validation of the training dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;myControl &amp;lt;- trainControl(method = &amp;quot;cv&amp;quot;, number = 10, verboseIter = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;fitting-a-random-forest-model&#34;&gt;Fitting a random forest model&lt;/h4&gt;

&lt;p&gt;The first type of model I&amp;rsquo;d like to use is a random forest model (using the &lt;code&gt;ranger&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; packages and the trainControl object I just created).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_model &amp;lt;- train(nr_count ~ course + repeat_count + breaks + 
    median_time, data = train, tuneLength = 3, method = &amp;quot;ranger&amp;quot;, 
    trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_model
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Random Forest 
## 
## 55502 samples
##     4 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 49951, 49952, 49952, 49952, 49953, 49951, ... 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE      Rsquared 
##     2   69.16746  0.2839369
##   122   58.47552  0.3601910
##   243   66.00565  0.2475999
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was mtry = 122.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our model is an OK fit, explaining about 55% of the variation in our model with a RMSE of 49.&lt;/p&gt;

&lt;h4 id=&#34;fitting-a-glmnet-model&#34;&gt;Fitting a glmnet model&lt;/h4&gt;

&lt;p&gt;I&amp;rsquo;m also going to try to fit a glmnet model to these data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;glm_model &amp;lt;- train(nr_count ~ course + repeat_count + breaks + 
    median_time, data = train, tuneLength = 3, method = &amp;quot;glmnet&amp;quot;, 
    trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: glmnet

## Loading required package: Matrix

## 
## Attaching package: &#39;Matrix&#39;

## The following object is masked from &#39;package:tidyr&#39;:
## 
##     expand

## Loading required package: foreach

## Loaded glmnet 2.0-5
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;glm_model
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## glmnet 
## 
## 55502 samples
##     4 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 49952, 49950, 49952, 49952, 49951, 49952, ... 
## Resampling results across tuning parameters:
## 
##   alpha  lambda      RMSE      Rsquared 
##   0.10   0.05861448  64.27342  0.2272597
##   0.10   0.58614484  64.23881  0.2280560
##   0.10   5.86144844  64.26716  0.2287188
##   0.55   0.05861448  64.25864  0.2276078
##   0.55   0.58614484  64.17347  0.2297203
##   0.55   5.86144844  64.84995  0.2170755
##   1.00   0.05861448  64.23882  0.2280713
##   1.00   0.58614484  64.21272  0.2288975
##   1.00   5.86144844  65.07230  0.2166004
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final values used for the model were alpha = 0.55 and lambda
##  = 0.5861448.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The best glmnet model explained about 48% of the variance in our dataset with a RMSE of about 53.&lt;/p&gt;

&lt;h4 id=&#34;comparing-model-fit&#34;&gt;Comparing Model Fit&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a list of models
models &amp;lt;- list(rf = rf_model, glmnet = glm_model)

# Resample the models
resampled &amp;lt;- resamples(models)

# Generate a summary
summary(resampled)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = resampled)
## 
## Models: rf, glmnet 
## Number of resamples: 10 
## 
## RMSE 
##         Min. 1st Qu. Median  Mean 3rd Qu.  Max. NA&#39;s
## rf     57.79   57.91  58.52 58.48   58.85 59.50    0
## glmnet 63.36   64.06  64.27 64.17   64.34 64.75    0
## 
## Rsquared 
##          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf     0.3312  0.3510 0.3629 0.3602  0.3724 0.3781    0
## glmnet 0.2204  0.2258 0.2268 0.2297  0.2317 0.2487    0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Plot the differences between model fits
dotplot(resampled, metric = &amp;quot;RMSE&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src =&#34;../FCC_Courses_files/figure-markdown_github/unnamed-chunk-60-1.png&#34; class = &#34;img-responsive&#34; style = &#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dotplot(resampled, metric = &amp;quot;Rsquared&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src =&#34;../FCC_Courses_files/figure-markdown_github/unnamed-chunk-60-2.png&#34; class = &#34;img-responsive&#34; style = &#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So our Random Forest model has a better fit and a lower error than the glmnet model. Let&amp;rsquo;s see which predictors were the most important to that model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Creating a Variable Importance variable
vimp &amp;lt;- varImp(rf_model)

# Plotting &#39;vimp&#39;
ggplot(vimp, top = 20[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../FCC_Courses_files/figure-markdown_github/unnamed-chunk-61-1.png&#34; class = &#34;img-responsive&#34; style = &#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The median time spent on each class is the most important variable in our current model, followed by the first course in the series, and the number of courses that were repeated.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;While I didn&amp;rsquo;t answer every one of the questions that FCC was interested in, I was able to answer a few, and here&amp;rsquo;s what I found:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Starting Location&lt;/strong&gt; : While users start their FCC journey at a few different places, most begin at either &amp;ldquo;Learn how Free Code Camp works&amp;rdquo; and &amp;ldquo;Say Hello to HTML Elements&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Most Popular Courses&lt;/strong&gt; : The courses offered early in the curriculum were completed mre frequently, and course completion drops off throughout the &amp;ldquo;HTML5 and CSS&amp;rdquo; and &amp;ldquo;Responsive Design with Bootstrap&amp;rdquo; sections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Longest Courses to Complete&lt;/strong&gt; : The courses that took the longest (on average) to complete were:

&lt;ul&gt;
&lt;li&gt;Claim Your Backend Development Certificate (6845 minutes or 4.75 days)&lt;/li&gt;
&lt;li&gt;Build a Voting App (6675 minutes or 4.6 days)&lt;/li&gt;
&lt;li&gt;Build a Nightlife Coordination App (4861 minutes or 3.4 days)&lt;/li&gt;
&lt;li&gt;Use the Twitchtv JSON API (4289 minutes or 3 days)&lt;/li&gt;
&lt;li&gt;Build a Simon Game (4280 minutes or 3 days)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Course Completion&lt;/strong&gt; : About &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; of students only complete between 1 and 5 courses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Repeated Course Completion&lt;/strong&gt; : Many students complete the same course more than once. The most commonly repeated courses are:

&lt;ul&gt;
&lt;li&gt;Basic JavaScript&lt;/li&gt;
&lt;li&gt;Basic Algorithm Scripting&lt;/li&gt;
&lt;li&gt;Intermediate Algorithm Scripting&lt;/li&gt;
&lt;li&gt;Automated Testing and Debugging&lt;/li&gt;
&lt;li&gt;Advanced Algorithm Scripting&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Taking Two Week Breaks&lt;/strong&gt; : Taking one or more two week breaks actually appears to lead to a higher median number of completed courses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student Flow Through Course Map&lt;/strong&gt; : Users tend to take many of the completed courses in the recommended order, but some suggested pathways are ignored in favor of more user-preferred pathways. Several courses don&amp;rsquo;t appear to fit into the typical flow of the course curriculum. These courses seem to be treated as stand-alone courses:

&lt;ul&gt;
&lt;li&gt;Courses in the Node.js and Express.js section&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Get Set for Basejumps&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Save your code revisions forever with Git&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Courses in the Dynamic Web application section&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Predicting Course Completion&lt;/strong&gt; : While a model could be fit, more information is needed to properly predict course completion for FCC students.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;my-suggestions&#34;&gt;My Suggestions&lt;/h2&gt;

&lt;p&gt;While I can only offer suggestions based on the data I am given, I suggest that FCC:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Investigate &amp;ldquo;Line up Form Elements Responsively with Bootstrap&amp;rdquo; course. Almost 11,000 students complete this course but don&amp;rsquo;t continue to the next courses in the section.&lt;/li&gt;
&lt;li&gt;Determine why the longest courses to complete take so long. Are these courses just unlikely to be completed in one sitting? Are they significantly more difficult than other courses in the curriculum?&lt;/li&gt;
&lt;li&gt;Suggest to students that it is OK (and even sometimes helpful) to take a break and then come back. Though, it may be helpful to remind them to come back if they&amp;rsquo;ve been gone for more than 2 weeks.&lt;/li&gt;
&lt;li&gt;Determine why some courses were taken repeatedly by the same students. Is the course material in these courses harder and thus needed to be taken multiple times to comprehend?&lt;/li&gt;
&lt;li&gt;Integrate the &amp;ldquo;stand-alone&amp;rdquo; courses into the curriculum map in a more cohesive way.&lt;/li&gt;
&lt;li&gt;Offer different maps based on students&amp;rsquo; end-goal. All courses may not be necessary for each type of student.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As always, I appreciate any and all feedback on my work, so feel free to let me know what you think!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dog Ownership in Seattle</title>
      <link>/projects/Seattle_Dogs/</link>
      <pubDate>Wed, 16 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/Seattle_Dogs/</guid>
      <description>&lt;p&gt;Data cleaning, exploration, mapping, and data visualizations in RMarkdown.
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-licensed-dog-ownership-data&#34;&gt;Importing Licensed Dog Ownership Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-data&#34;&gt;Cleaning Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-visualizations&#34;&gt;Data Visualizations&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#dog-popularity----by-breed&#34;&gt;Dog Popularity &amp;ndash; By Breed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-popularity----by-size&#34;&gt;Dog Popularity &amp;ndash; By Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-populations-by-zip-code&#34;&gt;Dog Populations by Zip Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-populations-by-size&#34;&gt;Dog Populations by Size&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#small&#34;&gt;Small&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#medium&#34;&gt;Medium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#large&#34;&gt;Large&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#giant&#34;&gt;Giant&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#caveats-of-dog-size-by-zipcode&#34;&gt;Caveats of Dog Size by Zipcode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dog-names&#34;&gt;Dog Names&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This report investigates licensed dog ownership in Seattle, WA (USA).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m curious about a few things here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;People estimate that there are 160,000 dogs in Seattle. Where are they?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Seattle is a relatively densely-populated area. Are small, apartment-friendly dogs preferred?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Using this information, what recommendations could be made to aspiring dog sitters and walkers in Seattle?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I will annotate each step of data analysis as I go.&lt;/p&gt;

&lt;p&gt;Time to get started!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For mapping
library(choroplethr)
library(choroplethrZip)
library(ggmap)
library(mapproj)
library(zipcode)

# For data manipulation and tidying
library(dplyr)
library(tidyr)

# For data visualizations
library(ggplot2)
library(tm)
library(SnowballC)
library(wordcloud)

# For modeling and machine learning
library(caret)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-licensed-dog-ownership-data&#34;&gt;Importing Licensed Dog Ownership Data&lt;/h3&gt;

&lt;p&gt;The spreadsheet containing all licensed dog ownership information was obtained from the Seattle Times article &lt;a href=&#34;http://www.seattletimes.com/life/pets/mapping-the-dogs-of-seattle/&#34;&gt;&amp;ldquo;Mapping the Dogs of Seattle&amp;rdquo;&lt;/a&gt; and is available for &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1XWLw_hxWM2RHiwALzcM_QxNpzQn_cDmS3Z9HFoZMvTo/edit#gid=460106206&#34;&gt;download&lt;/a&gt;. According to the article, the original data were obtained from the Seattle Animal Shelter and represent the 43,000 licensed dogs in Seattle as of February 2015. &lt;em&gt;Note: This number is thought to only represent approximately &lt;a href=&#34;http://www.seattle.gov/Documents/Departments/ParksAndRecreation/PoliciesPlanning/Plans/Response_to_SLI_69-1-B-1_(Dog_Off-Leash_Areas).pdf&#34;&gt;27% of the dog population in Seattle&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs &amp;lt;- read.csv(file = &amp;quot;Seattle_Dogs_2015.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Let&amp;rsquo;s take a quick look at the data file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(dogs)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    42996 obs. of  7 variables:
##  $ License.Type.Sold: Factor w/ 15 levels &amp;quot;Dog 6 Month Prov/Rabies&amp;quot;,..: 1 1 1 1 1 1 1 1 2 2 ...
##  $ Animal.Type      : Factor w/ 1 level &amp;quot;Dog&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Gender           : Factor w/ 3 levels &amp;quot;Female&amp;quot;,&amp;quot;Male&amp;quot;,..: 2 1 1 2 2 1 2 2 1 2 ...
##  $ Primary.Breed    : Factor w/ 227 levels &amp;quot;Affenpinscher&amp;quot;,..: 53 53 174 123 137 102 53 106 26 15 ...
##  $ Primary.Color    : Factor w/ 90 levels &amp;quot;&amp;quot;,&amp;quot;Amber&amp;quot;,&amp;quot;Apricot&amp;quot;,..: 85 6 85 10 10 9 9 36 83 56 ...
##  $ Name             : Factor w/ 10712 levels &amp;quot;&amp;quot;,&amp;quot; &amp;quot;,&amp;quot; Carlota&amp;quot;,..: 603 9763 317 1324 3671 5764 6065 4254 490 7006 ...
##  $ Zip.C            : Factor w/ 155 levels &amp;quot;&amp;quot;,&amp;quot;*/116&amp;quot;,&amp;quot;14534&amp;quot;,..: 107 107 100 75 84 1 86 77 107 87 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like the variables we are working with right now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;License Type&lt;/strong&gt; : Indicates what type of license the dog has&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Animal Type&lt;/strong&gt; : Since this dataset is all about dogs, there is only one animal type listed: &amp;ldquo;Dog&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gender&lt;/strong&gt; : Dog&amp;rsquo;s sex (&amp;ldquo;Male&amp;rdquo;, &amp;ldquo;Female&amp;rdquo;, or &amp;ldquo;Unspec&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Primary Breed&lt;/strong&gt; : Indicates the general breed of the dog&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Primary Color&lt;/strong&gt; : Indicates the dog&amp;rsquo;s overall color&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt; : Lists the dog&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zip.C&lt;/strong&gt; : Indicates the zipcode where the dog is registered&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can eliminate the &amp;ldquo;Animal Type&amp;rdquo; column since it doesn&amp;rsquo;t give us any additional information.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs &amp;lt;- dogs %&amp;gt;% select(-2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, now is there anyway to condense or standardize the breeds listed?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at what kind of breeds are present in Seattle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(dogs$Primary.Breed)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;Affenpinscher&amp;quot;                  &amp;quot;Afghan Hound&amp;quot;                  
##   [3] &amp;quot;Airedale Terrier&amp;quot;               &amp;quot;Akita&amp;quot;                         
##   [5] &amp;quot;Alaskan Malumute&amp;quot;               &amp;quot;Amer. Pitbull Terrier&amp;quot;         
##   [7] &amp;quot;Amer. Water Spaniel&amp;quot;            &amp;quot;Amer.Staffordshire Terrier&amp;quot;    
##   [9] &amp;quot;American Eskimo&amp;quot;                &amp;quot;American Foxhound&amp;quot;             
##  [11] &amp;quot;Appenzel Mountain Dog&amp;quot;          &amp;quot;Australian Cattle Dog&amp;quot;         
##  [13] &amp;quot;Australian Kelpie&amp;quot;              &amp;quot;Australian Shepard&amp;quot;            
##  [15] &amp;quot;Australian Terrier&amp;quot;             &amp;quot;Basenji&amp;quot;                       
##  [17] &amp;quot;Basset Hound&amp;quot;                   &amp;quot;Beagle&amp;quot;                        
##  [19] &amp;quot;Bearded Collie&amp;quot;                 &amp;quot;Beauceron&amp;quot;                     
##  [21] &amp;quot;Belgian Malinios&amp;quot;               &amp;quot;Belgian Malinois&amp;quot;              
##  [23] &amp;quot;Belgian Sheepdog&amp;quot;               &amp;quot;Belgian Shepherd&amp;quot;              
##  [25] &amp;quot;Belgian Tervuren&amp;quot;               &amp;quot;Bernese Mountain Dog&amp;quot;          
##  [27] &amp;quot;Bichon Frise&amp;quot;                   &amp;quot;Bloodhound&amp;quot;                    
##  [29] &amp;quot;Blue Heeler&amp;quot;                    &amp;quot;Bordeaux Mastiff&amp;quot;              
##  [31] &amp;quot;Border Collie&amp;quot;                  &amp;quot;Border Terrier&amp;quot;                
##  [33] &amp;quot;Borzoi&amp;quot;                         &amp;quot;Boston Terrier&amp;quot;                
##  [35] &amp;quot;Bouvier De Flanders&amp;quot;            &amp;quot;Boxer&amp;quot;                         
##  [37] &amp;quot;Briard&amp;quot;                         &amp;quot;Brittany Spaniel&amp;quot;              
##  [39] &amp;quot;Brussels Griffon&amp;quot;               &amp;quot;Bull Terrier&amp;quot;                  
##  [41] &amp;quot;Bull Terrier, Minature&amp;quot;         &amp;quot;Bulldog&amp;quot;                       
##  [43] &amp;quot;Bulldog American&amp;quot;               &amp;quot;Bulldog English&amp;quot;               
##  [45] &amp;quot;Bullmastiff&amp;quot;                    &amp;quot;Cairn Terrier&amp;quot;                 
##  [47] &amp;quot;Canaan Dog&amp;quot;                     &amp;quot;Cane Corso&amp;quot;                    
##  [49] &amp;quot;Carolina&amp;quot;                       &amp;quot;Catahoula Leopard Dog&amp;quot;         
##  [51] &amp;quot;Cavalier King Charles Spaniel&amp;quot;  &amp;quot;Chesapeake Bay Retriever&amp;quot;      
##  [53] &amp;quot;Chihuahua&amp;quot;                      &amp;quot;Chihuahua, Long-haired&amp;quot;        
##  [55] &amp;quot;Chinese Crested&amp;quot;                &amp;quot;Chinook&amp;quot;                       
##  [57] &amp;quot;Chow Chow&amp;quot;                      &amp;quot;Cirneco Dell Etna&amp;quot;             
##  [59] &amp;quot;Clumber Spaniel&amp;quot;                &amp;quot;Cocker Spaniel&amp;quot;                
##  [61] &amp;quot;Cocker Spaniel, American&amp;quot;       &amp;quot;Cocker Spaniel, English&amp;quot;       
##  [63] &amp;quot;Collie&amp;quot;                         &amp;quot;Collie, Rough-Coated&amp;quot;          
##  [65] &amp;quot;Collie, Smooth-Coated&amp;quot;          &amp;quot;Coonhound&amp;quot;                     
##  [67] &amp;quot;Coonhound, Redbone&amp;quot;             &amp;quot;Coonhound, Walker&amp;quot;             
##  [69] &amp;quot;Corgi&amp;quot;                          &amp;quot;Corgi, Cardigan Welsh&amp;quot;         
##  [71] &amp;quot;Corgi, Pembroke Welsh&amp;quot;          &amp;quot;Coton de Tulear&amp;quot;               
##  [73] &amp;quot;Coton Retulear&amp;quot;                 &amp;quot;Curly-Coated Retriever&amp;quot;        
##  [75] &amp;quot;Curs&amp;quot;                           &amp;quot;Dachshund&amp;quot;                     
##  [77] &amp;quot;Dachshund, Long-Haired&amp;quot;         &amp;quot;Dachshund, Minature&amp;quot;           
##  [79] &amp;quot;Dachshund, Standard&amp;quot;            &amp;quot;Dachshund, Wirehaired&amp;quot;         
##  [81] &amp;quot;Dalmatian&amp;quot;                      &amp;quot;Dandie Dinmont Terrier&amp;quot;        
##  [83] &amp;quot;Dingo&amp;quot;                          &amp;quot;Doberman Pinscher&amp;quot;             
##  [85] &amp;quot;Dogo de Argentino&amp;quot;              &amp;quot;Dogue De Bordeaux&amp;quot;             
##  [87] &amp;quot;Elkhound&amp;quot;                       &amp;quot;English Foxhound&amp;quot;              
##  [89] &amp;quot;English Setter&amp;quot;                 &amp;quot;English Springer Spaniel&amp;quot;      
##  [91] &amp;quot;English Toy Spaniel&amp;quot;            &amp;quot;Entelbucher&amp;quot;                   
##  [93] &amp;quot;Field Spaniel&amp;quot;                  &amp;quot;Finnish Spitz&amp;quot;                 
##  [95] &amp;quot;Flat-Coated Retriever&amp;quot;          &amp;quot;Formosan Mountain Dog&amp;quot;         
##  [97] &amp;quot;Fox Terrier&amp;quot;                    &amp;quot;Fox Terrier, Smooth&amp;quot;           
##  [99] &amp;quot;Fox Terrier, Toy&amp;quot;               &amp;quot;Fox Terrier, Wirehaired&amp;quot;       
## [101] &amp;quot;French Bulldog&amp;quot;                 &amp;quot;German Shepherd&amp;quot;               
## [103] &amp;quot;German Shorthair Pointer&amp;quot;       &amp;quot;German Wirehair Pointer&amp;quot;       
## [105] &amp;quot;Giffon Vendeen&amp;quot;                 &amp;quot;Golden Retriever&amp;quot;              
## [107] &amp;quot;Goldendoodle&amp;quot;                   &amp;quot;Gordon Setter&amp;quot;                 
## [109] &amp;quot;Great Dane&amp;quot;                     &amp;quot;Great Pyrenees&amp;quot;                
## [111] &amp;quot;Greater Swiss Mountain Dog&amp;quot;     &amp;quot;Greyhound&amp;quot;                     
## [113] &amp;quot;Harrier&amp;quot;                        &amp;quot;Havanese&amp;quot;                      
## [115] &amp;quot;Hound&amp;quot;                          &amp;quot;Husky&amp;quot;                         
## [117] &amp;quot;Ibizan Hound&amp;quot;                   &amp;quot;Irish Setter&amp;quot;                  
## [119] &amp;quot;Irish Terrier&amp;quot;                  &amp;quot;Irish Wolfhound&amp;quot;               
## [121] &amp;quot;Italian Greyhound&amp;quot;              &amp;quot;Italian Spinone&amp;quot;               
## [123] &amp;quot;Jack Russell Terrier&amp;quot;           &amp;quot;Japanese Chin&amp;quot;                 
## [125] &amp;quot;Japanese Fox&amp;quot;                   &amp;quot;Kairn Terrier&amp;quot;                 
## [127] &amp;quot;Karelian Bear Dog&amp;quot;              &amp;quot;Keeshond&amp;quot;                      
## [129] &amp;quot;Kerry Blue Terrier&amp;quot;             &amp;quot;King Charles Spaniel&amp;quot;          
## [131] &amp;quot;Kookier Hound&amp;quot;                  &amp;quot;Korean Chin-do&amp;quot;                
## [133] &amp;quot;Kuvasz&amp;quot;                         &amp;quot;Kyileo&amp;quot;                        
## [135] &amp;quot;Lab Retriever&amp;quot;                  &amp;quot;Labradoodle&amp;quot;                   
## [137] &amp;quot;Labrador Retriever&amp;quot;             &amp;quot;Lakeland Terrier&amp;quot;              
## [139] &amp;quot;Landseer&amp;quot;                       &amp;quot;Leonberger&amp;quot;                    
## [141] &amp;quot;Lhaso Apso&amp;quot;                     &amp;quot;Looks Like&amp;quot;                    
## [143] &amp;quot;Lowchen&amp;quot;                        &amp;quot;Maltese&amp;quot;                       
## [145] &amp;quot;Manchester Terrier&amp;quot;             &amp;quot;Manchester Terrier, Toy&amp;quot;       
## [147] &amp;quot;Mastiff&amp;quot;                        &amp;quot;McNab&amp;quot;                         
## [149] &amp;quot;Mexican Hairless&amp;quot;               &amp;quot;Miniture Pinscher&amp;quot;             
## [151] &amp;quot;Mix&amp;quot;                            &amp;quot;Neapolitan Mastiff&amp;quot;            
## [153] &amp;quot;Newfoundland&amp;quot;                   &amp;quot;Norfolk Terrier&amp;quot;               
## [155] &amp;quot;Norwegian Elkhound&amp;quot;             &amp;quot;Norwegian Lundehund&amp;quot;           
## [157] &amp;quot;Norwich Terrier&amp;quot;                &amp;quot;Novia Scotia Duck Tolling Retr&amp;quot;
## [159] &amp;quot;NULL&amp;quot;                           &amp;quot;Old English Sheepdog&amp;quot;          
## [161] &amp;quot;Otterhound&amp;quot;                     &amp;quot;Papillon&amp;quot;                      
## [163] &amp;quot;Pekingese&amp;quot;                      &amp;quot;Pharaoh Hound&amp;quot;                 
## [165] &amp;quot;Pitbull&amp;quot;                        &amp;quot;Plott Hound&amp;quot;                   
## [167] &amp;quot;Pointer&amp;quot;                        &amp;quot;Pointing Griffon, Wirehaired&amp;quot;  
## [169] &amp;quot;Pomeranian&amp;quot;                     &amp;quot;Poodle&amp;quot;                        
## [171] &amp;quot;Poodle, Minature&amp;quot;               &amp;quot;Poodle, Standard&amp;quot;              
## [173] &amp;quot;Poodle, Teacup&amp;quot;                 &amp;quot;Poodle, Toy&amp;quot;                   
## [175] &amp;quot;Portuguese Water Dog&amp;quot;           &amp;quot;Pug&amp;quot;                           
## [177] &amp;quot;Puli&amp;quot;                           &amp;quot;Purebred&amp;quot;                      
## [179] &amp;quot;Queensland Blue Heeler&amp;quot;         &amp;quot;Red Heeler&amp;quot;                    
## [181] &amp;quot;Rhodesian Ridgeback&amp;quot;            &amp;quot;Rottweiler&amp;quot;                    
## [183] &amp;quot;Saint Bernard&amp;quot;                  &amp;quot;Saluki&amp;quot;                        
## [185] &amp;quot;Samoyed&amp;quot;                        &amp;quot;Schipperke&amp;quot;                    
## [187] &amp;quot;Schnauzer&amp;quot;                      &amp;quot;Schnauzer, Giant&amp;quot;              
## [189] &amp;quot;Schnauzer, Minature&amp;quot;            &amp;quot;Schnauzer, Standard&amp;quot;           
## [191] &amp;quot;Scottish Deerhound&amp;quot;             &amp;quot;Scottish Terrier&amp;quot;              
## [193] &amp;quot;Sealyham Terrier&amp;quot;               &amp;quot;See Notes&amp;quot;                     
## [195] &amp;quot;Setter&amp;quot;                         &amp;quot;Shar-Pei&amp;quot;                      
## [197] &amp;quot;Shepherd&amp;quot;                       &amp;quot;Shetland Sheepdog&amp;quot;             
## [199] &amp;quot;Shiba Inu&amp;quot;                      &amp;quot;Shih Tzu&amp;quot;                      
## [201] &amp;quot;Siberian Husky&amp;quot;                 &amp;quot;Silken Windhound&amp;quot;              
## [203] &amp;quot;Silky Terrier&amp;quot;                  &amp;quot;Spaniel&amp;quot;                       
## [205] &amp;quot;Springer Spaniel&amp;quot;               &amp;quot;Staffordshire Bull Terrier&amp;quot;    
## [207] &amp;quot;Sussex Spaniel&amp;quot;                 &amp;quot;Terrier&amp;quot;                       
## [209] &amp;quot;Terrier, Black Russian&amp;quot;         &amp;quot;Terrier, Rat&amp;quot;                  
## [211] &amp;quot;Terrier, Soft-Coated Wheaten&amp;quot;   &amp;quot;Tibetan Mastiff&amp;quot;               
## [213] &amp;quot;Tibetan Spaniel&amp;quot;                &amp;quot;Tibetan Terrier&amp;quot;               
## [215] &amp;quot;Unspecified&amp;quot;                    &amp;quot;Vizsla&amp;quot;                        
## [217] &amp;quot;Water Spaniel&amp;quot;                  &amp;quot;Weimaraner&amp;quot;                    
## [219] &amp;quot;Welsh Springer Spaniel&amp;quot;         &amp;quot;Welsh Terrier&amp;quot;                 
## [221] &amp;quot;West Highland Terrier&amp;quot;          &amp;quot;West Highland White Terrier&amp;quot;   
## [223] &amp;quot;West Hihgland White Terrier&amp;quot;    &amp;quot;Whippet&amp;quot;                       
## [225] &amp;quot;Wirehair Terrier&amp;quot;               &amp;quot;Wolf Hybrid&amp;quot;                   
## [227] &amp;quot;Yorkshire Terrier&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! That&amp;rsquo;s quite a few! We&amp;rsquo;ll come back to cleaning up the species names in a bit.&lt;/p&gt;

&lt;p&gt;Generally, the dog&amp;rsquo;s estimated size may be more beneficial than their breed, so let&amp;rsquo;s try to pair these data up with information from other sources. The data used are available &lt;a href=&#34;http://modernpuppies.com/breedweightchart.aspx&#34;&gt;here&lt;/a&gt;. Time to import the database of dog breeds with their sizes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weight &amp;lt;- read.csv(file = &amp;quot;Breed_Wt.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s see what that looks like.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(weight)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    372 obs. of  3 variables:
##  $ Breed                 : chr  &amp;quot;Airedoodle&amp;quot; &amp;quot;Alapaha Blue Blood Bulldog&amp;quot; &amp;quot;Alaskan Klee Kai&amp;quot; &amp;quot;Alsatian&amp;quot; ...
##  $ Average.Adult.Weight  : chr  &amp;quot;Male: 45-65 lbs&amp;quot; &amp;quot;Male: 50-80 lbs&amp;quot; &amp;quot;Male: 11-15 lbs&amp;quot; &amp;quot;Male: 65-85 lbs&amp;quot; ...
##  $ Average.Adult.Weight.1: chr  &amp;quot;Female: 45-65 lbs&amp;quot; &amp;quot;Female: 50-80 lbs&amp;quot; &amp;quot;Female: 11-15 lbs&amp;quot; &amp;quot;Female: 50-70 lbs&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(weight)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                        Breed Average.Adult.Weight Average.Adult.Weight.1
## 1                 Airedoodle      Male: 45-65 lbs      Female: 45-65 lbs
## 2 Alapaha Blue Blood Bulldog      Male: 50-80 lbs      Female: 50-80 lbs
## 3           Alaskan Klee Kai      Male: 11-15 lbs      Female: 11-15 lbs
## 4                   Alsatian      Male: 65-85 lbs      Female: 50-70 lbs
## 5           American Bulldog      Male: 45-75 lbs      Female: 45-75 lbs
## 6               Aussiedoodle     Male: 35-65 lbs       Female: 25-55 lbs
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cleaning-data&#34;&gt;Cleaning Data&lt;/h2&gt;

&lt;p&gt;Looks like lots of character strings. Time to split out some of these columns. We&amp;rsquo;ll use the R packages &lt;code&gt;tidyr&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt; for this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Delete empty rows
weight &amp;lt;- weight[!apply(weight == &amp;quot;&amp;quot;, 1, all), ]

# Splitting Average Adult Weight (Species with Weight Ranges)
weight_split &amp;lt;- weight %&amp;gt;% separate(Average.Adult.Weight, into = c(&amp;quot;Male&amp;quot;, 
    &amp;quot;Wt_Range&amp;quot;), sep = &amp;quot;: &amp;quot;) %&amp;gt;% filter(grepl(&amp;quot;-&amp;quot;, Wt_Range)) %&amp;gt;% 
    separate(Wt_Range, into = c(&amp;quot;Min&amp;quot;, &amp;quot;Max&amp;quot;, &amp;quot;lbs&amp;quot;)) %&amp;gt;% select(-lbs) %&amp;gt;% 
    separate(Average.Adult.Weight.1, into = c(&amp;quot;Female&amp;quot;, &amp;quot;Wt_Range_F&amp;quot;), 
        sep = &amp;quot;: &amp;quot;) %&amp;gt;% filter(grepl(&amp;quot;-&amp;quot;, Wt_Range_F)) %&amp;gt;% separate(Wt_Range_F, 
    into = c(&amp;quot;Min_F&amp;quot;, &amp;quot;Max_F&amp;quot;, &amp;quot;lbs_F&amp;quot;)) %&amp;gt;% mutate_each(funs(as.numeric), 
    (Min:Max)) %&amp;gt;% mutate_each(funs(as.numeric), (Min_F:Max_F)) %&amp;gt;% 
    mutate(Male_Avg = (Min + Max)/2) %&amp;gt;% mutate(Female_Avg = (Min_F + 
    Max_F)/2) %&amp;gt;% select(1, 9:10)

# Splitting Average Adult Weight (no ranges)
weight_split_2 &amp;lt;- weight %&amp;gt;% separate(Average.Adult.Weight, into = c(&amp;quot;Male&amp;quot;, 
    &amp;quot;Wt_Range&amp;quot;), sep = &amp;quot;: &amp;quot;) %&amp;gt;% filter(!grepl(&amp;quot;-&amp;quot;, Wt_Range)) %&amp;gt;% 
    separate(Wt_Range, into = c(&amp;quot;Male_Avg&amp;quot;, &amp;quot;lbs&amp;quot;)) %&amp;gt;% separate(Average.Adult.Weight.1, 
    into = c(&amp;quot;Female&amp;quot;, &amp;quot;Wt_Range_F&amp;quot;), sep = &amp;quot;: &amp;quot;) %&amp;gt;% separate(Wt_Range_F, 
    into = c(&amp;quot;Female_Avg&amp;quot;, &amp;quot;lbs_2&amp;quot;)) %&amp;gt;% select(1, 3, 6)

# Bind Both Data Frames
weight_split_all &amp;lt;- rbind(weight_split_2, weight_split)

# Check out our new dataframe
head(weight_split_all)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##              Breed Male_Avg Female_Avg
## 1     Afghan Hound       60         50
## 2 Airedale Terrier       55         55
## 3 Alaskan Malamute       85         75
## 4          Basenji       24         22
## 5  English Bulldog       50         40
## 6    Cairn Terrier       14         13
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Now we have a dataframe that just lists breed, and then average weight for males and females. Now we can use this to fill in the estimated weight for each of the animals in our &lt;code&gt;dogs&lt;/code&gt; dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make a copy of our dataset
dogs_2 &amp;lt;- dogs

# Match dog breed from dogs dataset to breed from
# weight_split_all dataset
dogs_2$Male_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Male_Avg&amp;quot;]

dogs_2$Male_Avg &amp;lt;- as.numeric(dogs_2$Male_Avg)

dogs_2$Female_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Female_Avg&amp;quot;]

dogs_2$Female_Avg &amp;lt;- as.numeric(dogs_2$Female_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Let&amp;rsquo;s check how we did.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(dogs_2$Male_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    5.00   16.00   52.50   47.53   72.50  182.50   11611
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well, looks like our system automatically placed 73% of our entries, the remaining 27% (or 11,611 dogs) were not found. Let&amp;rsquo;s see if those were all the same or similar species.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg)) %&amp;gt;% group_by(Primary.Breed) %&amp;gt;% 
    summarise(count = n())

head(missing_size)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 2
##                Primary.Breed count
##                       &amp;lt;fctr&amp;gt; &amp;lt;int&amp;gt;
## 1           Alaskan Malumute   123
## 2      Amer. Pitbull Terrier   137
## 3        Amer. Water Spaniel     5
## 4 Amer.Staffordshire Terrier   186
## 5      Appenzel Mountain Dog     3
## 6         Australian Shepard  1216
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ah, looks like we have a few misspelled names in our original database. Let&amp;rsquo;s try to clean those up a bit.&lt;/p&gt;

&lt;p&gt;Due to the random nature of the misspellings and re-wording of breeds in this dataset, I&amp;rsquo;ll use the &lt;code&gt;gsub&lt;/code&gt; function to manually recode the ones that need it. This also allows for verification that the correct new term is being used.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Fixing Misspellings
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Alaskan Malumute&amp;quot;, &amp;quot;Alaskan Malamute&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Shepard&amp;quot;, &amp;quot;Shepherd&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Belgian Malinios&amp;quot;, &amp;quot;Belgian Malinois&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bouvier De Flanders&amp;quot;, &amp;quot;Bouvier des Flandres&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Coton Retulear&amp;quot;, &amp;quot;Coton de Tulear&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Dogo de Argentino&amp;quot;, &amp;quot;Dogo Argentino&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Entelbucher&amp;quot;, &amp;quot;Entlebucher&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;German Shorthair Pointer&amp;quot;, &amp;quot;German Shorthaired Pointer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;German Wirehair Pointer&amp;quot;, &amp;quot;German Wirehaired Pointer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Giffon Vendeen&amp;quot;, &amp;quot;Griffon Vendeen&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Italian Spinone&amp;quot;, &amp;quot;Spinone Italiano&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Kairn Terrier&amp;quot;, &amp;quot;Cairn Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Kookier Hound&amp;quot;, &amp;quot;Kooikerhondje&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Korean Chin-do&amp;quot;, &amp;quot;Jindo&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Kyileo&amp;quot;, &amp;quot;Kyi-Leo&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Lhaso Apso&amp;quot;, &amp;quot;Lhasa Apso&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Miniture Pinscher&amp;quot;, &amp;quot;Miniature Pinscher&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Novia Scotia Duck Tolling Retr&amp;quot;, 
    &amp;quot;Nova Scotia Duck Tolling Retriever&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Setter$&amp;quot;, &amp;quot;English Setter&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;West Hihgland White Terrier|West Highland White Terrier&amp;quot;, 
    &amp;quot;West Highland Terrier&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Amer.Staffordshire Terrier&amp;quot;, &amp;quot;American Staffordshire Terrier&amp;quot;, 
    dogs_2$Primary.Breed)

# Change any &#39;Amer.&#39; to &#39;American&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Amer\\.$&amp;quot;, &amp;quot;American&amp;quot;, dogs_2$Primary.Breed, 
    fixed = TRUE)

# Another name for Bordeaux Mastiff is &#39;French Mastiff&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bordeaux Mastiff|Dogue De Bordeaux&amp;quot;, 
    &amp;quot;French Mastiff&amp;quot;, dogs_2$Primary.Breed)

# Change &#39;Elkhound&#39; to &#39;Norwegian Elkhound&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Elkhound$&amp;quot;, &amp;quot;Norwegian Elkhound&amp;quot;, 
    dogs_2$Primary.Breed)

# Change &#39;Husky&#39; to &#39;Siberian Husky&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Husky$&amp;quot;, &amp;quot;Siberian Husky&amp;quot;, dogs_2$Primary.Breed)

# Change King Charles Spaniel to Cavalier King Charles
# Spaniel
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;King Charles Spaniel|Cavalier King Charles Spaniel&amp;quot;, 
    &amp;quot;Cavalier King Charles Spaniel&amp;quot;, dogs_2$Primary.Breed)

# Change Lab Retriever to Labrador Retriever
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Lab Retriever&amp;quot;, &amp;quot;Labrador Retriever&amp;quot;, 
    dogs_2$Primary.Breed)

# Mexican Hairless are also called &#39;Xolo&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Mexican Hairless&amp;quot;, &amp;quot;Xolo&amp;quot;, dogs_2$Primary.Breed)

# Queensland Blue Heelers and Red Heelers are more commonly
# known as Australian Cattle Dogs
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Queensland Blue Heeler|Red Heeler&amp;quot;, 
    &amp;quot;Australian Cattle Dog&amp;quot;, dogs_2$Primary.Breed)

# Water Spaniels are the same as American Water Spaniels
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Amer\\. Water Spaniel|^Water Spaniel$&amp;quot;, 
    &amp;quot;American Water Spaniel&amp;quot;, dogs_2$Primary.Breed)

# Japanese Foxes are also called &#39;Shiba Inu&#39;
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Japanese Fox&amp;quot;, &amp;quot;Shiba Inu&amp;quot;, dogs_2$Primary.Breed)

# Changing the order of some words
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bull Terrier, Minature&amp;quot;, &amp;quot;Miniature Bull Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bulldog American&amp;quot;, &amp;quot;American Bulldog&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Bulldog English&amp;quot;, &amp;quot;English Bulldog&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Cocker Spaniel, American&amp;quot;, &amp;quot;American Cocker Spaniel&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Cocker Spaniel, English&amp;quot;, &amp;quot;English Cocker Spaniel&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Corgi, Cardigan Welsh&amp;quot;, &amp;quot;Cardigan Welsh Corgi&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Corgi, Pembroke Welsh&amp;quot;, &amp;quot;Pembroke Welsh Corgi&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Dachshund, Minature&amp;quot;, &amp;quot;Miniature Dachshund&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Fox Terrier, Toy&amp;quot;, &amp;quot;Toy Fox Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Manchester Terrier, Toy&amp;quot;, &amp;quot;Toy Manchester Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Pointing Griffon, Wirehaired&amp;quot;, 
    &amp;quot;Wirehaired Pointing Griffon&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Poodle, Minature&amp;quot;, &amp;quot;Miniature Poodle&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Schnauzer, Giant&amp;quot;, &amp;quot;Giant Schnauzer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Schnauzer, Minature&amp;quot;, &amp;quot;Miniature Schnauzer&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Terrier, Black Russian&amp;quot;, &amp;quot;Black Russian Terrier&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Terrier, Rat&amp;quot;, &amp;quot;Rat Terrier&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Terrier, Soft-Coated Wheaten&amp;quot;, 
    &amp;quot;Soft Coated Wheaten Terrier&amp;quot;, dogs_2$Primary.Breed)

# Combine similar types
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Collie, Rough-Coated|Collie, Smooth-Coated&amp;quot;, 
    &amp;quot;Collie&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Chihuahua, Long-haired&amp;quot;, &amp;quot;Chihuahua&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Coonhound, Redbone|Coonhound, Walker&amp;quot;, 
    &amp;quot;Coonhound&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Dachshund, Long-Haired|Dachshund, Standard|Dachshund, Wirehaired|^Dachshund$&amp;quot;, 
    &amp;quot;Standard Dachshund&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Fox Terrier$|Fox Terrier, Smooth|Fox Terrier, Wirehaired|Wirehair Terrier&amp;quot;, 
    &amp;quot;Standard Fox Terrier&amp;quot;, dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Poodle$|Poodle, Standard&amp;quot;, &amp;quot;Standard Poodle&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Poodle, Teacup|Poodle, Toy&amp;quot;, &amp;quot;Toy Poodle&amp;quot;, 
    dogs_2$Primary.Breed)
dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;^Schnauzer$|Schnauzer, Standard&amp;quot;, 
    &amp;quot;Standard Schnauzer&amp;quot;, dogs_2$Primary.Breed)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was a lot of very different errors in that dataset! Let&amp;rsquo;s see if that helped.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Match dog breed from dogs dataset to breed from
# weight_split_all dataset
dogs_2$Male_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Male_Avg&amp;quot;]

dogs_2$Male_Avg &amp;lt;- as.numeric(dogs_2$Male_Avg)

dogs_2$Female_Avg &amp;lt;- weight_split_all[match(dogs_2$Primary.Breed, 
    weight_split_all$Breed), &amp;quot;Female_Avg&amp;quot;]

dogs_2$Female_Avg &amp;lt;- as.numeric(dogs_2$Female_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see how we did.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(dogs_2$Male_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    5.00   15.50   50.00   45.19   72.50  182.50    3503
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well, that did fix some of the missing values! Still another 3,503 (or 8%) to go!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size_2 &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg)) %&amp;gt;% group_by(Primary.Breed) %&amp;gt;% 
    summarise(count = n())

missing_size_2$Primary.Breed
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Amer. Pitbull Terrier&amp;quot;  &amp;quot;Appenzel Mountain Dog&amp;quot; 
##  [3] &amp;quot;Belgian Shepherd&amp;quot;       &amp;quot;Bulldog&amp;quot;               
##  [5] &amp;quot;Carolina&amp;quot;               &amp;quot;Cirneco Dell Etna&amp;quot;     
##  [7] &amp;quot;Curs&amp;quot;                   &amp;quot;Dingo&amp;quot;                 
##  [9] &amp;quot;Entlebucher&amp;quot;            &amp;quot;Formosan Mountain Dog&amp;quot; 
## [11] &amp;quot;Hound&amp;quot;                  &amp;quot;Kyi-Leo&amp;quot;               
## [13] &amp;quot;Landseer&amp;quot;               &amp;quot;Looks Like&amp;quot;            
## [15] &amp;quot;McNab&amp;quot;                  &amp;quot;Mix&amp;quot;                   
## [17] &amp;quot;Norwegian Lundehund&amp;quot;    &amp;quot;NULL&amp;quot;                  
## [19] &amp;quot;Purebred&amp;quot;               &amp;quot;Saluki&amp;quot;                
## [21] &amp;quot;See Notes&amp;quot;              &amp;quot;Shepherd&amp;quot;              
## [23] &amp;quot;Silken Windhound&amp;quot;       &amp;quot;Spaniel&amp;quot;               
## [25] &amp;quot;Terrier&amp;quot;                &amp;quot;Toy Manchester Terrier&amp;quot;
## [27] &amp;quot;Unspecified&amp;quot;            &amp;quot;Welsh Springer Spaniel&amp;quot;
## [29] &amp;quot;Wolf Hybrid&amp;quot;            &amp;quot;Xolo&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like a few of these can&amp;rsquo;t be sorted. For example, we have no way of estimating size for &amp;ldquo;Looks Like&amp;rdquo;, &amp;ldquo;Mix&amp;rdquo;, &amp;ldquo;Purebred&amp;rdquo;, &amp;ldquo;See Notes&amp;rdquo; or &amp;ldquo;Unspecified&amp;rdquo;, so I&amp;rsquo;ll make the sizes of all of those &amp;ldquo;NA&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_2$Primary.Breed &amp;lt;- gsub(&amp;quot;Looks Like|^Mix$|NULL|Purebred|See Notes|Unspecified|^Curs$&amp;quot;, 
    NA, dogs_2$Primary.Breed)

# Calculate how many are missing now
missing_size_3 &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg)) %&amp;gt;% group_by(Primary.Breed) %&amp;gt;% 
    summarise(count = n())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So of our remaining 3,503 dogs, how many of them have sizes that we can&amp;rsquo;t estimate?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size_3[which(is.na(missing_size_3)), ]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   Primary.Breed count
##           &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
## 1          &amp;lt;NA&amp;gt;  1313
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can&amp;rsquo;t estimate 1,313 dogs&amp;rsquo; sizes, which means that we can still estimate the size of the remaining 2,190 dogs. We only have a few species left, and it looks like they weren&amp;rsquo;t ones that were in our original weights dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;missing_size_3$Primary.Breed
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Amer. Pitbull Terrier&amp;quot;  &amp;quot;Appenzel Mountain Dog&amp;quot; 
##  [3] &amp;quot;Belgian Shepherd&amp;quot;       &amp;quot;Bulldog&amp;quot;               
##  [5] &amp;quot;Carolina&amp;quot;               &amp;quot;Cirneco Dell Etna&amp;quot;     
##  [7] &amp;quot;Dingo&amp;quot;                  &amp;quot;Entlebucher&amp;quot;           
##  [9] &amp;quot;Formosan Mountain Dog&amp;quot;  &amp;quot;Hound&amp;quot;                 
## [11] &amp;quot;Kyi-Leo&amp;quot;                &amp;quot;Landseer&amp;quot;              
## [13] &amp;quot;McNab&amp;quot;                  &amp;quot;Norwegian Lundehund&amp;quot;   
## [15] &amp;quot;Saluki&amp;quot;                 &amp;quot;Shepherd&amp;quot;              
## [17] &amp;quot;Silken Windhound&amp;quot;       &amp;quot;Spaniel&amp;quot;               
## [19] &amp;quot;Terrier&amp;quot;                &amp;quot;Toy Manchester Terrier&amp;quot;
## [21] &amp;quot;Welsh Springer Spaniel&amp;quot; &amp;quot;Wolf Hybrid&amp;quot;           
## [23] &amp;quot;Xolo&amp;quot;                   NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since there are only a few breeds left, I will manually create a database of the average weights (all found on the Wikipedia pages for the species).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll upload in the supplemental file and match the breed name and mass.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Import File
supp_weight &amp;lt;- read.csv(file = &amp;quot;Supp_Breed_Wt.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)

# Make a copy of our filtered dataset
dogs_3 &amp;lt;- dogs_2 %&amp;gt;% filter(is.na(Male_Avg))

dogs_4 &amp;lt;- dogs_2 %&amp;gt;% filter(!is.na(Male_Avg))

# Match dog breed from dogs dataset to breed from
# weight_split_all dataset
dogs_3$Male_Avg &amp;lt;- supp_weight[match(dogs_3$Primary.Breed, supp_weight$Breed), 
    &amp;quot;Male_Avg&amp;quot;]

dogs_3$Male_Avg &amp;lt;- as.numeric(dogs_3$Male_Avg)

dogs_3$Female_Avg &amp;lt;- supp_weight[match(dogs_3$Primary.Breed, 
    supp_weight$Breed), &amp;quot;Female_Avg&amp;quot;]

dogs_3$Female_Avg &amp;lt;- as.numeric(dogs_3$Female_Avg)

# Bind datasets back together
dogs_5 &amp;lt;- rbind(dogs_3, dogs_4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(dogs_5$Male_Avg)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    5.00   16.00   50.00   45.77   72.50  182.50    1313
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Awesome! So the only dogs that we still don&amp;rsquo;t have approximate weights on are the ones with miscoded breeds. Now let&amp;rsquo;s get a better approximation of weight based on gender.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_5$Gender &amp;lt;- as.factor(dogs_5$Gender)

dogs_5 &amp;lt;- dogs_5 %&amp;gt;% mutate(weight = ifelse(Gender == &amp;quot;Female&amp;quot;, 
    Female_Avg, Male_Avg))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Now we can make an estimate of how they would be categorized on &amp;ldquo;&lt;a href=&#34;www.rover.com&#34;&gt;Rover.com&lt;/a&gt;&amp;rdquo;, a Seattle-based website aimed at helping dog-owners find reliable dog-sitters and walkers. Their website lists the following size cutoffs (in lbs):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Small = 0 - 15&lt;/li&gt;
&lt;li&gt;Medium = 16 - 40&lt;/li&gt;
&lt;li&gt;Large = 41 - 100&lt;/li&gt;
&lt;li&gt;Giant = 100 +&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s add those classifications to our dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_5 &amp;lt;- dogs_5 %&amp;gt;% mutate(size_class = ifelse(weight &amp;lt;= 15, 
    &amp;quot;Small&amp;quot;, ifelse(weight &amp;gt; 15 &amp;amp; weight &amp;lt;= 40, &amp;quot;Medium&amp;quot;, ifelse(weight &amp;gt; 
        40 &amp;amp; weight &amp;lt;= 100, &amp;quot;Large&amp;quot;, ifelse(weight &amp;gt; 100, &amp;quot;Giant&amp;quot;, 
        NA)))))

dogs_5$size_class &amp;lt;- as.factor(dogs_5$size_class)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ve got information on dogs, with their breeds, zipcodes and approximate sizes and size classes. This will help us later.&lt;/p&gt;

&lt;h2 id=&#34;data-visualizations&#34;&gt;Data Visualizations&lt;/h2&gt;

&lt;h3 id=&#34;dog-popularity-by-breed&#34;&gt;Dog Popularity &amp;ndash; By Breed&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s look at some visualizations. We&amp;rsquo;ll start with the popularity of each dog breed within Seattle. This figure shows the top 24 most popular breeds in the city.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-23-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Looks like labrador retrievers are by far the most popular breed of dog in Seattle.&lt;/p&gt;

&lt;h3 id=&#34;dog-popularity-by-size&#34;&gt;Dog Popularity &amp;ndash; By Size&lt;/h3&gt;

&lt;p&gt;How do the numbers of dogs break down by dog size?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-24-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For a city filled with apartment buildings, Seattle-ites really love large dogs (almost as much as medium and small dogs combined!).&lt;/p&gt;

&lt;p&gt;I wonder if this trend varies depending on which part of the city the pets are living in.&lt;/p&gt;

&lt;h3 id=&#34;dog-populations-by-zip-code&#34;&gt;Dog Populations by Zip Code&lt;/h3&gt;

&lt;p&gt;First let&amp;rsquo;s see the density of dogs living in each zip code. Looks like we have some messy zip code data with quite a few zip codes not falling in the Seattle area. We&amp;rsquo;ll use a list of &lt;a href=&#34;http://www.unitedstateszipcodes.org/wa/#zips-list&#34;&gt;Washington State zip codes&lt;/a&gt; to narrow this list down.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Import Zipcode dataset
zipcodes &amp;lt;- read.csv(&amp;quot;Zipcodes.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)

# Match zipcodes in database to those listed on dog licenses
dogs_5$zip &amp;lt;- zipcodes[match(dogs_5$Zip.C, zipcodes$ZIP), &amp;quot;ZIP&amp;quot;]

# Make zipcodes factors
dogs_5$zip &amp;lt;- as.factor(dogs_5$zip)

# How many are missing?
sum(is.na(dogs_5$zip))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 365
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so there were 365 dog licenses that didn&amp;rsquo;t list appropriate zip codes. That&amp;rsquo;s alright, that&amp;rsquo;s less than 1% of our dataset. Let&amp;rsquo;s move forward.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It looks like several of the zipcodes listed are &amp;ldquo;industrial&amp;rdquo; zip codes. We&amp;rsquo;ll replace the zip code with the residential zip code that each industrial one falls within.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-26-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like the highest populations of licensed dogs are found in zipcodes 98115, 98103, and 98117. That corresponds roughly to Northeast Seattle, the area between Fremont and Greenwood, and the Ballard to Crown Hill area. It is certainly possible that the high dog populations in those areas could be correlated with the human population in the same areas. Let&amp;rsquo;s see how many licensed dogs there are per person in these areas.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Human Population Data Obtained &lt;a href=&#34;http://zipatlas.com/us/wa/seattle/zip-code-comparison/population-density.htm&#34;&gt;Here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;human_pop &amp;lt;- read.csv(&amp;quot;Human_Pop.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)

# Make a copy of our dataset (dog populations by zipcode)
pop_zip_2 &amp;lt;- pop_zip

# Match human populations from new dataset to zipcodes from
# dog population dataset
pop_zip_2$h_pop &amp;lt;- human_pop[match(pop_zip_2$region, human_pop$Zip), 
    &amp;quot;Population&amp;quot;]
pop_zip_2$h_pop &amp;lt;- gsub(&amp;quot;,&amp;quot;, &amp;quot;&amp;quot;, pop_zip_2$h_pop)
pop_zip_2$h_pop &amp;lt;- as.numeric(pop_zip_2$h_pop)


# Create new factor: dog_human (i.e. ratio of dogs to humans)
pop_zip_2 &amp;lt;- pop_zip_2 %&amp;gt;% filter(!is.na(h_pop)) %&amp;gt;% filter(h_pop &amp;gt; 
    10) %&amp;gt;% mutate(dog_human = value/h_pop) %&amp;gt;% select(1, 4)

# Change variable names for choroplethrZip
pop_zip_2 &amp;lt;- rename(pop_zip_2, value = dog_human)

# Plot
zip_choropleth(pop_zip_2, zip_zoom = (pop_zip_2$region), legend = &amp;quot;Dog:Human Ratio&amp;quot;, 
    reference_map = TRUE, num_colors = 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-27-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Generally speaking, central Seattle has a higher &amp;ldquo;Licensed Dogs : People&amp;rdquo; Ratio than the neighborhoods along the north and south edges. The highest proportion is found in zipcode 98117 or the Ballard to Crown Hill area with roughly 1 licensed dog for every 10 people. That is a residential area with lots of homes and fewer apartment buildings than the downtown-area.&lt;/p&gt;

&lt;p&gt;I wonder if there are more large dogs in those house-filled areas and small dogs in apartment-laden areas. Let&amp;rsquo;s map dog populations by their size.&lt;/p&gt;

&lt;p&gt;These figures will be proportions of small, medium, large and giant dogs in proportion to the number of dogs in each zipcode.&lt;/p&gt;

&lt;h3 id=&#34;dog-populations-by-size&#34;&gt;Dog Populations by Size&lt;/h3&gt;

&lt;h4 id=&#34;small&#34;&gt;Small&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-28-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;medium&#34;&gt;Medium&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-29-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;large&#34;&gt;Large&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-30-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;giant&#34;&gt;Giant&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-31-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;caveats-of-dog-size-by-zipcode&#34;&gt;Caveats of Dog Size by Zipcode&lt;/h3&gt;

&lt;p&gt;Wow! Looks like the largest proportion of small dogs is quite concentrated to zipcodes 98134 (Industrial District) and 98101 (Downtown Seattle, near Pike Place Market). These zip codes do have relatively small total dog populations though, totalling at only 38 and 487 dogs, respectively.&lt;/p&gt;

&lt;p&gt;Medium, large and giant sized dogs have a generally more consistent proportional distribution throughout the city. Both medium and large dogs have a higher than average proportion in zip code 98155, but again, this area boasts a small overall dog population (17 dogs total).&lt;/p&gt;

&lt;h3 id=&#34;dog-names&#34;&gt;Dog Names&lt;/h3&gt;

&lt;p&gt;Just for fun, let&amp;rsquo;s take a look at the most popular dog names in Seattle. Word cloud, anyone?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a corpus
names &amp;lt;- Corpus(VectorSource(dogs_5$Name))

# Convert to plain text document
names &amp;lt;- tm_map(names, PlainTextDocument)

# Remove numbers and punctuation, just in case
names &amp;lt;- tm_map(names, removeNumbers)
names &amp;lt;- tm_map(names, removePunctuation)

# Make all names lowercase
names &amp;lt;- tm_map(names, content_transformer(tolower))


# Generate the wordcloud
wordcloud(names, scale = c(5, 0.2), max.words = 150, random.order = FALSE, 
    rot.per = 0.35, use.r.layout = TRUE, colors = brewer.pal(6, 
        &amp;quot;Greens&amp;quot;)[c(4, 5, 6, 7, 8, 9)])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-32-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Oops! Looks like a few of those are probably not real names. We&amp;rsquo;ll go ahead and remove &amp;ldquo;dog&amp;rdquo;, &amp;ldquo;null&amp;rdquo;, &amp;ldquo;altered&amp;rdquo;, &amp;ldquo;female&amp;rdquo;, &amp;ldquo;male&amp;rdquo;, &amp;ldquo;labrador&amp;rdquo;, &amp;ldquo;retriever&amp;rdquo;, &amp;ldquo;year&amp;rdquo;, and &amp;ldquo;seattle&amp;rdquo; from the wordcloud.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Remove non-names
names_2 &amp;lt;- tm_map(names, removeWords, c(&amp;quot;dog&amp;quot;, &amp;quot;null&amp;quot;, &amp;quot;seattle&amp;quot;, 
    &amp;quot;altered&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;, &amp;quot;labrador&amp;quot;, &amp;quot;retriever&amp;quot;, &amp;quot;year&amp;quot;))

# Generate the wordcloud
wordcloud(names_2, scale = c(5, 0.2), max.words = 150, random.order = FALSE, 
    rot.per = 0.25, use.r.layout = TRUE, colors = brewer.pal(6, 
        &amp;quot;Greens&amp;quot;)[c(4, 5, 6, 7, 8, 9)])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Seattle_Dogs_files/figure-markdown_github/unnamed-chunk-33-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Lucy looks like the clear winner here!&lt;/p&gt;

&lt;p&gt;Looks like some other well-known dog names (like Buddy) are pretty common in Seattle. How about &amp;ldquo;Rover&amp;rdquo;?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dogs_5 %&amp;gt;% filter(Name == &amp;quot;Rover&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##            License.Type.Sold Gender          Primary.Breed Primary.Color
## 1         Dog Altered 1 year   Male        German Shepherd          Rust
## 2         Dog Altered 1 year   Male     Labrador Retriever       Chocola
## 3         Dog Altered 2 year   Male                Maltese           Red
## 4         Dog Altered 2 year   Male     Labrador Retriever         Black
## 5         Dog Altered 2 year   Male  Australian Cattle Dog         Black
## 6 Dog Unaltered SR/HC 2 year   Male American Water Spaniel         Liver
##    Name Zip.C Male_Avg Female_Avg weight size_class   zip
## 1 Rover 98112     85.0       85.0   85.0      Large 98112
## 2 Rover 98103     72.5       62.5   72.5      Large 98103
## 3 Rover 98103      5.5        5.5    5.5      Small 98103
## 4 Rover 98122     72.5       62.5   72.5      Large 98122
## 5 Rover 98125     40.0       40.0   40.0     Medium 98125
## 6 Rover 98117     37.5       32.5   37.5     Medium 98117
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are 6 licensed dogs in Seattle named Rover!&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Dogs are basically everywhere in Seattle, but are most highly concentrated closer to the center of the city rather than on bordering neighborhoods.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Regardless of apartment-living, Seattle-ites are big fans of big dogs throughout the city.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The highest dog to human ratio is found in the Ballard to Crown Hill area, with nearly 1 dog per 10 people.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generally, Seattle would be a great place to be a dog sitter or walker. To increase the likelihood of finding customers, I&amp;rsquo;d suggest being open to walking or pet-sitting large dogs where possible.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For a company like Rover.com which aims to connect dog-parents to dog sitters and walkers, I&amp;rsquo;d recommend providing this type of city-wide breakdown to potential sitters. I&amp;rsquo;d also suggest reaching out to large-dog owners to investigate their interest in becoming a sitter of other large dogs.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Without both sitter and user data from Rover.com, I am unable to make recommendations regarding the best neighborhood to become a dog sitter.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bicycle Sharing in Seattle</title>
      <link>/projects/Bicycle_Sharing_2/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/Bicycle_Sharing_2/</guid>
      <description>&lt;p&gt;Data exploration, mapping, and data visualizations in RMarkdown.
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-data&#34;&gt;Importing Data&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data-structures-and-variables&#34;&gt;Data Structures and Variables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-visualizations&#34;&gt;Data Visualizations&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-the-stations-dataset&#34;&gt;Exploring the Stations Dataset&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#station-installations&#34;&gt;Station Installations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#current-station-size&#34;&gt;Current Station Size&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-the-trips-dataset&#34;&gt;Exploring the Trips Dataset&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#plotting-trips-per-month-by-season&#34;&gt;Plotting Trips Per Month (By Season)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#average-trip-duration&#34;&gt;Average Trip Duration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#number-of-trips-by-day-of-week&#34;&gt;Number of Trips by Day of Week&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#number-of-trips-by-time-of-day&#34;&gt;Number of Trips by Time of Day&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#number-of-trips-by-member-type&#34;&gt;Number of Trips by Member Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trip-duration-by-member-type&#34;&gt;Trip Duration by Member Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#member-demographics&#34;&gt;Member Demographics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trip-routes&#34;&gt;Trip Routes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#station-by-trip-departure-and-arrival&#34;&gt;Station by Trip Departure and arrival&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#station-usage&#34;&gt;Station Usage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-the-weather-dataset&#34;&gt;Exploring the Weather Dataset&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#temperature&#34;&gt;Temperature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#events&#34;&gt;Events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combining-weather-and-trip-datasets&#34;&gt;Combining Weather and Trip Datasets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mean-temperature-vs.-number-of-trips&#34;&gt;Mean Temperature vs. Number of Trips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#precipitation-vs.-number-of-trips&#34;&gt;Precipitation vs. Number of Trips&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#suggestions-for-pronto&#34;&gt;Suggestions for Pronto!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is an exploration of bicycle-sharing data in the city of Seattle, WA (USA) from October 2014 - August 2016. I hope to eventually combine this data with other forms of ride-sharing and transportation in the city, but this will be the first step.&lt;/p&gt;

&lt;p&gt;Time to get started!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For data manipulation and tidying
library(dplyr)
library(lubridate)
library(tidyr)

# For mapping
library(ggmap)
library(mapproj)

# For data visualizations
library(ggplot2)

# For modeling and machine learning
library(caret)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-data&#34;&gt;Importing Data&lt;/h3&gt;

&lt;p&gt;All of the data can be downloaded from the bicycle-sharing service &lt;a href=&#34;https://www.prontocycleshare.com/data&#34;&gt;&amp;ldquo;Pronto!&amp;rdquo;&amp;rsquo;s website&lt;/a&gt; or from &lt;a href=&#34;https://www.kaggle.com/pronto/cycle-share-dataset&#34;&gt;Kaggle&lt;/a&gt;. This project contains 3 data sets and I&amp;rsquo;ll import and inspect each data file independently.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station &amp;lt;- read.csv(file = &amp;quot;2016_station_data.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)

trip &amp;lt;- read.csv(file = &amp;quot;2016_trip_data.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)

weather &amp;lt;- read.csv(file = &amp;quot;2016_weather_data.csv&amp;quot;, header = TRUE, 
    stringsAsFactors = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, let&amp;rsquo;s take a look at each of these data files.&lt;/p&gt;

&lt;h4 id=&#34;data-structures-and-variables&#34;&gt;Data Structures and Variables&lt;/h4&gt;

&lt;h5 id=&#34;station&#34;&gt;Station&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 58
## Variables: 9
## $ station_id        &amp;lt;chr&amp;gt; &amp;quot;BT-01&amp;quot;, &amp;quot;BT-03&amp;quot;, &amp;quot;BT-04&amp;quot;, &amp;quot;BT-05&amp;quot;, &amp;quot;CBD-03&amp;quot;...
## $ name              &amp;lt;chr&amp;gt; &amp;quot;3rd Ave &amp;amp; Broad St&amp;quot;, &amp;quot;2nd Ave &amp;amp; Vine St&amp;quot;, &amp;quot;...
## $ lat               &amp;lt;dbl&amp;gt; 47.61842, 47.61583, 47.61609, 47.61311, 47.6...
## $ long              &amp;lt;dbl&amp;gt; -122.3510, -122.3486, -122.3411, -122.3442, ...
## $ install_date      &amp;lt;chr&amp;gt; &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/13/2014&amp;quot;, &amp;quot;1...
## $ install_dockcount &amp;lt;int&amp;gt; 18, 16, 16, 14, 20, 18, 20, 20, 20, 18, 16, ...
## $ modification_date &amp;lt;chr&amp;gt; &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;11/9/2015&amp;quot;, &amp;quot;&amp;quot;,...
## $ current_dockcount &amp;lt;int&amp;gt; 18, 16, 16, 14, 20, 18, 20, 18, 20, 18, 0, 1...
## $ decommission_date &amp;lt;chr&amp;gt; &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;8/9...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like this dataset is dealing with 9 variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Station ID&lt;/strong&gt; : The individual ID number for a bike station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt; : The name of that station ID, also appears to be the rough location of the station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latitude&lt;/strong&gt; : The latitude of the station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Longitude&lt;/strong&gt; : The longitude of the station&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install Date&lt;/strong&gt; : When that particular station was installed (in MM/DD/YYYY format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install Dock Count&lt;/strong&gt; : Number of docks (bike positions) available at each station on installation day&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modification Date&lt;/strong&gt; : When a particular station was modified (in MM/DD/YYYY format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Current Dock Count&lt;/strong&gt; : Number of docks (bike positions) available at each station on August 31, 2016&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decommission Date&lt;/strong&gt; : The date that a particular station was put out of service (in MM/DD/YYYY format)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;trip&#34;&gt;Trip&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 236,065
## Variables: 12
## $ trip_id           &amp;lt;int&amp;gt; 431, 432, 433, 434, 435, 436, 437, 438, 439,...
## $ starttime         &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:31&amp;quot;, &amp;quot;10/13/2014 10:32&amp;quot;, &amp;quot;10/...
## $ stoptime          &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/...
## $ bikeid            &amp;lt;chr&amp;gt; &amp;quot;SEA00298&amp;quot;, &amp;quot;SEA00195&amp;quot;, &amp;quot;SEA00486&amp;quot;, &amp;quot;SEA0033...
## $ tripduration      &amp;lt;dbl&amp;gt; 985.935, 926.375, 883.831, 865.937, 923.923,...
## $ from_station_name &amp;lt;chr&amp;gt; &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;, &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;...
## $ to_station_name   &amp;lt;chr&amp;gt; &amp;quot;Occidental Park / Occidental Ave S &amp;amp; S Wash...
## $ from_station_id   &amp;lt;chr&amp;gt; &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD...
## $ to_station_id     &amp;lt;chr&amp;gt; &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;,...
## $ usertype          &amp;lt;chr&amp;gt; &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Mem...
## $ gender            &amp;lt;chr&amp;gt; &amp;quot;Male&amp;quot;, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;, ...
## $ birthyear         &amp;lt;int&amp;gt; 1960, 1970, 1988, 1977, 1971, 1974, 1978, 19...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This dataset appears to contain 12 variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Trip ID&lt;/strong&gt; : An identification number assigned to each trip (from one bike station to another)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Start Time&lt;/strong&gt; : The time and date that a bike was borrowed from a station (in MM/DD/YYYY HH:MM format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stop Time&lt;/strong&gt; : The time and date that a bike was returned to a station (in MM/DD/YYYY HH:MM format)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bike ID&lt;/strong&gt; : The identification number for a specific bike&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trip Duration&lt;/strong&gt; : Time of trip (measured in seconds)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;From Station Name&lt;/strong&gt; : The name of the station where the bike was borrowed from&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To Station Name&lt;/strong&gt; : The name of the station where the bike was returned to&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;From Station ID&lt;/strong&gt; : The ID number of the station where the bike was borrowed from&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;To Station ID&lt;/strong&gt; : The ID number of the station where the bike was returned to&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User Type&lt;/strong&gt; : Indicates whether the user was a &amp;ldquo;Member&amp;rdquo; (i.e., someone with a monthly or annual membership to Pronto!) or a &amp;ldquo;Short-Term Pass Holder&amp;rdquo; (i.e., someone who purchased a 24 hour or 3 day pass)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gender&lt;/strong&gt; : The gender of the rider (if known)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Birth Year&lt;/strong&gt; : The year that the rider was born&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;weather&#34;&gt;Weather&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 689
## Variables: 21
## $ Date                       &amp;lt;chr&amp;gt; &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/14/2014&amp;quot;, &amp;quot;10/15/...
## $ Max_Temperature_F          &amp;lt;int&amp;gt; 71, 63, 62, 71, 64, 68, 73, 66, 64,...
## $ Mean_Temperature_F         &amp;lt;int&amp;gt; 62, 59, 58, 61, 60, 64, 64, 60, 58,...
## $ Min_TemperatureF           &amp;lt;int&amp;gt; 54, 55, 54, 52, 57, 59, 55, 55, 55,...
## $ Max_Dew_Point_F            &amp;lt;int&amp;gt; 55, 52, 53, 49, 55, 59, 57, 57, 52,...
## $ MeanDew_Point_F            &amp;lt;int&amp;gt; 51, 51, 50, 46, 51, 57, 55, 54, 49,...
## $ Min_Dewpoint_F             &amp;lt;int&amp;gt; 46, 50, 46, 42, 41, 55, 53, 50, 46,...
## $ Max_Humidity               &amp;lt;int&amp;gt; 87, 88, 87, 83, 87, 90, 94, 90, 87,...
## $ Mean_Humidity              &amp;lt;int&amp;gt; 68, 78, 77, 61, 72, 83, 74, 78, 70,...
## $ Min_Humidity               &amp;lt;int&amp;gt; 46, 63, 67, 36, 46, 68, 52, 67, 58,...
## $ Max_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 30.03, 29.84, 29.98, 30.03, 29.83, ...
## $ Mean_Sea_Level_Pressure_In &amp;lt;dbl&amp;gt; 29.79, 29.75, 29.71, 29.95, 29.78, ...
## $ Min_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 29.65, 29.54, 29.51, 29.81, 29.73, ...
## $ Max_Visibility_Miles       &amp;lt;int&amp;gt; 10, 10, 10, 10, 10, 10, 10, 10, 10,...
## $ Mean_Visibility_Miles      &amp;lt;int&amp;gt; 10, 9, 9, 10, 10, 8, 10, 10, 10, 6,...
## $ Min_Visibility_Miles       &amp;lt;int&amp;gt; 4, 3, 3, 10, 6, 2, 6, 5, 6, 2, 10, ...
## $ Max_Wind_Speed_MPH         &amp;lt;int&amp;gt; 13, 10, 18, 9, 8, 10, 10, 12, 15, 1...
## $ Mean_Wind_Speed_MPH        &amp;lt;int&amp;gt; 4, 5, 7, 4, 3, 4, 3, 5, 8, 8, 9, 4,...
## $ Max_Gust_Speed_MPH         &amp;lt;chr&amp;gt; &amp;quot;21&amp;quot;, &amp;quot;17&amp;quot;, &amp;quot;25&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;1...
## $ Precipitation_In           &amp;lt;dbl&amp;gt; 0.00, 0.11, 0.45, 0.00, 0.14, 0.31,...
## $ Events                     &amp;lt;chr&amp;gt; &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Ra...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This dataset represents quite a bit of weather data in 21 variables.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Date&lt;/strong&gt; : The date in MM/DD/YYYY format&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Temperature F&lt;/strong&gt; : The maximum temperature that day (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Temperature F&lt;/strong&gt; : The average temperature that day (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Temperature F&lt;/strong&gt; : The minimum temperature that day (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Dew Point F&lt;/strong&gt; : The maximum dew point (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Dew Point F&lt;/strong&gt; : The average dew point (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Dew Point F&lt;/strong&gt; : The minimum dew point (in degrees F)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Humidity&lt;/strong&gt; : The maximum humidity (in %)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Humidity&lt;/strong&gt; : The average humidity (in %)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Humidity&lt;/strong&gt; : The minimum humidity (in %)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maximum Sea Level Pressure&lt;/strong&gt; : The maximum atmospheric pressure at sea level (in inches of mercury)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Sea Level Pressure&lt;/strong&gt; : The average atmospheric pressure at sea level (in inches of mercury)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Sea Level Pressure&lt;/strong&gt; : The minimum atmospheric pressure at sea level (in inches of mercury)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Visibility Miles&lt;/strong&gt; : The maximum visibility (in miles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Visibility Miles&lt;/strong&gt; : The average visibility (in miles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Min Visibility Miles&lt;/strong&gt; : The minimum visibility (in miles)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Wind Speed MPH&lt;/strong&gt; : The maximum sustained wind speed (in miles per hour)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mean Wind Speed MPH&lt;/strong&gt; : The average sustained wind speed (in miles per hour)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Max Gust Speed MPH&lt;/strong&gt; : The maximum gust wind speed (in miles per hour)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Precipitation&lt;/strong&gt; : The amount of precipitation (measured in inches)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Events&lt;/strong&gt; : Weather events that occurred that day (e.g., rain, fog, snow, thunderstorm etc.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;data-visualizations&#34;&gt;Data Visualizations&lt;/h2&gt;

&lt;h3 id=&#34;exploring-the-stations-dataset&#34;&gt;Exploring the Stations Dataset&lt;/h3&gt;

&lt;p&gt;Since the &amp;ldquo;Stations&amp;rdquo; dataset was the first one I imported, let&amp;rsquo;s start with a little exploration there. First of all, how many unique stations are we dealing with?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station %&amp;gt;% summarise(n_distinct(station_id))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   n_distinct(station_id)
## 1                     58
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! 58 different stations! Let&amp;rsquo;s take a quick peek at where they are located.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station_locs &amp;lt;- station %&amp;gt;% group_by(station_id) %&amp;gt;% select(1:4, 
    -2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Load the correct map
mymap &amp;lt;- get_map(location = &amp;quot;Seattle&amp;quot;, maptype = &amp;quot;roadmap&amp;quot;, zoom = 12)

# Plot a single point for each Station ID
ggmap(mymap) + geom_point(aes(x = long, y = lat), data = station_locs, 
    alpha = 0.7, color = &amp;quot;darkred&amp;quot;, size = 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-8-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So it looks like all of the stations are located near the Lower Queen Anne, Belltown, International District, Capitol Hill and University of Washington areas. Let&amp;rsquo;s take a more zoomed-in look.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-9-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Great! So the locations are pretty well clustered. I wonder what order they were added in.&lt;/p&gt;

&lt;h4 id=&#34;station-installations&#34;&gt;Station Installations&lt;/h4&gt;

&lt;p&gt;First, let&amp;rsquo;s convert those character-string date objects to actual dates using the &lt;code&gt;lubridate&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;station$install_date &amp;lt;- mdy(station$install_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many times were new stations installed?
station %&amp;gt;% summarise(n_distinct(install_date))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   n_distinct(install_date)
## 1                        9
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many stations were installed on each date?
station %&amp;gt;% group_by(install_date) %&amp;gt;% summarise(count = n()) %&amp;gt;% 
    arrange(install_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 2
##   install_date count
##         &amp;lt;date&amp;gt; &amp;lt;int&amp;gt;
## 1   2014-10-13    50
## 2   2015-05-22     1
## 3   2015-06-12     1
## 4   2015-07-27     1
## 5   2015-09-15     1
## 6   2015-10-29     1
## 7   2016-03-18     1
## 8   2016-07-03     1
## 9   2016-08-09     1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like the vast majority (86%) of the stations were added on opening day. Let&amp;rsquo;s see where those original ones were and where the rest were added.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-12-1.png&#34; alt=&#34;&#34; /&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-12-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So they added more stations throughout the district that they serve, instead of adding several new stations to a single neighborhood all at once. Good to know.&lt;/p&gt;

&lt;p&gt;Now, I wonder how many bikes can be parked at each station (as of August 31,2016)?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-13-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well that&amp;rsquo;s weird, some of the stations have a dock count of 0. I&amp;rsquo;m assuming they didn&amp;rsquo;t start that way. Let&amp;rsquo;s calculate the change in dock count from station installation to August 31, 2016 and plot it on a map.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dock_change &amp;lt;- station %&amp;gt;% group_by(station_id) %&amp;gt;% select(station_id, 
    long, lat, ends_with(&amp;quot;dockcount&amp;quot;)) %&amp;gt;% mutate(dock_change = current_dockcount - 
    install_dockcount)
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;change-in-number-of-bike-docks-per-station&#34;&gt;Change in Number of Bike Docks Per Station&lt;/h5&gt;

&lt;p&gt;Any stations with no change in number of docks are not shown here. &lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-15-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Looks like quite a few stations took away bike docks and none gained any. Perhaps those stations weren&amp;rsquo;t being used very frequently. We&amp;rsquo;ll have to look at that a bit later.&lt;/p&gt;

&lt;h4 id=&#34;current-station-size&#34;&gt;Current Station Size&lt;/h4&gt;

&lt;p&gt;I&amp;rsquo;m going to take one quick look at the current size of each station before moving on to the next dataset. &lt;em&gt;Note: I did not include any stations that were closed as of August 31, 2016 in this map&lt;/em&gt; &lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-16-1.png&#34;  class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So it looks like the biggest stations tend to be on the outskirts of the rest. Where there are several stations in close proximity, there tend to be fewer bike docks at each station. That makes sense, logically speaking. If you go to a station and there is no bike to rent, you can easily go to another nearby, assuming there is another nearby. In areas where the stations are more secluded, it&amp;rsquo;s more important that there be bikes and open spaces readily available for users.&lt;/p&gt;

&lt;p&gt;Alright, I&amp;rsquo;m feeling good about exploring this dataset. Time to check out the trip dataset!&lt;/p&gt;

&lt;h3 id=&#34;exploring-the-trips-dataset&#34;&gt;Exploring the Trips Dataset&lt;/h3&gt;

&lt;p&gt;It&amp;rsquo;s been a while since we&amp;rsquo;ve looked at the trip dataset, so let&amp;rsquo;s take another peek at it here.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 236,065
## Variables: 12
## $ trip_id           &amp;lt;int&amp;gt; 431, 432, 433, 434, 435, 436, 437, 438, 439,...
## $ starttime         &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:31&amp;quot;, &amp;quot;10/13/2014 10:32&amp;quot;, &amp;quot;10/...
## $ stoptime          &amp;lt;chr&amp;gt; &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/13/2014 10:48&amp;quot;, &amp;quot;10/...
## $ bikeid            &amp;lt;chr&amp;gt; &amp;quot;SEA00298&amp;quot;, &amp;quot;SEA00195&amp;quot;, &amp;quot;SEA00486&amp;quot;, &amp;quot;SEA0033...
## $ tripduration      &amp;lt;dbl&amp;gt; 985.935, 926.375, 883.831, 865.937, 923.923,...
## $ from_station_name &amp;lt;chr&amp;gt; &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;, &amp;quot;2nd Ave &amp;amp; Spring St&amp;quot;...
## $ to_station_name   &amp;lt;chr&amp;gt; &amp;quot;Occidental Park / Occidental Ave S &amp;amp; S Wash...
## $ from_station_id   &amp;lt;chr&amp;gt; &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD-06&amp;quot;, &amp;quot;CBD...
## $ to_station_id     &amp;lt;chr&amp;gt; &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;, &amp;quot;PS-04&amp;quot;,...
## $ usertype          &amp;lt;chr&amp;gt; &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Member&amp;quot;, &amp;quot;Mem...
## $ gender            &amp;lt;chr&amp;gt; &amp;quot;Male&amp;quot;, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Male&amp;quot;, ...
## $ birthyear         &amp;lt;int&amp;gt; 1960, 1970, 1988, 1977, 1971, 1974, 1978, 19...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, so there are quite a few things that we can potentially look at using this dataset by itself. Let&amp;rsquo;s start with the number of trips per day since Pronto! began opening bike stations. To do that, we need to recode our start date/times as POSIXct objects. We&amp;rsquo;ll use the &lt;code&gt;lubridate&lt;/code&gt; package for this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make the start and stop dates into POSIXct objects
trip_2 &amp;lt;- trip %&amp;gt;% mutate(start_dt = mdy_hm(starttime), stop_dt = mdy_hm(stoptime))

# Recode the dates
trip_2 &amp;lt;- trip_2 %&amp;gt;% mutate(start_date = paste(month(start_dt), 
    day(start_dt), year(start_dt), sep = &amp;quot;/&amp;quot;))
trip_2$start_date &amp;lt;- mdy(trip_2$start_date)

trip_2 &amp;lt;- trip_2 %&amp;gt;% mutate(stop_date = paste(month(stop_dt), 
    day(stop_dt), year(stop_dt), sep = &amp;quot;/&amp;quot;))
trip_2$stop_date &amp;lt;- mdy(trip_2$stop_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Time to visualize the number of rides per day.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-19-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, grouping by day is a little noisy. Perhaps we should try by month?&lt;/p&gt;

&lt;h4 id=&#34;plotting-trips-per-month-by-season&#34;&gt;Plotting Trips Per Month (By Season)&lt;/h4&gt;

&lt;p&gt;First, we need to create a &amp;ldquo;Year-Month&amp;rdquo; variable&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;start_date_ym &amp;lt;- trip_2 %&amp;gt;% mutate(ym = paste(year(start_date), 
    month(start_date), sep = &amp;quot;/&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now plot. I think I&amp;rsquo;ll plot this by month but color it by season (where December, January, and February are &amp;ldquo;winter&amp;rdquo;, March, April, and May are &amp;ldquo;spring&amp;rdquo;, June, July, August are &amp;ldquo;summer&amp;rdquo;, and September, October, November are &amp;ldquo;autumn&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-21-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well that intuitively makes sense. The number of trips taken per month increases in the spring, reaches a maximum in the summer, declines through the fall, remains fairly stable in the winter and then repeats.&lt;/p&gt;

&lt;h4 id=&#34;average-trip-duration&#34;&gt;Average Trip Duration&lt;/h4&gt;

&lt;p&gt;Great! I wonder how the average trip duration fluctuates over this time period.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Convert Trip Duration from Seconds to Minutes
Trip_Duration_Month &amp;lt;- start_date_ym %&amp;gt;% mutate(trip_duration_min = tripduration/60) %&amp;gt;% 
    group_by(ym) %&amp;gt;% select(ym, trip_duration_min) %&amp;gt;% summarise(Avg = mean(trip_duration_min), 
    sd = sd(trip_duration_min)) %&amp;gt;% mutate(se = sd/sqrt(n()))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to plot the average trip duration (in minutes) (plus or minus standard error), with colors indicating season.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-23-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s surprisingly not a huge range in trip durations here.&lt;/p&gt;

&lt;p&gt;The little bit of variation here makes logical sense. Longer trips were being taken in the spring and summer months rather than the fall and winter. It&amp;rsquo;s also notable that the spring and summer of 2016 may have shown fewer trips than the previous year, show a slight increase in average trip length.&lt;/p&gt;

&lt;h4 id=&#34;number-of-trips-by-day-of-week&#34;&gt;Number of Trips by Day of Week&lt;/h4&gt;

&lt;p&gt;I wonder if people are using this service to commute to/from work. Let&amp;rsquo;s look at the number of trips by day of the week.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s create a Day of the Week variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_2$wd &amp;lt;- wday(trip_2$start_date, label = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to plot the total number of trips by day of the week.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-25-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ok, so there are definitely more trips during the week than on the weekends. I wonder if this varies by season too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-26-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So it looks like usage is relatively consistent across seasons, at least as far as the number of trips are concerned.&lt;/p&gt;

&lt;h4 id=&#34;number-of-trips-by-time-of-day&#34;&gt;Number of Trips by Time of Day&lt;/h4&gt;

&lt;p&gt;How about time of day? Are people using these around commuting times during the week and later on weekends?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-27-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow, looks like regardless of the season, people are commuting to/from work using this service (there&amp;rsquo;s a spike between 8 and 10 AM and another between 4 and 7 PM Monday through Friday). But the weekends seem to be popular between 10 AM and 10 PM.&lt;/p&gt;

&lt;h4 id=&#34;number-of-trips-by-member-type&#34;&gt;Number of Trips by Member Type&lt;/h4&gt;

&lt;p&gt;I wonder if different types of members (those who have a membership vs. those that bought a 24 hour or 3 day pass) vary in the number of trips they take.&lt;/p&gt;

&lt;p&gt;If I were to guess, I&amp;rsquo;d think the short-term passes would be ideal for tourists or people looking for a quick weekend trip, whereas members may be more likely to continue using the service year-round. Let&amp;rsquo;s check out my assumptions by plotting, once again colored by season.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-28-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Surprisingly (to me, at least), different types of users seem to follow similar patterns of usage. Spring and Summer are definitely the most popular times for anyone to ride a bike in the Seattle area.&lt;/p&gt;

&lt;h4 id=&#34;trip-duration-by-member-type&#34;&gt;Trip Duration by Member Type&lt;/h4&gt;

&lt;p&gt;While it may seem that the trip duration shouldn&amp;rsquo;t vary widely by member type, a quick look at &lt;a href=&#34;https://www.prontocycleshare.com/pricing&#34;&gt;Pronto!&amp;rsquo;s pricing structure&lt;/a&gt; may make you reconsider that assumption. You see, while you have to purchase either an annual membership ($85/year), a 24-Hour Pass ($8) or a 3-Day Pass ($16) there is still a cap on the duration of your trip. For members, any ride under 45 minutes is free, but any ride going over 45 minutes will incur a fee of $2 for every additional 30 minutes. For short-term users, any ride under 30 minutes is free, but going over that time limit would cost you an additional $2 for the first 30 minutes and $5 for each additional 30 minutes after that!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if these time limits cause differing behaviors in our users.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-29-1.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ok, so our members are pretty good about making sure that they return their bike before they incur extra charges, but the short-term pass holders frequently go over their time limit. I wonder how the cost of a trip varies for members and pass holders. Let&amp;rsquo;s try to calculate the cost of a trip.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_cost &amp;lt;- trip_2 %&amp;gt;% mutate(cost = ifelse(usertype == &amp;quot;Member&amp;quot; &amp;amp; 
    tripduration_m &amp;lt;= 45, 0, ifelse(usertype == &amp;quot;Member&amp;quot; &amp;amp; tripduration_m &amp;gt; 
    45 &amp;amp; tripduration_m &amp;lt;= 75, 2, ifelse(usertype == &amp;quot;Member&amp;quot; &amp;amp; 
    tripduration_m &amp;gt; 75, (2 + 5 * ((tripduration_m - 75)/30)), 
    ifelse(usertype == &amp;quot;Short-Term Pass Holder&amp;quot; &amp;amp; tripduration_m &amp;lt;= 
        30, 0, ifelse(usertype == &amp;quot;Short-Term Pass Holder&amp;quot; &amp;amp; 
        tripduration_m &amp;gt; 30 &amp;amp; tripduration_m &amp;lt; 60, 2, ifelse(usertype == 
        &amp;quot;Short-Term Pass Holder&amp;quot; &amp;amp; tripduration_m &amp;gt; 60, (2 + 
        5 * ((tripduration_m - 60)/30)), &amp;quot;unknown&amp;quot;)))))))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was a complicated nested if/else statement! Let&amp;rsquo;s see how much these folks are paying in additional fees!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-31-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like short-term pass holders (who are already paying a higher price per day of biking), are also paying lots of extra fees. This could be because they are unfamiliar with the pricing structure and don&amp;rsquo;t realize they need to return their bike to a station within 30 minutes without getting charged. It is also possible that short-term users may be tourists who don&amp;rsquo;t know their way around as easily, and thus can&amp;rsquo;t find their way to a station within the time limit.&lt;/p&gt;

&lt;h4 id=&#34;member-demographics&#34;&gt;Member Demographics&lt;/h4&gt;

&lt;p&gt;We only seem to have age and gender information about people who have an annual Pronto! membership, so we can at least take a look at what types of people use this service.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look first at age.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_2$usertype &amp;lt;- as.factor(trip_2$usertype)
trip_age &amp;lt;- trip_2 %&amp;gt;% mutate(age = year(start_dt) - birthyear)

hist(trip_age$age, main = &amp;quot;Member Age&amp;quot;, xlab = &amp;quot;Number of Riders&amp;quot;, 
    col = &amp;quot;#56B4E9&amp;quot;, breaks = 25)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-32-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;My first instinct here is to say &amp;ldquo;Wow! There&amp;rsquo;s a lot of 20 and 30-somethings that use this service!&amp;rdquo; But this figure (and these data) may be a little misleading. You see, we don&amp;rsquo;t have any sort of Rider ID number, meaning we can&amp;rsquo;t take &amp;ldquo;individual activity level&amp;rdquo; into account. So we can&amp;rsquo;t tell if the tallest spike is because 5 very athletic 28-year-olds went on 4,000 trips each, or if 100 people went on 200 trips each, or if there were 20,000 28-year-olds who each only used the service once.&lt;/p&gt;

&lt;p&gt;The same problem would arise if we looked at gender, so I&amp;rsquo;m just going to move beyond demographics.&lt;/p&gt;

&lt;h4 id=&#34;trip-routes&#34;&gt;Trip Routes&lt;/h4&gt;

&lt;p&gt;I&amp;rsquo;m going to do my best to look at some potential routes that these users could have taken, given their start and stop locations and duration. All of these data will be analyzed using the &lt;code&gt;ggmap&lt;/code&gt; package and Google Maps API (&lt;a href=&#34;https://journal.r-project.org/archive/2013-1/kahle-wickham.pdf&#34;&gt;more info here&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;To start, I need to combine the coordinates of the station (from the &lt;code&gt;station&lt;/code&gt; dataset) with the data from the &lt;code&gt;trip&lt;/code&gt; dataset. Let&amp;rsquo;s get started.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a dataframe with only station ID, latitude, and
# longitude
station_coord &amp;lt;- station %&amp;gt;% select(station_id, lat, long)

# Trim our trip dataframe to only include start &amp;amp; stop
# dates/times, and station ID
trip_route &amp;lt;- trip_2 %&amp;gt;% select(trip_id, starts_with(&amp;quot;start_&amp;quot;), 
    starts_with(&amp;quot;stop_&amp;quot;), from_station_id, to_station_id, tripduration)

# Match by station ID
trip_route$start_lat &amp;lt;- station_coord[match(trip_route$from_station_id, 
    station_coord$station_id), &amp;quot;lat&amp;quot;]

trip_route$start_long &amp;lt;- station_coord[match(trip_route$from_station_id, 
    station_coord$station_id), &amp;quot;long&amp;quot;]

trip_route$stop_lat &amp;lt;- station_coord[match(trip_route$to_station_id, 
    station_coord$station_id), &amp;quot;lat&amp;quot;]

trip_route$stop_long &amp;lt;- station_coord[match(trip_route$to_station_id, 
    station_coord$station_id), &amp;quot;long&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Now to start looking at routes.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll start by looking at the possible routes of the very first trip.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-34-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Cool! So Google Maps API was able to give us two potential routes for this particular trip. We can make a best guess on which trip was taken by determining the trip duration.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Converting trip duration to minutes
trip_route$tripduration &amp;lt;- trip_route$tripduration/60

# Finding actual trip duration
trip_route[1, &amp;quot;tripduration&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 16.43225
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so the actual trip on October 13, 2014 took 16.4 minutes. Let&amp;rsquo;s see how long each of the hypothetical trips took.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;leg_1 %&amp;gt;% group_by(route) %&amp;gt;% summarise(duration = sum(minutes))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 2
##   route duration
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     A 4.950000
## 2     B 5.583333
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hmm, looks like Google estimates those trips should have only taken between 5 and 6 minutes. It is very possible that our user did not go directly from one station to the other. It&amp;rsquo;s also possible that he got stopped at a few red lights along his route.&lt;/p&gt;

&lt;p&gt;Perhaps this, being the first trip, was a demo of some sort. Let&amp;rsquo;s check out the last trip that was recorded and see if we still run into the same time disconnect.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-37-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt; Well this was certainly a longer ride than the first one we looked at!&lt;/p&gt;

&lt;p&gt;How long did this trip take?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;trip_route[nrow(trip_route), &amp;quot;tripduration&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 31.60052
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so how long did Google estimate it should take?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;leg_2 %&amp;gt;% group_by(route) %&amp;gt;% summarise(duration = sum(minutes))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 2
##   route duration
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     A  9.50000
## 2     B 12.13333
## 3     C 13.45000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once again, the trip took quite a bit longer than any of the routes shown here. It&amp;rsquo;s possible that estimating the routes taken by cyclists is not the best use of this dataset. So, what else is there to look at?&lt;/p&gt;

&lt;h4 id=&#34;station-by-trip-departure-and-arrival&#34;&gt;Station by Trip Departure and arrival&lt;/h4&gt;

&lt;p&gt;I suppose we can see which stations have the most trip departures and which have the most arrivals. Unless people are always making round-trip journeys, these are not likely to be equal.&lt;/p&gt;

&lt;h4 id=&#34;station-usage&#34;&gt;Station Usage&lt;/h4&gt;

&lt;h5 id=&#34;trip-departure&#34;&gt;Trip Departure&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-40-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Great, so it looks like the station that sends the highest number of bikes out and takes the highest number of bikes in is located at Pier 69 / Alaskan Way &amp;amp; Clay Street. Looks like this is pretty close to a few parks and several big tourist attractions.&lt;/p&gt;

&lt;p&gt;Also, if you flip between &amp;ldquo;Departures&amp;rdquo; and &amp;ldquo;Arrivals&amp;rdquo;, you&amp;rsquo;ll notice that quite a few bikes are picked up in the Capitol Hill area, but are returned down by the coast. If you&amp;rsquo;re unfamiliar with Seattle&amp;rsquo;s topography, Capitol Hill is aptly named because it&amp;rsquo;s situated on a very steep hill. It makes sense that people would borrow bikes to ride &lt;em&gt;down&lt;/em&gt; the hill, but not want to borrow a bike to go back &lt;em&gt;up&lt;/em&gt; the hill. Interesting!&lt;/p&gt;

&lt;h5 id=&#34;trip-arrival&#34;&gt;Trip Arrival&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-41-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Great, so it looks like the station that sends the highest number of bikes out and takes the highest number of bikes in is located at Pier 69 / Alaskan Way &amp;amp; Clay Street. Looks like this is pretty close to a few parks and several big tourist attractions.&lt;/p&gt;

&lt;p&gt;Also, if you flip between &amp;ldquo;Departures&amp;rdquo; and &amp;ldquo;Arrivals&amp;rdquo;, you&amp;rsquo;ll notice that quite a few bikes are picked up in the Capitol Hill area, but are returned down by the coast. If you&amp;rsquo;re unfamiliar with Seattle&amp;rsquo;s topography, Capitol Hill is aptly named because it&amp;rsquo;s situated on a very steep hill. It makes sense that people would borrow bikes to ride &lt;em&gt;down&lt;/em&gt; the hill, but not want to borrow a bike to go back &lt;em&gt;up&lt;/em&gt; the hill. Interesting!&lt;/p&gt;

&lt;h3 id=&#34;exploring-the-weather-dataset&#34;&gt;Exploring the Weather Dataset&lt;/h3&gt;

&lt;p&gt;Now that I&amp;rsquo;ve visualized all that I can think of in terms of the &amp;ldquo;trips&amp;rdquo; dataset, it&amp;rsquo;s time to take a brief look at the weather dataset.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get a quick reminder of what we&amp;rsquo;re looking at here.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;glimpse(weather)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 689
## Variables: 21
## $ Date                       &amp;lt;chr&amp;gt; &amp;quot;10/13/2014&amp;quot;, &amp;quot;10/14/2014&amp;quot;, &amp;quot;10/15/...
## $ Max_Temperature_F          &amp;lt;int&amp;gt; 71, 63, 62, 71, 64, 68, 73, 66, 64,...
## $ Mean_Temperature_F         &amp;lt;int&amp;gt; 62, 59, 58, 61, 60, 64, 64, 60, 58,...
## $ Min_TemperatureF           &amp;lt;int&amp;gt; 54, 55, 54, 52, 57, 59, 55, 55, 55,...
## $ Max_Dew_Point_F            &amp;lt;int&amp;gt; 55, 52, 53, 49, 55, 59, 57, 57, 52,...
## $ MeanDew_Point_F            &amp;lt;int&amp;gt; 51, 51, 50, 46, 51, 57, 55, 54, 49,...
## $ Min_Dewpoint_F             &amp;lt;int&amp;gt; 46, 50, 46, 42, 41, 55, 53, 50, 46,...
## $ Max_Humidity               &amp;lt;int&amp;gt; 87, 88, 87, 83, 87, 90, 94, 90, 87,...
## $ Mean_Humidity              &amp;lt;int&amp;gt; 68, 78, 77, 61, 72, 83, 74, 78, 70,...
## $ Min_Humidity               &amp;lt;int&amp;gt; 46, 63, 67, 36, 46, 68, 52, 67, 58,...
## $ Max_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 30.03, 29.84, 29.98, 30.03, 29.83, ...
## $ Mean_Sea_Level_Pressure_In &amp;lt;dbl&amp;gt; 29.79, 29.75, 29.71, 29.95, 29.78, ...
## $ Min_Sea_Level_Pressure_In  &amp;lt;dbl&amp;gt; 29.65, 29.54, 29.51, 29.81, 29.73, ...
## $ Max_Visibility_Miles       &amp;lt;int&amp;gt; 10, 10, 10, 10, 10, 10, 10, 10, 10,...
## $ Mean_Visibility_Miles      &amp;lt;int&amp;gt; 10, 9, 9, 10, 10, 8, 10, 10, 10, 6,...
## $ Min_Visibility_Miles       &amp;lt;int&amp;gt; 4, 3, 3, 10, 6, 2, 6, 5, 6, 2, 10, ...
## $ Max_Wind_Speed_MPH         &amp;lt;int&amp;gt; 13, 10, 18, 9, 8, 10, 10, 12, 15, 1...
## $ Mean_Wind_Speed_MPH        &amp;lt;int&amp;gt; 4, 5, 7, 4, 3, 4, 3, 5, 8, 8, 9, 4,...
## $ Max_Gust_Speed_MPH         &amp;lt;chr&amp;gt; &amp;quot;21&amp;quot;, &amp;quot;17&amp;quot;, &amp;quot;25&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;1...
## $ Precipitation_In           &amp;lt;dbl&amp;gt; 0.00, 0.11, 0.45, 0.00, 0.14, 0.31,...
## $ Events                     &amp;lt;chr&amp;gt; &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Rain&amp;quot;, &amp;quot;Ra...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great, let&amp;rsquo;s change the Date variable to a POSIXct object, and make the &amp;ldquo;Events&amp;rdquo; variable factors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Adjusting the Date Variable
weather$Date &amp;lt;- mdy(weather$Date)

# Adjusting the Events Variable
weather$Events &amp;lt;- as.factor(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great. Now how many weather events are there?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;&amp;quot;                    &amp;quot;Fog&amp;quot;                 &amp;quot;Fog , Rain&amp;quot;         
##  [4] &amp;quot;Fog-Rain&amp;quot;            &amp;quot;Rain&amp;quot;                &amp;quot;Rain , Snow&amp;quot;        
##  [7] &amp;quot;Rain , Thunderstorm&amp;quot; &amp;quot;Rain-Snow&amp;quot;           &amp;quot;Rain-Thunderstorm&amp;quot;  
## [10] &amp;quot;Snow&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow! So mostly combinations of rain&amp;hellip;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s combine a few of these things that seem to represent the same event.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather$Events &amp;lt;- gsub(&amp;quot;Fog , Rain|Fog-Rain&amp;quot;, &amp;quot;Fog-Rain&amp;quot;, weather$Events)
weather$Events &amp;lt;- gsub(&amp;quot;Rain , Snow|Rain-Snow&amp;quot;, &amp;quot;Rain-Snow&amp;quot;, 
    weather$Events)
weather$Events &amp;lt;- gsub(&amp;quot;Rain , Thunderstorm|Rain-Thunderstorm&amp;quot;, 
    &amp;quot;Rain-TS&amp;quot;, weather$Events)

weather$Events &amp;lt;- as.factor(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where else does this dataset need to be cleaned up? Let&amp;rsquo;s look for any missing values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(weather)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       Date            Max_Temperature_F Mean_Temperature_F
##  Min.   :2014-10-13   Min.   :39.00     Min.   :33.00     
##  1st Qu.:2015-04-03   1st Qu.:55.00     1st Qu.:48.00     
##  Median :2015-09-22   Median :63.00     Median :56.00     
##  Mean   :2015-09-22   Mean   :64.03     Mean   :56.58     
##  3rd Qu.:2016-03-12   3rd Qu.:73.00     3rd Qu.:65.00     
##  Max.   :2016-08-31   Max.   :98.00     Max.   :83.00     
##                                         NA&#39;s   :1         
##  Min_TemperatureF Max_Dew_Point_F MeanDew_Point_F Min_Dewpoint_F 
##  Min.   :23.00    Min.   :10.00   Min.   : 4.00   Min.   : 1.00  
##  1st Qu.:43.00    1st Qu.:44.00   1st Qu.:41.00   1st Qu.:36.00  
##  Median :50.00    Median :50.00   Median :46.00   Median :42.00  
##  Mean   :49.45    Mean   :48.57   Mean   :45.02   Mean   :40.87  
##  3rd Qu.:57.00    3rd Qu.:54.00   3rd Qu.:51.00   3rd Qu.:47.00  
##  Max.   :70.00    Max.   :77.00   Max.   :59.00   Max.   :57.00  
##                                                                  
##   Max_Humidity    Mean_Humidity    Min_Humidity  
##  Min.   : 40.00   Min.   :24.00   Min.   :15.00  
##  1st Qu.: 78.00   1st Qu.:60.00   1st Qu.:38.00  
##  Median : 86.00   Median :70.00   Median :50.00  
##  Mean   : 84.54   Mean   :68.51   Mean   :49.97  
##  3rd Qu.: 90.00   3rd Qu.:79.00   3rd Qu.:63.00  
##  Max.   :100.00   Max.   :95.00   Max.   :87.00  
##                                                  
##  Max_Sea_Level_Pressure_In Mean_Sea_Level_Pressure_In
##  Min.   :29.47             Min.   :29.31             
##  1st Qu.:30.01             1st Qu.:29.93             
##  Median :30.12             Median :30.04             
##  Mean   :30.12             Mean   :30.03             
##  3rd Qu.:30.24             3rd Qu.:30.16             
##  Max.   :30.86             Max.   :30.81             
##                                                      
##  Min_Sea_Level_Pressure_In Max_Visibility_Miles Mean_Visibility_Miles
##  Min.   :29.14             Min.   : 3.00        Min.   : 1.00        
##  1st Qu.:29.84             1st Qu.:10.00        1st Qu.: 9.00        
##  Median :29.96             Median :10.00        Median :10.00        
##  Mean   :29.94             Mean   : 9.99        Mean   : 9.43        
##  3rd Qu.:30.08             3rd Qu.:10.00        3rd Qu.:10.00        
##  Max.   :30.75             Max.   :10.00        Max.   :10.00        
##                                                                      
##  Min_Visibility_Miles Max_Wind_Speed_MPH Mean_Wind_Speed_MPH
##  Min.   : 0.000       Min.   : 4.00      Min.   : 0.000     
##  1st Qu.: 4.000       1st Qu.: 8.00      1st Qu.: 3.000     
##  Median : 9.000       Median :10.00      Median : 4.000     
##  Mean   : 7.245       Mean   :11.09      Mean   : 4.631     
##  3rd Qu.:10.000       3rd Qu.:13.00      3rd Qu.: 6.000     
##  Max.   :10.000       Max.   :30.00      Max.   :23.000     
##                                                             
##  Max_Gust_Speed_MPH Precipitation_In       Events   
##  Length:689         Min.   :0.0000            :361  
##  Class :character   1st Qu.:0.0000   Fog      : 16  
##  Mode  :character   Median :0.0000   Fog-Rain : 13  
##                     Mean   :0.1051   Rain     :287  
##                     3rd Qu.:0.0900   Rain-Snow:  3  
##                     Max.   :2.2000   Rain-TS  :  7  
##                                      Snow     :  2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so we have one NA for &amp;ldquo;Mean_Temperature_F&amp;rdquo;, &amp;ldquo;Max_Gust_Speed_MPH&amp;rdquo; seems to be represented as a character vector because it has &amp;ldquo;-&amp;rdquo; representing NA values, and we have 361 unlabelled Events.&lt;/p&gt;

&lt;p&gt;Max Gust Speed should be the easiest one to fix, so we&amp;rsquo;ll start there.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather$Max_Gust_Speed_MPH &amp;lt;- gsub(&amp;quot;-&amp;quot;, 0, weather$Max_Gust_Speed_MPH)

weather$Max_Gust_Speed_MPH &amp;lt;- as.numeric(weather$Max_Gust_Speed_MPH)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! We changed any absent values for Maximum Gust Speed to 0 MPH and changed the variable type to a number. Uh oh, looks like there are still 185 NA values for Max Gust Speed. That&amp;rsquo;s a lot to try to replace. I would normally suggest generating a model that could try to predict those values based on other known values, but for now, we&amp;rsquo;ll just leave it alone.&lt;/p&gt;

&lt;p&gt;Since there is only one missing Mean Temperature, it seems the easiest way to fill in the hole is to look up what the average temperature was that day. &lt;em&gt;Note: I certainly would not recommend this if it were any more than one missing value&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather[which(is.na(weather$Mean_Temperature_F)), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2016-02-14&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so we&amp;rsquo;re looking for the Mean Temperature on February 14, 2016 in the zipcode 98101 (according to dataset documentation). Looks like the mean temperature that day was 50 degrees F.&lt;/p&gt;

&lt;p&gt;Time to substitute in that value.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather[490, &amp;quot;Mean_Temperature_F&amp;quot;] &amp;lt;- &amp;quot;50&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Now what to do with the unlabelled &amp;ldquo;Event&amp;rdquo; categories. The dataset &amp;ldquo;ReadMe&amp;rdquo; file from Pronto! doesn&amp;rsquo;t include any information about this weather dataset. The only thing I can think to do is refer to the Event as &amp;ldquo;Other&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;weather$Events &amp;lt;- gsub(&amp;quot;^$&amp;quot;, &amp;quot;Other&amp;quot;, weather$Events)
weather$Events &amp;lt;- as.factor(weather$Events)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, we&amp;rsquo;re in good shape. Now to do a few quick visualizations.&lt;/p&gt;

&lt;h4 id=&#34;temperature&#34;&gt;Temperature&lt;/h4&gt;

&lt;h5 id=&#34;minimum&#34;&gt;Minimum&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-51-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;mean&#34;&gt;Mean&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-52-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;maximum&#34;&gt;Maximum&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-53-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;events&#34;&gt;Events&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-54-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;combining-weather-and-trip-datasets&#34;&gt;Combining Weather and Trip Datasets&lt;/h4&gt;

&lt;p&gt;Good, so we can now see some parts of the weather data. Let&amp;rsquo;s combine the weather data with our trip data. Let&amp;rsquo;s try a &lt;code&gt;left join&lt;/code&gt; from the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Make a copy of the data frame
trip_3 &amp;lt;- trip_2

# Change column name in trip_3 to match weather dataset
trip_3$Date &amp;lt;- trip_3$start_date

# Left join the trip and weather dataframes by date.
trip_weather &amp;lt;- left_join(trip_3, weather, by = &amp;quot;Date&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;mean-temperature-vs-number-of-trips&#34;&gt;Mean Temperature vs. Number of Trips&lt;/h4&gt;

&lt;p&gt;Ok. Now let&amp;rsquo;s see how the number of trips per day is influenced by weather (mean temperature, rounded to the nearest 5 degrees F)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-56-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So, as expected, there are more trips when the weather is mild but not too warm (over 70F) or too cold (below 50F). However, this figure may be influenced by the overall number of days that exhibited each mean temperature. Let&amp;rsquo;s try to standardize that.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-57-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So when we standardize our measurements, correcting for the number of days that actually reached each temperature, we see a steady increase in the number of trips until around 75F where the trend levels off. People are more likely to ride a bike when it&amp;rsquo;s warm outside.&lt;/p&gt;

&lt;h4 id=&#34;precipitation-vs-number-of-trips&#34;&gt;Precipitation vs. Number of Trips&lt;/h4&gt;

&lt;p&gt;If you&amp;rsquo;ve ever heard of Seattle, you probably hear that it rains all the time there. Let&amp;rsquo;s see if that has an impact on the number of trips taken in a day.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with a figure standardized for number of days at a precipitation level, rounded to the nearest 0.2 inches. &lt;img src=&#34;../Bicycle_Sharing_2_files/figure-markdown_github/unnamed-chunk-58-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like even Seattleites have a limit when it comes to riding a bike in the rain. The more it rained, the fewer trips were taken per day.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;So what did we learn from all of this? In the nearly 2 years since Pronto! opened in Seattle:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;236,065 bike trips were taken using this service&lt;/li&gt;
&lt;li&gt;More trips occur in the spring and summer than winter/autumn&lt;/li&gt;
&lt;li&gt;More trips occur during warm/dry weather&lt;/li&gt;
&lt;li&gt;People tend to ride downhill more frequently than uphill&lt;/li&gt;
&lt;li&gt;Pronto! bikes are used for work commutes during the week and more leisurely use on weekends&lt;/li&gt;
&lt;li&gt;Short-Term Pass Holders are more likely to incur extra charges due to surpassing their time limit&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;suggestions-for-pronto&#34;&gt;Suggestions for Pronto!&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Give users bonuses for bringing bikes back to a station on the top of the hill&lt;/li&gt;
&lt;li&gt;Hold discounts in fall/winter&lt;/li&gt;
&lt;li&gt;Find a way to alert short-term users that their time limit will be ending soon, and where the nearest station is to them at that time&lt;/li&gt;
&lt;li&gt;Consider a 3rd membership option: &amp;ldquo;Commuter&amp;rdquo;. This may allow users to take bikes between 7-10 AM and 4-7 PM for free, but operate under a different time limit schedule during other times of day.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As always, I appreciate any and all feedback from my work and appreciate you taking the time to see what I&amp;rsquo;ve done. Thanks!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ghosts, Goblins, and Ghouls</title>
      <link>/projects/Ghosts_Goblins_Ghouls_02/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/projects/Ghosts_Goblins_Ghouls_02/</guid>
      <description>&lt;p&gt;Kaggle Playground Competition&lt;/p&gt;

&lt;p&gt;Data exploration and machine learning in RMarkdown.
&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-data&#34;&gt;Importing Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-exploration&#34;&gt;Data Exploration&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#distribution-of-continuous-variables-by-creature-type&#34;&gt;Distribution of Continuous Variables by Creature Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#distribution-of-color-by-creature-type&#34;&gt;Distribution of Color by Creature Type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#distinguishing-features&#34;&gt;Distinguishing Features?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-data&#34;&gt;Cleaning Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#clustering-data&#34;&gt;Clustering data&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cluster-without-categorical-variables&#34;&gt;Cluster Without Categorical Variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-for-creature-identity&#34;&gt;Modeling for Creature Identity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-traincontrol&#34;&gt;Creating trainControl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#random-forest-modeling&#34;&gt;Random Forest Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#glmnet-modeling&#34;&gt;GLMnet Modeling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparing-model-fit&#34;&gt;Comparing model fit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predicting-creature-identity&#34;&gt;Predicting Creature Identity&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is my second-ever Kaggle competition (looking for the &lt;a href=&#34;https://www.kaggle.com/amberthomas/titanic/predicting-survival-on-the-titanic&#34;&gt;first&lt;/a&gt;?) I&amp;rsquo;ll do my best to walk through my thought-process here and welcome any comments on my work. Let&amp;rsquo;s get started!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For data manipulation and tidying
library(dplyr)

# For data visualizations
library(ggplot2)
library(fpc)

# For modeling and predictions
library(caret)
library(glmnet)
library(ranger)
library(e1071)
library(clValid)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-data&#34;&gt;Importing Data&lt;/h3&gt;

&lt;p&gt;The data were downloaded directly from the &lt;a href=&#34;https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo/data&#34;&gt;Kaggle Website&lt;/a&gt;. Before binding the training and test sets into a single data file, I added a column called &amp;ldquo;Dataset&amp;rdquo; and labelled rows from the training file &amp;ldquo;train&amp;rdquo; and rows from the testing file &amp;ldquo;test&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train &amp;lt;- read.csv(file = &amp;quot;train.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
train$Dataset &amp;lt;- &amp;quot;train&amp;quot;

test &amp;lt;- read.csv(file = &amp;quot;test.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
test$Dataset &amp;lt;- &amp;quot;test&amp;quot;

full &amp;lt;- bind_rows(train, test)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, time to take a look at the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    900 obs. of  8 variables:
##  $ id           : int  0 1 2 4 5 7 8 11 12 19 ...
##  $ bone_length  : num  0.355 0.576 0.468 0.777 0.566 ...
##  $ rotting_flesh: num  0.351 0.426 0.354 0.509 0.876 ...
##  $ hair_length  : num  0.466 0.531 0.812 0.637 0.419 ...
##  $ has_soul     : num  0.781 0.44 0.791 0.884 0.636 ...
##  $ color        : chr  &amp;quot;clear&amp;quot; &amp;quot;green&amp;quot; &amp;quot;black&amp;quot; &amp;quot;black&amp;quot; ...
##  $ type         : chr  &amp;quot;Ghoul&amp;quot; &amp;quot;Goblin&amp;quot; &amp;quot;Ghoul&amp;quot; &amp;quot;Ghoul&amp;quot; ...
##  $ Dataset      : chr  &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##        id         bone_length     rotting_flesh     hair_length    
##  Min.   :  0.0   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:224.8   1st Qu.:0.3321   1st Qu.:0.4024   1st Qu.:0.3961  
##  Median :449.5   Median :0.4268   Median :0.5053   Median :0.5303  
##  Mean   :449.5   Mean   :0.4291   Mean   :0.5050   Mean   :0.5222  
##  3rd Qu.:674.2   3rd Qu.:0.5182   3rd Qu.:0.6052   3rd Qu.:0.6450  
##  Max.   :899.0   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##     has_soul         color               type             Dataset         
##  Min.   :0.0000   Length:900         Length:900         Length:900        
##  1st Qu.:0.3439   Class :character   Class :character   Class :character  
##  Median :0.4655   Mode  :character   Mode  :character   Mode  :character  
##  Mean   :0.4671                                                           
##  3rd Qu.:0.5892                                                           
##  Max.   :1.0000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! So here&amp;rsquo;s what we know so far:&lt;/p&gt;

&lt;p&gt;We have 8 variables currently:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt; : Appears to be the identification number of the monster in question&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bone Length&lt;/strong&gt; : Average length of the bones in the creature, normalized to 0 - 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rotting Flesh&lt;/strong&gt; : Percentage of flesh on the creature that is rotting&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hair Length&lt;/strong&gt; : Average length of the hair on the creature, normalized from 0 - 1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Has Soul&lt;/strong&gt; : The percentage of a soul present in the creature&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Color&lt;/strong&gt; : The color of the creature&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt; : The category of the creature (i.e. ghoul, goblin or ghost)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dataset&lt;/strong&gt; : The column I added when importing data indicating whether the observation was part of the original training or test set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It seems like a few of these variables would serve better as factors, rather than character strings, so I&amp;rsquo;ll take care of that.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;factor_variables &amp;lt;- c(&amp;quot;id&amp;quot;, &amp;quot;color&amp;quot;, &amp;quot;type&amp;quot;, &amp;quot;Dataset&amp;quot;)
full[factor_variables] &amp;lt;- lapply(full[factor_variables], function(x) as.factor(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at what we&amp;rsquo;ve got here so far. What&amp;rsquo;s the distribution of each variable across each monster?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first temporarily remove the &amp;ldquo;test&amp;rdquo; rows.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_2 &amp;lt;- full[full$Dataset == &amp;quot;train&amp;quot;, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;distribution-of-continuous-variables-by-creature-type&#34;&gt;Distribution of Continuous Variables by Creature Type&lt;/h3&gt;

&lt;h4 id=&#34;bone-length&#34;&gt;Bone Length&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-6-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;rotting-flesh&#34;&gt;Rotting Flesh&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-7-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;hair-length&#34;&gt;Hair Length&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-8-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;soul&#34;&gt;Soul&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-9-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;distribution-of-color-by-creature-type&#34;&gt;Distribution of Color by Creature Type&lt;/h3&gt;

&lt;h4 id=&#34;ghost&#34;&gt;Ghost&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-10-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;ghoul&#34;&gt;Ghoul&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-11-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;goblin&#34;&gt;Goblin&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-12-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;distinguishing-features&#34;&gt;Distinguishing Features?&lt;/h3&gt;

&lt;p&gt;Hmm, looks like ghosts have shorter hair and fewer pieces of soul than ghouls and goblins, but otherwise are pretty close. Ghouls and goblins are going to be tricky to distinguish. Color doesn&amp;rsquo;t appear to help a whole lot as there seems to be a pretty even distribution to these multi-colored critters.&lt;/p&gt;

&lt;h2 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h2&gt;

&lt;p&gt;Normally here I would try to come up with additional ways to look at these data, but we can&amp;rsquo;t infer the size of the creature since both bone and hair length have been normalized. As of now, I can&amp;rsquo;t think of any features worth engineering from the current data.&lt;/p&gt;

&lt;p&gt;Maybe I&amp;rsquo;m missing some interesting connection between variables?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pairs(full[, 2:5], col = full$type, labels = c(&amp;quot;Bone Length&amp;quot;, 
    &amp;quot;Rotting Flesh&amp;quot;, &amp;quot;Hair Length&amp;quot;, &amp;quot;Soul&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-13-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Nope. But perhaps we can take advantage of a combination of characteristics that do seem to show some promise: most notably &amp;ldquo;Hair Length&amp;rdquo; and &amp;ldquo;Soul&amp;rdquo;. Do we get any better separation among creatures if we combine these variables into one?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full &amp;lt;- full %&amp;gt;% mutate(hair_soul = hair_length * has_soul)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-15-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That may have separated Ghosts a little further from the other two&amp;hellip; Let&amp;rsquo;s try a few more variable interactions.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full &amp;lt;- full %&amp;gt;% mutate(bone_flesh = bone_length * rotting_flesh, 
    bone_hair = bone_length * hair_length, bone_soul = bone_length * 
        has_soul, flesh_hair = rotting_flesh * hair_length, flesh_soul = rotting_flesh * 
        has_soul)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Time to check for ways to tidy up.&lt;/p&gt;

&lt;h2 id=&#34;cleaning-data&#34;&gt;Cleaning Data&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s take another look at the summary statistics for this dataset.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##        id       bone_length     rotting_flesh     hair_length    
##  0      :  1   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1      :  1   1st Qu.:0.3321   1st Qu.:0.4024   1st Qu.:0.3961  
##  2      :  1   Median :0.4268   Median :0.5053   Median :0.5303  
##  3      :  1   Mean   :0.4291   Mean   :0.5050   Mean   :0.5222  
##  4      :  1   3rd Qu.:0.5182   3rd Qu.:0.6052   3rd Qu.:0.6450  
##  5      :  1   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##  (Other):894                                                     
##     has_soul        color         type      Dataset      hair_soul     
##  Min.   :0.0000   black:104   Ghost :117   test :529   Min.   :0.0000  
##  1st Qu.:0.3439   blood: 21   Ghoul :129   train:371   1st Qu.:0.1322  
##  Median :0.4655   blue : 54   Goblin:125               Median :0.2448  
##  Mean   :0.4671   clear:292   NA&#39;s  :529               Mean   :0.2588  
##  3rd Qu.:0.5892   green: 95                            3rd Qu.:0.3631  
##  Max.   :1.0000   white:334                            Max.   :0.7768  
##                                                                        
##    bone_flesh       bone_hair        bone_soul        flesh_hair    
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.1473   1st Qu.:0.1361   1st Qu.:0.1136   1st Qu.:0.1847  
##  Median :0.2039   Median :0.2194   Median :0.1944   Median :0.2473  
##  Mean   :0.2159   Mean   :0.2330   Mean   :0.2098   Mean   :0.2585  
##  3rd Qu.:0.2701   3rd Qu.:0.3191   3rd Qu.:0.2810   3rd Qu.:0.3242  
##  Max.   :0.7887   Max.   :0.7779   Max.   :0.6869   Max.   :0.7478  
##                                                                     
##    flesh_soul    
##  Min.   :0.0000  
##  1st Qu.:0.1539  
##  Median :0.2163  
##  Mean   :0.2316  
##  3rd Qu.:0.2991  
##  Max.   :0.7195  
## 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only column that has any missing values is &lt;code&gt;type&lt;/code&gt; which is to be expected since that&amp;rsquo;s what we need to be predicting. Everything else seems to look good so far. Let&amp;rsquo;s try to model these as is.&lt;/p&gt;

&lt;h2 id=&#34;clustering-data&#34;&gt;Clustering data&lt;/h2&gt;

&lt;p&gt;While clustering is generally used for unsupervised machine learning, I want to take a peek at the clusters that could be formed using the data at hand. The potential issue with trying to cluster this data is that we are working with two types of data: continuous and categorical. They break down like this:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Continuous Variables&lt;/th&gt;
&lt;th&gt;Categorical Variables&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;bone length&lt;/td&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;rotting flesh&lt;/td&gt;
&lt;td&gt;color&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;hair length&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;has soul&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So, sure, there&amp;rsquo;s only two categorical variables. Because of our small sample size, it&amp;rsquo;s not a good idea to count out these variables completely, but we&amp;rsquo;ll try to create clusters without them just to see how well the clustering models do.&lt;/p&gt;

&lt;h3 id=&#34;cluster-without-categorical-variables&#34;&gt;Cluster Without Categorical Variables&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ll first try to cluster using the &lt;code&gt;kmeans&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Set the seed
set.seed(100)

# Extract creature labels and remove column from dataset
creature_labels &amp;lt;- full$type
full2 &amp;lt;- full
full2$type &amp;lt;- NULL

# Remove categorical variables (id, color, and dataset) from
# dataset
full2$id &amp;lt;- NULL
full2$color &amp;lt;- NULL
full2$Dataset &amp;lt;- NULL

# Perform k-means clustering with 3 clusters, repeat 30 times
creature_km_1 &amp;lt;- kmeans(full2, 3, nstart = 30)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so now we have clusters, time to see how well they did. Let&amp;rsquo;s look at them graphically first. This was created using the &lt;code&gt;plotcluster()&lt;/code&gt; function from the &lt;code&gt;fpc&lt;/code&gt; package.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-19-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, those clusters don&amp;rsquo;t look very discrete. Let&amp;rsquo;s look at &lt;a href=&#34;https://en.wikipedia.org/wiki/Dunn_index&#34;&gt;Dunn&amp;rsquo;s Index&lt;/a&gt; mathematically to see if we&amp;rsquo;re missing something visually. This calculation comes from the &lt;code&gt;dunn&lt;/code&gt; function in the &lt;code&gt;clValid&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dunn_ckm_1 &amp;lt;- dunn(clusters = creature_km_1$cluster, Data = full2)

# Print results
dunn_ckm_1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 0.04670431
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As Dunn&amp;rsquo;s Index represents a ratio of the smallest distance between clusters to the largest distance between two points in the same cluster (or, the smallest inter-cluster distance to the largest intra-cluster distance), such a low number indicates that our current clusters are not condensed, separate entities. This is not terribly surprising considering we completely disregarded one of our variables.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how well this clustering method correctly separated the labelled creatures.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(creature_km_1$cluster, creature_labels)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    creature_labels
##     Ghost Ghoul Goblin
##   1     7    39     75
##   2     4    86     24
##   3   106     4     26
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like currently, ghosts were separated relatively well, but ghouls and goblins are split between the clusters. Ok, I&amp;rsquo;m convinced. I haven&amp;rsquo;t really gained any new information here, but it&amp;rsquo;s been an interesting exploratory path!&lt;/p&gt;

&lt;p&gt;On to supervised modeling!&lt;/p&gt;

&lt;h3 id=&#34;modeling-for-creature-identity&#34;&gt;Modeling for Creature Identity&lt;/h3&gt;

&lt;p&gt;Clustering was not particularly helpful in discerning creature identity, so perhaps creating models will work better.&lt;/p&gt;

&lt;p&gt;First things first, I need to split out the test and training data back into separate datasets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_complete &amp;lt;- full[full$Dataset == &amp;quot;train&amp;quot;, ]
test_complete &amp;lt;- full[full$Dataset == &amp;quot;test&amp;quot;, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because I plan on using the &lt;code&gt;caret&lt;/code&gt; package for all of my modeling, I&amp;rsquo;m going to generate a standard &lt;code&gt;trainControl&lt;/code&gt; so that those tuning parameters remain consistent throughout the various models.&lt;/p&gt;

&lt;h3 id=&#34;creating-traincontrol&#34;&gt;Creating trainControl&lt;/h3&gt;

&lt;p&gt;I will create a system that will perform 20 repeats of a 10-Fold cross-validation of the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;myControl &amp;lt;- trainControl(method = &amp;quot;cv&amp;quot;, number = 10, repeats = 20, 
    verboseIter = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;random-forest-modeling&#34;&gt;Random Forest Modeling&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s start with a random forest model, generated using the &lt;code&gt;ranger&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; packages. I&amp;rsquo;m going to include all of the original variables, including any interactions here.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

rf_model &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + color + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, tuneLength = 3, data = train_complete, 
    method = &amp;quot;ranger&amp;quot;, trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at the levels of importance of each factor in this model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-25-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Huh. Our &amp;ldquo;hair_soul&amp;rdquo; variable seems to be the most important to this model and our other interactions rank pretty highly. I suppose we can hold on to them for now. Color, on the other hand, hardly plays into this. Let&amp;rsquo;s try removing it from a second random forest model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

rf_model_2 &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, tuneLength = 3, data = train_complete, 
    method = &amp;quot;ranger&amp;quot;, trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;glmnet-modeling&#34;&gt;GLMnet Modeling&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;m going to follow the random forest model up with a glmnet model, also from the &lt;code&gt;caret&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

glm_model &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + color + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(alpha = 0:1, 
    lambda = seq(1e-04, 1, length = 20)), data = train_complete, 
    trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once again, we&amp;rsquo;ll try without &amp;ldquo;color&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(10)

glm_model_2 &amp;lt;- train(type ~ bone_length + rotting_flesh + hair_length + 
    has_soul + hair_soul + bone_flesh + bone_hair + bone_soul + 
    flesh_hair + flesh_soul, method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(alpha = 0:1, 
    lambda = seq(1e-04, 1, length = 20)), data = train_complete, 
    trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;comparing-model-fit&#34;&gt;Comparing model fit&lt;/h3&gt;

&lt;p&gt;Now that we have two random forest models and two glmnet models, it&amp;rsquo;s time to compare their fit.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a list of models
models &amp;lt;- list(rf = rf_model, rf2 = rf_model_2, glmnet = glm_model, 
    glmnet2 = glm_model_2)

# Resample the models
resampled &amp;lt;- resamples(models)

# Generate a summary
summary(resampled)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = resampled)
## 
## Models: rf, rf2, glmnet, glmnet2 
## Number of resamples: 10 
## 
## Accuracy 
##           Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf      0.6389  0.6888 0.7201 0.7194  0.7566 0.7838    0
## rf2     0.6667  0.6888 0.7105 0.7195  0.7500 0.7895    0
## glmnet  0.6842  0.7222 0.7333 0.7438  0.7616 0.8649    0
## glmnet2 0.6842  0.7047 0.7500 0.7547  0.7829 0.8649    0
## 
## Kappa 
##           Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf      0.4577  0.5337 0.5801 0.5789  0.6347 0.6754    0
## rf2     0.4977  0.5337 0.5664 0.5791  0.6247 0.6837    0
## glmnet  0.5265  0.5833 0.5988 0.6156  0.6428 0.7965    0
## glmnet2 0.5260  0.5555 0.6254 0.6321  0.6758 0.7965    0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Plot the differences between model fits
dotplot(resampled, metric = &amp;quot;Accuracy&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Ghosts_Goblins_Ghouls_02_files/figure-markdown_github/unnamed-chunk-29-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;predicting-creature-identity&#34;&gt;Predicting Creature Identity&lt;/h2&gt;

&lt;p&gt;Although I generated four models above, the second glmnet model (all interactions but without color) provided the highest accuracy, so I&amp;rsquo;ll use that model to predict survival in the test set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Reorder the data by creature ID number
test_complete &amp;lt;- test_complete %&amp;gt;% arrange(id)

# Make predicted survival values
my_prediction &amp;lt;- predict(glm_model_2, test_complete)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/h3&gt;

&lt;p&gt;The instructions on Kaggle indicate that they are expecting a csv file with 2 columns: ID and Creature Type. I need to make sure that my data are arranged properly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a data frame with two columns
my_solution_GGG_03 &amp;lt;- data.frame(id = test_complete$id, Type = my_prediction)

# Write the solution to a csv file
write.csv(my_solution_GGG_03, file = &amp;quot;my_solution_GGG_03.csv&amp;quot;, 
    row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/h3&gt;

&lt;p&gt;Looks like that submission scored 0.74669! Not bad!!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I&amp;rsquo;d love to hear any feedback you may have on this process. Thanks in advance!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Machine Learning from Disaster</title>
      <link>/projects/Titanic_md/</link>
      <pubDate>Sat, 05 Nov 2016 18:25:22 +0530</pubDate>
      
      <guid>/projects/Titanic_md/</guid>
      <description>&lt;p&gt;Kaggle Playground Competition&lt;/p&gt;

&lt;p&gt;Data exploration and machine learning in RMarkdown.
&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#importing-data&#34;&gt;Importing Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#names-and-titles&#34;&gt;Names and Titles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sibsp-and-parch-for-family-size&#34;&gt;SibSp and Parch for Family Size&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ticket-numbers-and-travel-groups&#34;&gt;Ticket Numbers and Travel Groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing-data&#34;&gt;Missing Data&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#missing-fare&#34;&gt;Missing Fare&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing-embarkment&#34;&gt;Missing Embarkment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing-age&#34;&gt;Missing Age&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modeling-for-survival&#34;&gt;Modeling for Survival&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#creating-traincontrol&#34;&gt;Creating trainControl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-random-forest-model&#34;&gt;Fitting a random forest model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-a-glmnet-model&#34;&gt;Fitting a glmnet model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparing-model-fit&#34;&gt;Comparing model fit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predicting-survival&#34;&gt;Predicting Survival&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is my first project on Kaggle and my first attempt at machine learning. I&amp;rsquo;ll do my best to illustrate what I&amp;rsquo;ve down and the logic behind my actions, but feedback is very much welcome and appreciated!&lt;/p&gt;

&lt;h3 id=&#34;loading-necessary-packages&#34;&gt;Loading Necessary Packages&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# For data manipulation and tidying
library(dplyr)

# For data visualizations
library(ggplot2)

# For modeling and predictions
library(caret)
library(glmnet)
library(ranger)
library(e1071)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;importing-data&#34;&gt;Importing Data&lt;/h3&gt;

&lt;p&gt;The data were downloaded directly from the &lt;a href=&#34;https://www.kaggle.com/c/titanic/data&#34;&gt;Kaggle Website&lt;/a&gt;. Before binding the training and test sets into a single data file, I added a column called &amp;ldquo;Dataset&amp;rdquo; and labelled rows from the training file &amp;ldquo;train&amp;rdquo; and rows from the testing file &amp;ldquo;test&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train &amp;lt;- read.csv(file = &amp;quot;train.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
train$Dataset &amp;lt;- &amp;quot;train&amp;quot;

test &amp;lt;- read.csv(file = &amp;quot;test.csv&amp;quot;, header = TRUE, stringsAsFactors = FALSE)
test$Dataset &amp;lt;- &amp;quot;test&amp;quot;

full &amp;lt;- bind_rows(train, test)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The full dataset can then be inspected:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(full)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:    1309 obs. of  13 variables:
##  $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
##  $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
##  $ Name       : chr  &amp;quot;Braund, Mr. Owen Harris&amp;quot; &amp;quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&amp;quot; &amp;quot;Heikkinen, Miss. Laina&amp;quot; &amp;quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&amp;quot; ...
##  $ Sex        : chr  &amp;quot;male&amp;quot; &amp;quot;female&amp;quot; &amp;quot;female&amp;quot; &amp;quot;female&amp;quot; ...
##  $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
##  $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
##  $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
##  $ Ticket     : chr  &amp;quot;A/5 21171&amp;quot; &amp;quot;PC 17599&amp;quot; &amp;quot;STON/O2. 3101282&amp;quot; &amp;quot;113803&amp;quot; ...
##  $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
##  $ Cabin      : chr  &amp;quot;&amp;quot; &amp;quot;C85&amp;quot; &amp;quot;&amp;quot; &amp;quot;C123&amp;quot; ...
##  $ Embarked   : chr  &amp;quot;S&amp;quot; &amp;quot;C&amp;quot; &amp;quot;S&amp;quot; &amp;quot;S&amp;quot; ...
##  $ Dataset    : chr  &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; &amp;quot;train&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It appears that several of these variables should be represented as factors and thus should be reclassified.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;factor_variables &amp;lt;- c(&amp;quot;PassengerId&amp;quot;, &amp;quot;Survived&amp;quot;, &amp;quot;Pclass&amp;quot;, &amp;quot;Sex&amp;quot;, 
    &amp;quot;Embarked&amp;quot;, &amp;quot;Dataset&amp;quot;)
full[factor_variables] &amp;lt;- lapply(full[factor_variables], function(x) as.factor(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are now left with the following variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Passenger ID&lt;/strong&gt; : A seemingly unique number assigned to each passenger&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Survived&lt;/strong&gt; : A binary indicator of survival (0 = died, 1 = survived)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pclass&lt;/strong&gt; : A proxy for socio-economic status (1 = upper, 3 = lower)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Name&lt;/strong&gt; : Passenger&amp;rsquo;s Name. For wedded women, her husband&amp;rsquo;s name appears first and her maiden name appears in parentheses&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt; : General indication of passenger&amp;rsquo;s sex&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Age&lt;/strong&gt; : Age of passenger (or approximate age). Passengers under the age of 1 year have fractional ages&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;SibSp&lt;/strong&gt; : A count of the passenger&amp;rsquo;s siblings or spouses aboard&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parch&lt;/strong&gt; : A count of the passenger&amp;rsquo;s parents or siblings aboard&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ticket&lt;/strong&gt; : The number printed on the ticket. The numbering system is not immediately apparent&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Fare&lt;/strong&gt; : The price for the ticket (presumably in pounds, shillings, and pennies)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Cabin&lt;/strong&gt; : Cabin number occupied by the passenger (this field is quite empty)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Embarked&lt;/strong&gt; : The port from which the passenger boarded the ship&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt; : Whether this particular row was a part of the training or testing dataset&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h2&gt;

&lt;h3 id=&#34;names-and-titles&#34;&gt;Names and Titles&lt;/h3&gt;

&lt;p&gt;At first glance, the &amp;ldquo;Name&amp;rdquo; column doesn&amp;rsquo;t help too much as there are 1307 unique names, however, this column also includes embedded title information that may be of interest. I decided to use &lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf&#34;&gt;regular expressions&lt;/a&gt; and the &lt;code&gt;gsub()&lt;/code&gt; functions to extract the titles into a new variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names &amp;lt;- full$Name

titles &amp;lt;- gsub(&amp;quot;^.*, (.*?)\\..*$&amp;quot;, &amp;quot;\\1&amp;quot;, names)

full$Titles &amp;lt;- titles

unique(full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Mr&amp;quot;           &amp;quot;Mrs&amp;quot;          &amp;quot;Miss&amp;quot;         &amp;quot;Master&amp;quot;      
##  [5] &amp;quot;Don&amp;quot;          &amp;quot;Rev&amp;quot;          &amp;quot;Dr&amp;quot;           &amp;quot;Mme&amp;quot;         
##  [9] &amp;quot;Ms&amp;quot;           &amp;quot;Major&amp;quot;        &amp;quot;Lady&amp;quot;         &amp;quot;Sir&amp;quot;         
## [13] &amp;quot;Mlle&amp;quot;         &amp;quot;Col&amp;quot;          &amp;quot;Capt&amp;quot;         &amp;quot;the Countess&amp;quot;
## [17] &amp;quot;Jonkheer&amp;quot;     &amp;quot;Dona&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s a bit more manageable: only 18 unique titles. Time to see how many times each title was used. I decided to make a table separated by sex.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(full$Sex, full$Title)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         
##          Capt Col Don Dona  Dr Jonkheer Lady Major Master Miss Mlle Mme
##   female    0   0   0    1   1        0    1     0      0  260    2   1
##   male      1   4   1    0   7        1    0     2     61    0    0   0
##         
##           Mr Mrs  Ms Rev Sir the Countess
##   female   0 197   2   0   0            1
##   male   757   0   0   8   1            0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It looks like Captain, Don, Dona, Jonkheer, Lady, Madame, Sir and the Countess were each only used once. I&amp;rsquo;ll leave Captain separate, but the rest should be combined with similar categories.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Don&lt;/strong&gt; : A Spanish/Portuguese/Italian title used with, but not instead of, a name.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dona&lt;/strong&gt; : Female version of &amp;ldquo;Don&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jonkheer&lt;/strong&gt; : Dutch honorific of nobility&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lady&lt;/strong&gt; : English honorific of nobility&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Madame&lt;/strong&gt; : French, polite form of address for a woman&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sir&lt;/strong&gt; : Honorific address (male)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;the Countess&lt;/strong&gt; : Rank of nobility (female)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It seems that most of the rarely used titles indicate some form of nobility. That&amp;rsquo;s easy to check with another table comparing &lt;code&gt;Pclass&lt;/code&gt; and &lt;code&gt;Titles&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(full$Pclass, full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    
##     Capt Col Don Dona  Dr Jonkheer Lady Major Master Miss Mlle Mme  Mr Mrs
##   1    1   4   1    1   6        1    1     2      5   60    2   1 159  77
##   2    0   0   0    0   2        0    0     0     11   50    0   0 150  55
##   3    0   0   0    0   0        0    0     0     45  150    0   0 448  65
##    
##      Ms Rev Sir the Countess
##   1   0   0   1            1
##   2   1   8   0            0
##   3   1   0   0            0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since Don, Jonkheer, and Sir are all of similar usage, and each represent only one first-class man, I combined them into the category &amp;ldquo;Sir&amp;rdquo;. Dona, Lady, Madame, and the Countess each only represent one first-class woman, so I combined them into the category &amp;ldquo;Lady&amp;rdquo;. These values were substituted using the &lt;code&gt;gsub&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full$Titles &amp;lt;- gsub(&amp;quot;Dona|Lady|Madame|the Countess&amp;quot;, &amp;quot;Lady&amp;quot;, 
    full$Titles)
full$Titles &amp;lt;- gsub(&amp;quot;Don|Jonkheer|Sir&amp;quot;, &amp;quot;Sir&amp;quot;, full$Titles)

unique(full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Mr&amp;quot;     &amp;quot;Mrs&amp;quot;    &amp;quot;Miss&amp;quot;   &amp;quot;Master&amp;quot; &amp;quot;Sir&amp;quot;    &amp;quot;Rev&amp;quot;    &amp;quot;Dr&amp;quot;    
##  [8] &amp;quot;Mme&amp;quot;    &amp;quot;Ms&amp;quot;     &amp;quot;Major&amp;quot;  &amp;quot;Lady&amp;quot;   &amp;quot;Mlle&amp;quot;   &amp;quot;Col&amp;quot;    &amp;quot;Capt&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: If you are planning to replicate the above substitution without any RegEx, make sure that you substitute &amp;ldquo;Dona&amp;rdquo; before substituting &amp;ldquo;Don&amp;rdquo;! Otherwise, &amp;ldquo;Dona&amp;rdquo; becomes &amp;ldquo;Sira&amp;rdquo; (as the &amp;ldquo;Don&amp;rdquo; part was replaced with &amp;ldquo;Sir&amp;rdquo;) and your second substitution won&amp;rsquo;t find or replace &amp;ldquo;Dona&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Lastly for the titles, they should be factors, not character strings.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full$Titles &amp;lt;- as.factor(full$Titles)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These titles could certainly be condensed more, but for the time being, I am going to leave them separated as is.&lt;/p&gt;

&lt;p&gt;I have some thoughts about wanting to split up the names further to find family groups, but since many familial relationships (cousins, nieces/nephews, aunts/uncles, fiances, mistresses, in-laws, children with a nanny or close friends) aren&amp;rsquo;t reported in any way in this data set, I&amp;rsquo;ll have to think a little longer about the most appropriate way to find actual family groups.&lt;/p&gt;

&lt;h3 id=&#34;sibsp-and-parch-for-family-size&#34;&gt;SibSp and Parch for Family Size&lt;/h3&gt;

&lt;p&gt;Since the SibSp and Parch variables each give some indication as to close family members that were also aboard the ship, it would make sense to calculate family size as a combination of SibSp, Parch and the passenger in question.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full &amp;lt;- mutate(full, FamilySize = SibSp + Parch + 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s visualize family size&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-11-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Lots of people without immediate family with them. Perhaps these people were traveling with other family members/friends that weren&amp;rsquo;t captured in the SibSp / Parch variables.&lt;/p&gt;

&lt;h3 id=&#34;ticket-numbers-and-travel-groups&#34;&gt;Ticket Numbers and Travel Groups&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve decided that another possible way to discern groups that were travelling together is to look at the ticket numbers. It appears that families or groups who purchased their tickets together have identical ticket numbers, thus quantifying the number of families or traveling groups. A quick look at the unique ticket numbers indicates there are 929 of them in the full data set (out of a possible 1309 passengers).&lt;/p&gt;

&lt;p&gt;It seems the easiest way to separate these tickets is to create a new column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full$TravelGroup &amp;lt;- NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then arrange the data by ticket number using the &lt;code&gt;arrange()&lt;/code&gt; function from the &lt;code&gt;dplyr&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full2 &amp;lt;- arrange(full, Ticket)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take a look at the first few rows of results&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(full2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   PassengerId Survived Pclass
## 1         258        1      1
## 2         505        1      1
## 3         760        1      1
## 4         263        0      1
## 5         559        1      1
## 6         586        1      1
##                                                       Name    Sex Age
## 1                                     Cherry, Miss. Gladys female  30
## 2                                    Maioni, Miss. Roberta female  16
## 3 Rothes, the Countess. of (Lucy Noel Martha Dyer-Edwards) female  33
## 4                                        Taussig, Mr. Emil   male  52
## 5                   Taussig, Mrs. Emil (Tillie Mandelbaum) female  39
## 6                                      Taussig, Miss. Ruth female  18
##   SibSp Parch Ticket  Fare Cabin Embarked Dataset Titles FamilySize
## 1     0     0 110152 86.50   B77        S   train   Miss          1
## 2     0     0 110152 86.50   B79        S   train   Miss          1
## 3     0     0 110152 86.50   B77        S   train   Lady          1
## 4     1     1 110413 79.65   E67        S   train     Mr          3
## 5     1     1 110413 79.65   E67        S   train    Mrs          3
## 6     0     2 110413 79.65   E68        S   train   Miss          3
##   TravelGroup
## 1          NA
## 2          NA
## 3          NA
## 4          NA
## 5          NA
## 6          NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To verify that this is working so far, I inspected the first ticket number listed (110152) on the &lt;a href=&#34;https://www.encyclopedia-titanica.org/titanic-passengers-and-crew/&#34;&gt;Titanic Passenger and Crew&lt;/a&gt; table of Encyclopedia Titanica. That dataset lists the same three passengers owned those tickets, verified that the 3 women were traveling together, and indicated that two of the women (Miss Gladys Cherry and the Countess of Rothes) were cousins and the 3rd woman in their party (Miss Roberta Elizabeth Mary Maioni) was their servant. Looking at unique Ticket ID may be the only way to know that these women were travelling together. I&amp;rsquo;m feeling good that unique ticket numbers may be a good way to look at family/traveling groups, so full steam ahead!&lt;/p&gt;

&lt;p&gt;Next, I need to generate a &amp;ldquo;TravelGroup&amp;rdquo; number. To do this, I will use the &lt;code&gt;transform&lt;/code&gt; function looking for matching unique Ticket numbers.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full2 &amp;lt;- (transform(full2, TravelGroup = match(Ticket, unique(Ticket))))

# Can&#39;t forget to make those Travel Groups into factors!
full2$TravelGroup &amp;lt;- as.factor(full2$TravelGroup)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This generates 929 unique Travel Groups, which is the same number of unique Ticket numbers. So far so good.&lt;/p&gt;

&lt;p&gt;It may also be of interest to look at group size. We can generate this using the &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;mutate&lt;/code&gt; functions in &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full3 &amp;lt;- full2 %&amp;gt;% group_by(TravelGroup) %&amp;gt;% mutate(GroupSize = n()) %&amp;gt;% 
    ungroup()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How does Travel Group Size compare to Family Group Size that we calculated earlier?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-17-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-17-2.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;They look pretty close, again showing that most people were potentially travelling alone.&lt;/p&gt;

&lt;p&gt;Now to check if those with the unique Ticket IDs were really travelling alone:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;filtered &amp;lt;- filter(full3, GroupSize == 1)

# How many were listed as being onboard with siblings or
# spouses?
fSibSp &amp;lt;- filtered[filtered$SibSp &amp;gt; 0, ]
nrow(fSibSp)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 42
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many were listed as being onboard with parents or
# children?
fParch &amp;lt;- filtered[filtered$Parch &amp;gt; 0, ]
nrow(fParch)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 16
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# How many of those people overlapped both groups?
sum(fSibSp$PassengerId %in% fParch$PassengerId)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops! Looks like we were counting 50 passengers as solo-riders when they were actually riding with family. Given the current information, I&amp;rsquo;m not sure how to know to tell who was travelling together. Manually summing SibSp and Parch to estimate family size doesn&amp;rsquo;t account for other types of groups that were travelling together and looking only at unique Ticket Number doesn&amp;rsquo;t account for some travelling with family who purchased a separate ticket. I could override the GroupSize for those 50 that weren&amp;rsquo;t actually riding solo, but their TravelGroup number won&amp;rsquo;t be accurate. For the time being, I&amp;rsquo;m going to leave TravelGroup and GroupSize as is.&lt;/p&gt;

&lt;h2 id=&#34;missing-data&#34;&gt;Missing Data&lt;/h2&gt;

&lt;p&gt;At this point, I&amp;rsquo;m feeling pretty good about the Feature Engineering that I&amp;rsquo;ve done so far. Time to correct for missing data!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at what has NA values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(full3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   PassengerId   Survived   Pclass      Name               Sex     
##  1      :   1   0   :549   1:323   Length:1309        female:466  
##  2      :   1   1   :342   2:277   Class :character   male  :843  
##  3      :   1   NA&#39;s:418   3:709   Mode  :character               
##  4      :   1                                                     
##  5      :   1                                                     
##  6      :   1                                                     
##  (Other):1303                                                     
##       Age            SibSp            Parch          Ticket         
##  Min.   : 0.17   Min.   :0.0000   Min.   :0.000   Length:1309       
##  1st Qu.:21.00   1st Qu.:0.0000   1st Qu.:0.000   Class :character  
##  Median :28.00   Median :0.0000   Median :0.000   Mode  :character  
##  Mean   :29.88   Mean   :0.4989   Mean   :0.385                     
##  3rd Qu.:39.00   3rd Qu.:1.0000   3rd Qu.:0.000                     
##  Max.   :80.00   Max.   :8.0000   Max.   :9.000                     
##  NA&#39;s   :263                                                        
##       Fare            Cabin           Embarked  Dataset        Titles   
##  Min.   :  0.000   Length:1309         :  2    test :418   Mr     :757  
##  1st Qu.:  7.896   Class :character   C:270    train:891   Miss   :260  
##  Median : 14.454   Mode  :character   Q:123                Mrs    :197  
##  Mean   : 33.295                      S:914                Master : 61  
##  3rd Qu.: 31.275                                           Dr     :  8  
##  Max.   :512.329                                           Rev    :  8  
##  NA&#39;s   :1                                                 (Other): 18  
##    FamilySize      TravelGroup     GroupSize     
##  Min.   : 1.000   779    :  11   Min.   : 1.000  
##  1st Qu.: 1.000   105    :   8   1st Qu.: 1.000  
##  Median : 1.000   776    :   8   Median : 1.000  
##  Mean   : 1.884   336    :   7   Mean   : 2.102  
##  3rd Qu.: 2.000   455    :   7   3rd Qu.: 3.000  
##  Max.   :11.000   460    :   7   Max.   :11.000  
##                   (Other):1261
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like we are missing values in the &amp;ldquo;Survived&amp;rdquo; variable (which is to be expected since this is a combination of the training and test datasets), &amp;ldquo;Fare&amp;rdquo;, &amp;ldquo;Embarked&amp;rdquo;, and quite a few in the &amp;ldquo;Age&amp;rdquo; column. We&amp;rsquo;ll start with &amp;ldquo;Fare&amp;rdquo;.&lt;/p&gt;

&lt;h3 id=&#34;missing-fare&#34;&gt;Missing Fare&lt;/h3&gt;

&lt;p&gt;Which passenger has no fare information?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full3[(which(is.na(full3$Fare))), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   PassengerId
##        &amp;lt;fctr&amp;gt;
## 1        1044
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like Passenger number 1044 has no listed Fare.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Resort the dataset by Passenger Number
full4 &amp;lt;- arrange(full3, PassengerId)

# Where did this passenger leave from? What was their class?
full4[1044, c(3, 12)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   Pclass Embarked
##   &amp;lt;fctr&amp;gt;   &amp;lt;fctr&amp;gt;
## 1      3        S
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like he left from &amp;rsquo;S&amp;rsquo; (Southampton) as a 3rd class passenger. Let&amp;rsquo;s see what other people of the same class and embarkment port paid for their tickets.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-22-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4 %&amp;gt;% filter(Pclass == &amp;quot;3&amp;quot; &amp;amp; Embarked == &amp;quot;S&amp;quot;) %&amp;gt;% summarise(missing_fare = median(Fare, 
    na.rm = TRUE))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   missing_fare
##          &amp;lt;dbl&amp;gt;
## 1         8.05
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like the median cost for a 3rd class passenger leaving out of Southampton was 8.05. That seems like a logical value for this passenger to have paid.&lt;/p&gt;

&lt;p&gt;Time to replace that NA with 8.05&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4$Fare[1044] &amp;lt;- 8.05

summary(full4$Fare)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.000   7.896  14.450  33.280  31.280 512.300
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hooray! No more NA values for Fare.&lt;/p&gt;

&lt;h3 id=&#34;missing-embarkment&#34;&gt;Missing Embarkment&lt;/h3&gt;

&lt;p&gt;Which passengers have no listed embarkment port?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4$Embarked[full4$Embarked == &amp;quot;&amp;quot;] &amp;lt;- NA

full4[(which(is.na(full4$Embarked))), 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 1
##   PassengerId
##        &amp;lt;fctr&amp;gt;
## 1          62
## 2         830
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, so Passenger numbers 62 and 830 are each missing their embarkment ports. Let&amp;rsquo;s look at their class of ticket and their fare.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4[c(62, 830), c(1, 3, 10)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 3
##   PassengerId Pclass  Fare
##        &amp;lt;fctr&amp;gt; &amp;lt;fctr&amp;gt; &amp;lt;dbl&amp;gt;
## 1          62      1    80
## 2         830      1    80
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Both passengers had first class tickets that they spent 80 (pounds?) on. Let&amp;rsquo;s see the embarkment ports of others who bought similar kinds of tickets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4 %&amp;gt;% group_by(Embarked, Pclass) %&amp;gt;% filter(Pclass == &amp;quot;1&amp;quot;) %&amp;gt;% 
    summarise(mfare = median(Fare), n = n())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Source: local data frame [4 x 4]
## Groups: Embarked [?]
## 
##   Embarked Pclass   mfare     n
##     &amp;lt;fctr&amp;gt; &amp;lt;fctr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1        C      1 76.7292   141
## 2        Q      1 90.0000     3
## 3        S      1 52.0000   177
## 4       NA      1 80.0000     2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks like the median price for a first class ticket departing from &amp;lsquo;C&amp;rsquo; (Charbourg) was 77 (in comparison to our 80). While first class tickets departing from &amp;lsquo;Q&amp;rsquo; were only slightly more expensive (median price 90), only 3 first class passengers departed from that port. It seems far more likely that passengers 62 and 830 departed with the other 141 first-class passengers from Charbourg.&lt;/p&gt;

&lt;p&gt;Now to replace their NA values with &amp;lsquo;C&amp;rsquo;. And drop any unused levels.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Assign empty embark ports to &#39;C&#39;
full4$Embarked[c(62, 830)] &amp;lt;- &amp;quot;C&amp;quot;

# Drop unused levels (since there should be no more blanks)
full4$Embarked &amp;lt;- droplevels(full4$Embarked)

# Check to make sure there are no NA&#39;s or blanks
levels(full4$Embarked)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;C&amp;quot; &amp;quot;Q&amp;quot; &amp;quot;S&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yay! No more NA values for Embarked.&lt;/p&gt;

&lt;h3 id=&#34;missing-age&#34;&gt;Missing Age&lt;/h3&gt;

&lt;p&gt;This one is a bit trickier. 263 passengers have no age listed. Taking a median age of all passengers doesn&amp;rsquo;t seem like the best way to solve this problem, so it may be easiest to try to predict the passengers&amp;rsquo; age based on other known information.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve decided to use the &lt;code&gt;caret&lt;/code&gt; package for predicting age.&lt;/p&gt;

&lt;p&gt;Generate a random forest model on the full dataset (minus the age values that are NA)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;predicted_age &amp;lt;- train(Age ~ Pclass + Sex + SibSp + Parch + Fare + 
    Embarked + Titles + FamilySize + GroupSize, tuneGrid = data.frame(mtry = c(2, 
    3, 7)), data = full4[!is.na(full4$Age), ], method = &amp;quot;ranger&amp;quot;, 
    trControl = trainControl(method = &amp;quot;cv&amp;quot;, number = 10, repeats = 10, 
        verboseIter = TRUE), importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at what factors were the most important in modeling age:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-30-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Wow! Looks like it was a good idea to split out Titles!&lt;/p&gt;

&lt;p&gt;Now to use this information to predict the ages of passengers with missing ages and filling in their NA values.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;full4$Age[is.na(full4$Age)] &amp;lt;- predict(predicted_age, full4[is.na(full4$Age), 
    ])

# Check the summary to make sure there are no more NA values
summary(full4$Age)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.17   22.00   28.50   29.72   37.00   80.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s take a quick look at the age distribution of passengers with originally known ages, and the age distribution of the entire group (known and predicted ages) to make sure we didn&amp;rsquo;t terribly skew the distribution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-32-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-32-2.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hmm, seems to have shifted a bit, but that could be due to a greater lack of age information collected for middle-aged passengers.&lt;/p&gt;

&lt;h2 id=&#34;modeling-for-survival&#34;&gt;Modeling for Survival&lt;/h2&gt;

&lt;p&gt;First things first, I need to split out the test and training data back into separate data sets, now called &lt;code&gt;train_complete&lt;/code&gt; and &lt;code&gt;test_complete&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train_complete &amp;lt;- full4[full4$Dataset == &amp;quot;train&amp;quot;, ]
test_complete &amp;lt;- full4[full4$Dataset == &amp;quot;test&amp;quot;, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because I plan on using the &lt;code&gt;caret&lt;/code&gt; package for all of my modeling, I&amp;rsquo;m going to generate a standard &lt;code&gt;trainControl&lt;/code&gt; so that those tuning parameters remain consistent throughout the various models.&lt;/p&gt;

&lt;h3 id=&#34;creating-traincontrol&#34;&gt;Creating trainControl&lt;/h3&gt;

&lt;p&gt;I will create a system that will perform 10 repeats of a 10-Fold cross-validation of the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;myControl &amp;lt;- trainControl(method = &amp;quot;cv&amp;quot;, number = 10, repeats = 10, 
    verboseIter = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fitting-a-random-forest-model&#34;&gt;Fitting a random forest model&lt;/h3&gt;

&lt;p&gt;The first type of model I&amp;rsquo;d like to use is a random forest model (using the &lt;code&gt;ranger&lt;/code&gt; and &lt;code&gt;caret&lt;/code&gt; packages).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_model &amp;lt;- train(Survived ~ Age + Pclass + Sex + SibSp + Parch + 
    Fare + Embarked + Titles + FamilySize + TravelGroup + GroupSize, 
    tuneGrid = data.frame(mtry = c(2, 5, 8, 10, 15)), data = train_complete, 
    method = &amp;quot;ranger&amp;quot;, trControl = myControl, importance = &amp;quot;impurity&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;fitting-a-glmnet-model&#34;&gt;Fitting a glmnet model&lt;/h3&gt;

&lt;p&gt;Next, we&amp;rsquo;ll try a glmnet model, also from the &lt;code&gt;caret&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;glm_model &amp;lt;- train(Survived ~ Age + Pclass + Sex + SibSp + Parch + 
    Fare + Embarked + Titles + FamilySize + TravelGroup + GroupSize, 
    method = &amp;quot;glmnet&amp;quot;, tuneGrid = expand.grid(alpha = 0:1, lambda = seq(1e-04, 
        1, length = 20)), data = train_complete, trControl = myControl)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;comparing-model-fit&#34;&gt;Comparing model fit&lt;/h3&gt;

&lt;p&gt;Now that we have a random forest model and a glmnet model, it&amp;rsquo;s time to compare their fit.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a list of models
models &amp;lt;- list(rf = rf_model, glmnet = glm_model)

# Resample the models
resampled &amp;lt;- resamples(models)

# Generate a summary
summary(resampled)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## summary.resamples(object = resampled)
## 
## Models: rf, glmnet 
## Number of resamples: 10 
## 
## Accuracy 
##          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf     0.7667  0.7893 0.8146 0.8250  0.8669 0.8889    0
## glmnet 0.7889  0.8118 0.8531 0.8418  0.8624 0.9101    0
## 
## Kappa 
##          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## rf     0.5215  0.5375 0.6083 0.6239  0.7092 0.7613    0
## glmnet 0.5535  0.6026 0.6842 0.6617  0.7027 0.8117    0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Plot the differences between model fits
dotplot(resampled, metric = &amp;quot;Accuracy&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../Titanic_md_files/figure-markdown_github/unnamed-chunk-37-1.png&#34; class=&#34;img-responsive&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like the glmnet model is slightly more accurate than the random forest model, so we&amp;rsquo;ll use that to predict the survival rate.&lt;/p&gt;

&lt;p&gt;Ok, time to make some predictions.&lt;/p&gt;

&lt;h2 id=&#34;predicting-survival&#34;&gt;Predicting Survival&lt;/h2&gt;

&lt;p&gt;Although I generated two models above, the glmnet model provided higher accuracy, so I&amp;rsquo;ll use that model to predict survival in the test set.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Reorder the data by Passenger ID number
test_complete &amp;lt;- test_complete %&amp;gt;% arrange(PassengerId)

# Make predicted survival values
my_prediction &amp;lt;- predict(glm_model, test_complete)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;preparing-the-prediction-for-kaggle&#34;&gt;Preparing the prediction for Kaggle&lt;/h3&gt;

&lt;p&gt;The instructions on Kaggle indicate that they are expecting a csv file with 2 columns: Passenger ID and Survived. I need to make sure that my data are arranged properly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Create a data frame with two columns: PassengerId &amp;amp;
# Survived where Survived contains my predictions.
my_solution_5 &amp;lt;- data.frame(PassengerID = test$PassengerId, Survived = my_prediction)

# Write the solution to a csv file
write.csv(my_solution_5, file = &amp;quot;my_solution_5.csv&amp;quot;, row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;testing-with-kaggle&#34;&gt;Testing with Kaggle&lt;/h3&gt;

&lt;p&gt;Looks like that submission scored 0.80383! Not bad!!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I&amp;rsquo;d love to hear any feedback you may have on this process. Thanks in advance!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>